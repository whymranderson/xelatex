
\documentclass{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{accents}
\usepackage[ignoreall,a4paper]{geometry}
\usepackage{fancyhdr}

\setcounter{MaxMatrixCols}{10}
%TCIDATA{OutputFilter=LATEX.DLL}
%TCIDATA{Version=5.00.0.2606}
%TCIDATA{<META NAME="SaveForMode" CONTENT="1">}
%TCIDATA{BibliographyScheme=Manual}
%TCIDATA{Created=Wednesday, November 25, 2015 15:33:37}
%TCIDATA{LastRevised=Wednesday, December 09, 2015 16:39:19}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{<META NAME="DocumentShell" CONTENT="Standard LaTeX\Blank - Standard LaTeX Article">}
%TCIDATA{CSTFile=40 LaTeX article.cst}

\newtheorem{theorem}{Theorem}
\newtheorem{acknowledgement}[theorem]{Acknowledgement}
\newtheorem{algorithm}[theorem]{Algorithm}
\newtheorem{axiom}[theorem]{Axiom}
\newtheorem{case}[theorem]{Case}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conclusion}[theorem]{Conclusion}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{criterion}[theorem]{Criterion}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{solution}[theorem]{Solution}
\newtheorem{summary}[theorem]{Summary}
\newenvironment{proof}[1][Proof]{\noindent\textbf{#1.} }{\ \rule{0.5em}{0.5em}}
\input{../tcilatex}
\DeclareMathAccent{\wtilde}{\mathord}{largesymbols}{"65}
\pagestyle{fancy}
\fancyfoot[C]{\thepage}

\input{tcilatex}

\begin{document}


\section{Minimax Estimation}

\begin{equation}
\underset{\hat{\beta}\in \mathbb{A}}{\min }\,\underset{\beta \in \mathbb{B}}{%
\sup }\quad R\left( \underaccent{\wtilde}{\hat{\beta}}^{\ast },%
\underaccent{\wtilde}{\beta},A\right) =\underset{\beta \in \mathbb{B}}{\sup }%
\left( \underaccent{\wtilde}{\hat{\beta}}^{\ast },\underaccent{\wtilde}{%
\beta},A\right) \Rightarrow \hat{\beta}^{\ast }\text{ is minimax}
\end{equation}

\bigskip

\begin{theorem}
Inequality Restrictions
\end{theorem}

Restriction on $\underaccent{\wtilde}{\beta}$: $A\underaccent{\wtilde}{\beta}%
\leq a\qquad a:$know vector(by priori knowledge)

\begin{equation}
\min \,\text{\c{S}}\left( \underaccent{\wtilde}{\beta}\right) =\left( Y-x%
\underaccent{\wtilde}{\beta}\right) ^{T}\left( Y-x\underaccent{\wtilde}{%
\beta}\right)
\end{equation}

Assume $a_{i}\leq \beta _{i}\leq b_{i}$ ($a_{i}$, $b_{i}$ known)

take%
\begin{equation}
\frac{\left\vert \beta _{i}-\frac{\left( a_{i}+b_{i}\right) }{2}\right\vert 
}{\frac{\left( b_{i}-a_{i}\right) }{2}}\leq 1\qquad \forall \quad i
\end{equation}

We want an ellipsoid $\left( \underaccent{\wtilde}{\beta}-%
\underaccent{\wtilde}{\beta}_{0}\right) ^{^{\prime }}T\left( %
\underaccent{\wtilde}{\beta}-\underaccent{\wtilde}{\beta}_{0}\right) \leq 1$%
, which encloses the and fullness the following condition:

\begin{enumerate}
\item The ellipsoid and cuboid have the same center point%
\begin{equation}
(i.e.)\quad \underaccent{\wtilde}{\beta}_{0}=\frac{1}{2}\left(
a_{1}+b_{1},\cdots ,a_{k}+b_{k}\right) ^{T}
\end{equation}

\item The axes of ellipsoid are parallel the coordiated so%
\begin{equation}
T=diag\left( t_{1},\cdots ,t_{k}\right)
\end{equation}

\item The corner points of the cuboin are on the surface of the ellipsoid%
\begin{equation}
(i.e.)\quad \dsum\limits_{i=1}^{k}\left( \frac{a_{i}-b_{i}}{2}\right)
^{2}t_{i}=1
\end{equation}

\item The dllipsoid has minimum volume%
\begin{eqnarray}
\min \,V_{k} &=&C_{k}\dprod\limits_{i=1}^{k}t_{i}^{\frac{1}{2}} \\
&&C_{k}\text{ dependent on the dimension K}  \notag \\
s.t.\qquad \dsum\limits_{i=1}^{k}\left( \frac{a_{i}-b_{i}}{2}\right)
^{2}t_{i} &=&1
\end{eqnarray}
\end{enumerate}

\bigskip

take \~{V}$_{k}=\dprod\limits_{i=1}^{k}t_{i}^{-1}-\lambda \left(
\dsum\limits_{i=1}^{k}\left( \frac{a_{i}-b_{i}}{2}\right) ^{2}t_{i}-1\right) 
$

\begin{equation}
\left\{ 
\begin{array}{c}
\frac{\partial \tilde{V}_{k}}{\partial t_{j}}=\dprod\limits_{i\neq
j}^{k}t_{j}^{-1}-\lambda \left( \frac{a_{i}-b_{i}}{2}\right) ^{2}=0 \\ 
\frac{\partial \tilde{V}_{k}}{\partial t_{j}}=\dsum\limits_{{}}^{{}}\left( 
\frac{a_{i}-b_{i}}{2}\right) ^{2}t_{i}-1=0%
\end{array}%
\right.
\end{equation}

\begin{equation}
\Rightarrow \left\{ 
\begin{array}{c}
\lambda =-t_{j}^{-2}\dprod\limits_{i\neq j}^{k}t_{i}^{-1}\left( \frac{2}{%
a_{j}-b_{j}}\right) ^{2} \\ 
=-t_{j}^{-1}\dprod\limits_{i=1}^{k}t_{i}^{-1}\left( \frac{2}{a_{j}-b_{j}}%
\right) ^{2}%
\end{array}%
\right.
\end{equation}

\begin{eqnarray}
&\Rightarrow &t_{i}\left[ \frac{a_{i}-b_{i}}{2}\right] ^{2}=t_{j}\left[ 
\frac{a_{j}-b_{j}}{2}\right] ^{2} \\
\dsum\limits_{i=1}^{k}\left( \frac{a_{i}-b_{i}}{2}\right) ^{2}t_{i}
&=&\dsum\limits_{j=1}^{k}\left( \frac{a_{j}-b_{j}}{2}\right) ^{2}t_{j}
\end{eqnarray}

\begin{eqnarray}
&\Rightarrow &\dsum\limits_{i=1}^{k}\left( \frac{a_{i}-b_{i}}{2}\right)
^{2}t_{i}=1 \\
&\Rightarrow &\dsum\limits_{j=1}^{k}\left( \frac{a_{j}-b_{j}}{2}\right)
^{2}t_{j}=1 \\
&\Rightarrow &t_{j}=\frac{4}{k\left( a_{j}-b_{j}\right) ^{2}}\qquad
j=1,2,3,\cdots ,k
\end{eqnarray}

\bigskip

$\left( \underaccent{\wtilde}{\beta}-\underaccent{\wtilde}{\beta}_{0}\right)
^{T^{\prime }}T\left( \underaccent{\wtilde}{\beta}-\underaccent{\wtilde}{%
\beta}_{0}\right) =1$ the optimal which contain the cuboid, has the center
point vetor%
\begin{eqnarray}
\beta _{0}^{T} &=&\frac{1}{2}\left( a_{1}+b_{1},\cdots ,a_{k}+b_{k}\right) \\
T &=&diag\frac{4}{K}\left( \left( b_{1}-a_{1}\right) ^{-2},\cdots ,\left(
b_{k}-a_{k}\right) ^{-2}\right)
\end{eqnarray}

Note:

\begin{enumerate}
\item The ellipsoid has a larger volume than the cuboid

\item The transition to an ellipsoid as a priori information represents a
weakening, but comes with an earlier mathematical handling.
\end{enumerate}

\section{The Minimax Principle}

Consider the \emph{quodratic} risk $R_{1}\left( \underaccent{\wtilde}{\hat{%
\beta}},\underaccent{\wtilde}{\beta},A\right) =E\left[ \left( 
%TCIMACRO{%
%\TeXButton{underaccent_beta_hat}{\underaccent{\wtilde}{\hat{\beta}}}}%
%BeginExpansion
\underaccent{\wtilde}{\hat{\beta}}%
%EndExpansion
-%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
\right) ^{T}A\left( \hat{\beta}-\beta \right) \right] =tr\left[ AM\left( %
\underaccent{\wtilde}{\hat{\beta}},\underaccent{\wtilde}{\beta}\right) %
\right] $

Let B$\left( \beta \right) \subset \mathbb{R}^{k}$ be a convex region of a
priori restriction for $\underaccent{\wtilde}{\beta}$\bigskip

\begin{definition}
An estimator $b^{\ast }\in \left\{ \hat{\beta}\right\} $ is called a \textsf{%
minimax estimator} of $%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
$ if%
\begin{equation}
\underset{\left\{ 
%TCIMACRO{%
%\TeXButton{underaccent_beta_hat}{\underaccent{\wtilde}{\hat{\beta}}}}%
%BeginExpansion
\underaccent{\wtilde}{\hat{\beta}}%
%EndExpansion
\right\} }{\min }\,\underset{\beta \in \mathbb{B}}{\sup }\quad R_{1}\left( %
\underaccent{\wtilde}{\hat{\beta}},\underaccent{\wtilde}{\beta},A\right) =%
\underset{\beta \in \mathbb{B}}{\sup }R_{1}\left( b^{\ast },%
\underaccent{\wtilde}{\beta},A\right)
\end{equation}
\end{definition}

\bigskip

\paragraph{Linear Minimax Estimator}

Consider $\hat{\beta}=C%
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
$

\begin{eqnarray}
R_{1}\left( CY,\beta ,A\right) &=&E\left\{ \left( CY-B\right) ^{\dagger
}A\left( CY-B\right) \right\}  \notag \\
&=&E\left\{ \left( \underbrace{CY-C\chi \beta }+\underbrace{C\chi \beta -B}%
\right) ^{\dagger }A\left( \underbrace{CY-C\chi \beta }+\underbrace{C\chi
\beta -B}\right) \right\}  \notag \\
&=&\left( C\chi 
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
-%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
\right) ^{\dagger }A\left( C\chi 
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
-%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
\right)  \notag \\
&&+E\left\{ \left( CY-C\chi \beta \right) ^{\dagger }A\left( CY-C\chi \beta
\right) \right\}  \notag \\
&=&\beta ^{T}\left( C\chi -I\right) A\left( C\chi -I\right) \beta +E\left\{
C^{\dagger }\underbrace{\left( Y-\chi \beta \right) ^{\dagger }A\left(
Y-\chi \beta \right) }C\right\}  \notag \\
&=&\beta ^{T}\left( Cx-I\right) ^{\dagger }A\left( Cx-I\right) \beta
+tr\left\{ ACC^{\dagger }\underbrace{E\left( \hat{\beta}-\beta \right)
\left( \hat{\beta}-\beta \right) ^{\dagger }}\right\}  \notag \\
&=&\underset{1}{\underbrace{\beta ^{T}\left( Cx-I\right) ^{\dagger }A\left(
Cx-I\right) \beta }}+tr\left\{ ACC^{\dagger }\sigma ^{2}I\right\}
\end{eqnarray}

\begin{eqnarray*}
1 &=&\beta ^{T}T^{\frac{1}{2}}\underset{\tilde{A}}{\underbrace{\left[ T^{-%
\frac{1}{2}}\left( Cx-I\right) ^{T}A\left( Cx-I\right) T^{-\frac{1}{2}}%
\right] }}T^{\frac{1}{2}}\beta \\
&=&%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
^{\dagger }T^{\frac{1}{2}}\tilde{A}T^{\frac{1}{2}}%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
\end{eqnarray*}%
hence $R_{1}\left( CY,\beta ,A\right) =%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
^{\dagger }T^{\frac{1}{2}}\tilde{A}T^{\frac{1}{2}}%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
+tr\left\{ ACC^{\dagger }\sigma ^{2}I\right\} $

\begin{equation}
\underset{\beta ^{\dagger }T%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
\leq k}{\sup }\qquad R_{1}\left( CI,\beta ,A\right) =tr\left\{ ACC^{\dagger
}\sigma ^{2}I\right\} +k\lambda _{\max }\left( \tilde{A}\right)
\end{equation}%
want to a closed from for C

\bigskip

Consider $A=%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{\dagger }$, then $\left( \hat{\beta}-\beta \right) ^{T}%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{\dagger }\left( \hat{\beta}-\beta \right) =\left( a^{\dagger }\hat{\beta}%
-a^{\dagger }\beta \right) ^{\dagger }\left( a^{\dagger }\hat{\beta}%
-a^{\dagger }\beta \right) $

for this $A=%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{T}$, 
\begin{equation}
\tilde{A}=\left[ T^{-\frac{1}{2}}\left( Cx-I\right) ^{\dagger }%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
\right] \left[ 
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{\dagger }\left( Cx-I\right) T^{-\frac{1}{2}}\right] =\tilde{a}\tilde{a}%
^{\dagger }
\end{equation}

Note:{}

\begin{enumerate}
\item aa$^{\dagger }$ is monnegative $\tilde{a}\tilde{a}^{\dagger }x=\lambda
x$, take $x=\tilde{a}$, $\lambda =\tilde{a}^{\dagger }\tilde{a}$

\item $rank\left( aa^{T}\right) =1$, meaning eigenvalue = 1 is the only one,
the rest are zeros
\end{enumerate}

\bigskip

\paragraph{November 24}

\begin{eqnarray*}
R_{1} &=&E\left( CC%
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
-%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
\right) ^{T}A\left( CC%
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
-%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
\right) \qquad \beta ^{T}T\beta \leq k\qquad \text{no closed form} \\
R_{2} &=&E\left( CC%
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
-%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
\right) ^{T}%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{T}\left( CC%
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
-%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
\right)
\end{eqnarray*}

\begin{eqnarray}
&&\underset{\beta ^{\dagger }T%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
\leq k}{\sup }\qquad E\left( CC%
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
-%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
\right) ^{T}%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{T}\left( CC%
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
-%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
\right)  \notag \\
&=&\sigma ^{2}tr\left( 
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{T}CC^{T}\right) +k\underset{\lambda =%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{T}%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
}{\underbrace{%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{T}\left( Cx-I\right) T^{-1}\left( Cx-I\right) ^{T}%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
}}
\end{eqnarray}

\begin{equation*}
\frac{\partial }{\partial C}\left\{ \underset{\beta ^{T}T%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
\leq k}{\sup }\qquad R_{2}\right\} =\sigma ^{2}2C^{T}%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{T}%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
+2kxT^{-1}\left( Cx-I\right) ^{T}aa^{T}=0
\end{equation*}

\begin{equation*}
\Rightarrow \left[ \left( \sigma ^{2}I+kxT^{-1}x^{T}\right) C^{T}-kxT^{-1}%
\right] 
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{T}=0\qquad \forall \quad 
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
\end{equation*}

\begin{equation*}
\Rightarrow \left[ \left( \sigma ^{2}I+kxT^{-1}x^{T}\right) C^{T}-kxT^{-1}%
\right] =0
\end{equation*}

\begin{equation*}
\Rightarrow \left( \sigma ^{2}I+kxT^{-1}x^{T}\right) C^{T}=kxT^{-1}
\end{equation*}

\begin{equation*}
\Rightarrow C_{\ast }^{T}=k\left( \sigma ^{2}I+kxT^{-1}x^{T}\right)
^{-1}xT^{-1}
\end{equation*}%
so%
\begin{eqnarray*}
\left( \sigma ^{2}T+kx^{T}x\right) C_{\ast } &=&k\left( \sigma
^{2}T+kx^{T}x\right) T^{-1}x^{T}\left( \sigma ^{2}I+kxT^{-1}x^{T}\right)
^{-1} \\
&=&kx^{T}\left( \sigma ^{2}I+kxT^{-1}x^{T}\right) \left( \sigma
^{2}I+kxT^{-1}x^{T}\right) ^{-1} \\
&=&kx^{T}
\end{eqnarray*}

\begin{equation*}
\therefore \qquad C_{\ast }=\left( \sigma ^{2}T+kx^{T}x^{-1}\right)
kx^{T}=\left( x^{T}x+\frac{\sigma ^{2}}{k}T\right) ^{-1}x^{T}
\end{equation*}

\begin{equation*}
%TCIMACRO{%
%\TeXButton{underaccent_beta_hat}{\underaccent{\wtilde}{\hat{\beta}}}}%
%BeginExpansion
\underaccent{\wtilde}{\hat{\beta}}%
%EndExpansion
=CT\qquad \Rightarrow \hat{\beta}_{\ast }=C_{\ast }T=\left( x^{\dagger }x+%
\frac{\sigma ^{2}}{k}T\right) ^{-1}x^{\dagger }Y\qquad \beta ^{\dagger
}T\beta \leq k
\end{equation*}

\begin{enumerate}
\item LSE: $%
%TCIMACRO{%
%\TeXButton{underaccent_beta_hat}{\underaccent{\wtilde}{\hat{\beta}}}}%
%BeginExpansion
\underaccent{\wtilde}{\hat{\beta}}%
%EndExpansion
_{LSE}=\left( x^{\dagger }x\right) ^{-1}x^{\dagger }%
%TCIMACRO{\TeXButton{underaccent_T}{\underaccent{\wtilde}{T}}}%
%BeginExpansion
\underaccent{\wtilde}{T}%
%EndExpansion
$

\item Ridge: $%
%TCIMACRO{%
%\TeXButton{underaccent_beta_hat}{\underaccent{\wtilde}{\hat{\beta}}}}%
%BeginExpansion
\underaccent{\wtilde}{\hat{\beta}}%
%EndExpansion
_{R}=\left( x^{\dagger }x+kI\right) ^{-1}x^{\dagger }%
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
$

\item MinMax: $%
%TCIMACRO{%
%\TeXButton{underaccent_beta_hat}{\underaccent{\wtilde}{\hat{\beta}}}}%
%BeginExpansion
\underaccent{\wtilde}{\hat{\beta}}%
%EndExpansion
_{\ast }=\left( x^{\dagger }x+\frac{\sigma ^{2}}{k}T\right) ^{-1}x^{\dagger }%
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
$
\end{enumerate}

\begin{theorem}
In the model $Y=x\beta +\epsilon \qquad 
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
\sim N\left( o,\sigma ^{2}I\right) $ with the restriction $\beta ^{\dagger
}T\beta \leq k$ , $T>0$ and the risk function $R_{2}\left( \hat{\beta},\beta
,%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{\dagger }\right) $ the linear minimax estimator of the following form%
\begin{equation*}
\underline{\hat{\beta}_{\ast }=\left( x^{\dagger }x+\frac{\sigma ^{2}}{k}%
T\right) ^{-1}x^{\dagger }Y}=D_{t}^{-1}x^{\dagger }T
\end{equation*}%
\begin{eqnarray*}
bias\left( \hat{\beta}_{\ast },\beta \right) &=&E\left( \hat{\beta}_{\ast
}\right) -\beta =D_{t}^{-1}x^{\dagger }x\beta -\beta =\left(
D_{t}^{-1}x^{\dagger }x-I\right) 
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}} }%
%BeginExpansion
\underaccent{\wtilde}{\beta}
%EndExpansion
\\
&=&\left( D_{t}^{-1}x^{\dagger }x-D_{t}\right) 
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
=-\frac{\sigma ^{2}}{k}D_{t}^{-1}T%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
<0
\end{eqnarray*}%
\begin{equation*}
Var\left( \hat{\beta}_{\ast }\right) =Var\left( D_{t}^{-1}x^{\dagger
}Y\right) =D_{t}^{-1}x^{\dagger }xD_{t}^{-1}\sigma ^{2}
\end{equation*}%
And the minimax risk%
\begin{equation*}
\underset{\beta ^{\dagger }T\beta \leq k}{\sup }\qquad R_{2}\left( \hat{\beta%
}_{\ast },\beta ,%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
\right) =\sigma ^{2}%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{\dagger }D_{t}^{-1}%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
\end{equation*}
\end{theorem}

\begin{theorem}
Given the assumptions of the above theorem and the restriction $\left( \beta
-\beta _{0}\right) ^{\dagger }T\left( \beta -\beta _{0}\right) \leq k$ with
central point $\beta _{0}\neq 0$ then the linear minimax estimator is of the
following form%
\begin{equation*}
\hat{\beta}_{\ast }\left( \beta _{0}\right) =\beta _{0}+D^{-1}x^{\dagger
}\left( 
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
-x\beta _{0}\right)
\end{equation*}%
with bias,%
\begin{equation*}
bias\left( \hat{\beta}_{\ast }\left( \beta _{0}\right) ,\beta \right) =\frac{%
\sigma ^{2}}{k}D_{t}^{-1}T\left( \beta -\beta _{0}\right)
\end{equation*}%
\begin{equation*}
\sup \qquad R_{2}\left( \hat{\beta}_{\ast }\left( \beta _{0}\right) ,%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
,%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
\right) =\sigma ^{2}a^{\dagger }D_{t}^{-1}%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
\end{equation*}
\end{theorem}

\bigskip

\begin{theorem}
In the model $Y=x\beta +\epsilon \qquad 
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
\sim N\left( o,\sigma ^{2}I\right) $ with the restriction $\beta ^{\dagger
}T\beta \leq k$ , $T>0$ and the risk function $R_{2}\left( \hat{\beta},\beta
,%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{\dagger }\right) $ the linear minimax estimator of the following form%
\begin{equation*}
\underline{\hat{\beta}_{\ast }=\left( x^{\dagger }x+\frac{\sigma ^{2}}{k}%
T\right) ^{-1}x^{\dagger }Y}=D_{t}^{-1}x^{\dagger }T
\end{equation*}%
\begin{eqnarray*}
bias\left( \hat{\beta}_{\ast },\beta \right) &=&E\left( \hat{\beta}_{\ast
}\right) -\beta =D_{t}^{-1}x^{\dagger }x\beta -\beta =\left(
D_{t}^{-1}x^{\dagger }x-I\right) 
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}} }%
%BeginExpansion
\underaccent{\wtilde}{\beta}
%EndExpansion
\\
&=&\left( D_{t}^{-1}x^{\dagger }x-D_{t}\right) 
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
=-\frac{\sigma ^{2}}{k}D_{t}^{-1}T%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
<0
\end{eqnarray*}%
\begin{equation*}
Var\left( \hat{\beta}_{\ast }\right) =Var\left( D_{t}^{-1}x^{\dagger
}Y\right) =D_{t}^{-1}x^{\dagger }xD_{t}^{-1}\sigma ^{2}
\end{equation*}%
And the minimax risk%
\begin{equation*}
\underset{\beta ^{\dagger }T\beta \leq k}{\sup }\qquad R_{2}\left( \hat{\beta%
}_{\ast },\beta ,%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
\right) =\sigma ^{2}%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{\dagger }D_{t}^{-1}%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
\end{equation*}
\end{theorem}

\begin{theorem}
Given the assumptions of the above theorem and the restriction $\left( \beta
-\beta _{0}\right) ^{\dagger }T\left( \beta -\beta _{0}\right) \leq k$ with
central point $\beta _{0}\neq 0$ then the linear minimax estimator is of the
following form%
\begin{equation*}
\hat{\beta}_{\ast }\left( \beta _{0}\right) =\beta _{0}+D^{-1}x^{\dagger
}\left( 
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
-x\beta _{0}\right)
\end{equation*}%
with bias,%
\begin{equation*}
bias\left( \hat{\beta}_{\ast }\left( \beta _{0}\right) ,\beta \right) =\frac{%
\sigma ^{2}}{k}D_{t}^{-1}T\left( \beta -\beta _{0}\right)
\end{equation*}%
\begin{equation*}
\sup \qquad R_{2}\left( \hat{\beta}_{\ast }\left( \beta _{0}\right) ,%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
,%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
\right) =\sigma ^{2}a^{\dagger }D_{t}^{-1}%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
\end{equation*}
\end{theorem}

\bigskip

\begin{equation*}
Y=x\beta +\epsilon \qquad \beta ^{\dagger }T\beta \leq k\qquad \leq \left(
\beta -\beta _{0}\right) ^{\dagger }T\left( \beta -\beta _{0}\right) \leq k
\end{equation*}%
\begin{equation*}
\Rightarrow Y=x\left( \beta -\beta _{0}\right) +x\beta _{0}+\varepsilon
\Rightarrow Y-x\beta _{0}=x\left( \beta -\beta _{0}\right) +\varepsilon
\end{equation*}%
\begin{equation*}
\Rightarrow Y^{^{\prime }}=x\beta ^{^{\prime }}+\varepsilon
\end{equation*}

\bigskip

\begin{eqnarray*}
bias &=&\beta _{0}+D_{t}^{-1}x^{\dagger }x\beta -x\beta _{0}-\beta \\
&=&\left( I-x\right) \beta _{0}+\left( D_{t}^{-1}x^{\dagger }x-I\right) \beta
\\
&=&\left( I-x\right) \beta _{0}-\frac{\sigma ^{2}}{k}D_{t}^{-1}T\beta
\end{eqnarray*}

\bigskip

\begin{equation*}
\widehat{\left( \beta -\beta _{0}\right) }_{\ast }=D_{\ast }^{-1}x^{\dagger
}Y^{^{\prime }}\Rightarrow \hat{\beta}_{\ast }=\beta _{0}+D_{\ast
}^{-1}x^{\dagger }\left( \tilde{Y}-x\beta \right) \quad _{\#}
\end{equation*}%
\qquad \qquad

\bigskip

\paragraph{Comparisions of $\hat{\protect\beta}_{\ast }$ and $\hat{\protect%
\beta}_{OLE}$}

\quad

November 26

Minimax risk for $\hat{\beta}_{OLE}$

\begin{equation}
\blacktriangle \qquad \underset{\beta ^{\dagger }T\beta \leq k}{\sup }\qquad
R_{2}\left( \hat{\beta}_{OLE};%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
\right) =\sigma ^{2}%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{\dagger }\text{\c{S}}^{-1}%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
\end{equation}%
where \c{S}$=x^{\dagger }x$

since $\underset{\beta ^{\dagger }T\beta \leq k}{\sup }\qquad R_{2}\left( CY;%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
\right) =ka^{\dagger }\left[ \left( Cx-I\right) T^{-1}\left( Cx-I\right)
^{\dagger }\right] 
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
+tr\left( 
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{\dagger }CC^{\dagger }%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
\right) \sigma ^{2}$

for OL\c{S}E $\hat{\beta}=\left( x^{\dagger }x\right) ^{-1}x^{\dagger
}Y\Rightarrow C=\left( x^{\dagger }x\right) ^{-1}x^{\dagger }\Rightarrow
Cx-I=\left( x^{\dagger }x\right) ^{-1}x^{\dagger }x-I=0$

\begin{equation}
\blacktriangle \qquad \underset{\beta ^{\dagger }T\beta \leq k}{\sup }\qquad
R_{2}\left( \hat{\beta}_{\ast };%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
\right) =\sigma ^{2}a^{\dagger }D_{\ast }^{-1}a=\sigma ^{2}%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{\dagger }\left( x^{\dagger }x+\frac{\sigma ^{2}}{k}\right) ^{-1}%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
\end{equation}

\bigskip

\begin{enumerate}
\item $\underset{\beta ^{\dagger }T\beta \leq k}{\sup }\qquad R_{2}\left( 
\hat{\beta}_{OLE};%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
\right) -\underset{\beta ^{\dagger }T\beta \leq k}{\sup }\qquad R_{2}\left( 
\hat{\beta}_{\ast };%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
\right) =$%
\begin{eqnarray*}
&&\sigma ^{2}%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{\dagger }\text{\c{S}}^{-1}%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
-\sigma ^{2}%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{\dagger }\left( x^{\dagger }x+\frac{\sigma ^{2}}{k}T\right) ^{-1}%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}} }%
%BeginExpansion
\underaccent{\wtilde}{a}
%EndExpansion
\\
&=&\sigma ^{2}%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{\dagger }\left[ \text{\c{S}}-\left( x^{\dagger }x+\frac{\sigma ^{2}}{k}%
T\right) ^{-1}\right] 
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
\geq 0
\end{eqnarray*}%
Since \c{S}$-\left( \frac{\sigma ^{2}}{k}T+\text{\c{S}}\right) ^{-1}\leq
0\quad \Rightarrow $\c{S}$^{-1}-\left( \frac{\sigma ^{2}}{k}T+\text{\c{S}}%
\right) ^{-1}\geq 0$. (i.e. Minimax risk is smaller)

\item MDE-I superiority:%
\begin{eqnarray*}
M\left( \hat{\beta}_{\ast };\beta \right) &=&E\left[ \left( \hat{\beta}%
_{\ast }-\beta \right) \left( \hat{\beta}_{\ast }-\beta \right) ^{\dagger }%
\right] \\
&=&Var\left( \hat{\beta}_{\ast }\right) +bias\cdot bias \\
&=&\sigma ^{2}D_{\ast }^{-1}\text{\c{S}}D_{\ast }^{-1}+\left( \frac{\sigma
^{2}}{k}D_{\ast }^{-1}T%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
\right) \left( \frac{\sigma ^{2}}{k}D_{\ast }^{-1}T%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
\right) ^{\dagger } \\
&=&\sigma ^{2}D_{\ast }^{-1}\left( \text{\c{S}}+\frac{\sigma ^{2}}{k}T%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
^{\dagger }T^{\dagger }\right) D_{\ast }^{-1}
\end{eqnarray*}%
\begin{equation*}
\bigtriangleup \left( \hat{\beta}_{OLE}-\hat{\beta}_{\ast }\right) =\sigma
^{2}\text{\c{S}}^{-1}-\sigma ^{2}D_{\ast }^{-1}\left( \text{\c{S}}+\frac{%
\sigma ^{2}}{k}T%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
^{\dagger }T^{\dagger }\right) D_{\ast }^{-1}\geq 0
\end{equation*}%
\begin{equation*}
\Leftrightarrow \sigma ^{2}D_{\ast }^{-1}\underset{B}{\underline{\left(
D_{\ast }^{{}}\text{\c{S}}D_{\ast }^{-1}-\text{\c{S}}-\frac{\sigma ^{2}}{k}T%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
^{\dagger }T^{\dagger }\right) }}D_{\ast }^{-1}\geq 0
\end{equation*}%
\begin{equation*}
D=x^{\dagger }x+\frac{\sigma ^{2}}{k}T
\end{equation*}%
\begin{equation*}
\Leftrightarrow B\geq 0
\end{equation*}%
\begin{equation*}
\Leftrightarrow B=\frac{\sigma ^{4}}{k^{2}}T\left[ \text{\c{S}}^{-1}+2\frac{k%
}{\sigma ^{2}}T^{-1}-\frac{1}{\sigma ^{2}}\beta \beta ^{\dagger }\right] T%
\text{ \ \ \ substitute D}
\end{equation*}%
\begin{equation*}
\Leftrightarrow \left[ \underset{\tilde{C}}{\underline{S^{-1}+2\frac{k}{%
\sigma ^{2}}T^{-1}}}-\frac{1}{\sigma ^{2}}\beta \beta ^{\dagger }\right]
\geq 0
\end{equation*}%
\begin{equation*}
\Leftrightarrow \tilde{C}=S^{-1}+2\frac{k}{\sigma ^{2}}T^{-1}
\end{equation*}%
\begin{equation*}
\Leftrightarrow \frac{\sigma ^{4}}{k^{2}}T\tilde{C}^{\frac{1}{2}}\left[ I-%
\frac{1}{\sigma ^{2}}\tilde{C}^{-\frac{1}{2}}%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
^{\dagger }\tilde{C}^{-\frac{1}{2}}\right] \tilde{C}^{-\frac{1}{2}}T\geq 0
\end{equation*}
\end{enumerate}

by Thm A.46 $\Leftrightarrow I-\frac{1}{\sigma ^{2}}\tilde{C}^{-\frac{1}{2}%
}\beta \beta ^{\dagger }\tilde{C}^{-\frac{1}{2}}\geq 0$

by Thm A.57 $\Leftrightarrow \frac{1}{\sigma ^{2}}\beta ^{\dagger }\tilde{C}%
^{-\frac{1}{2}}\tilde{C}^{-\frac{1}{2}}\beta \leq 1$

$\Leftrightarrow \frac{1}{\sigma ^{2}}%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
^{\dagger }\left( S^{-1}+2\frac{k}{\sigma ^{2}}T^{-1}\right) ^{-1}\beta \leq
1$

by Thm A.40 $\left( 2\frac{k}{\sigma ^{2}}T^{-1}\right) ^{-1}-\left( S^{-1}+2%
\frac{k}{\sigma ^{2}}T^{-1}\right) ^{-1}\geq 0$

so $\frac{1}{\sigma ^{2}}%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
^{\dagger }\frac{\sigma ^{2}}{2k}-%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
=\frac{1}{2k}%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
^{\dagger }T%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
\leq 1$ $\Rightarrow $\underline{$%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
^{\dagger }T%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
\leq 2k$}

$\Rightarrow \hat{\beta}_{\ast }$ is best when $%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
^{\dagger }T%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
\leq k$

by MDE $%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
^{\dagger }T%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
\leq 2k$ is the best compared to OLE. (initially set to $\leq k$, but can
relax to 2k)

\bigskip

\begin{equation*}
\hat{\beta}_{\ast }:bias=-\frac{\sigma ^{2}}{k}D_{t}^{-1}T%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
,\qquad Var\left( \hat{\beta}_{\ast }\right) =\sigma
^{2}D_{t}^{-1}x^{\dagger }xD_{t}^{-1}=\sigma ^{2}D_{t}^{-1}\text{\c{S}}%
D_{t}^{-1}
\end{equation*}%
\begin{equation*}
\hat{\beta}_{OLE}:bias=0,\qquad Var\left( \hat{\beta}_{OLE}\right) =\sigma
^{2}\text{\c{S}}^{-1}
\end{equation*}

\bigskip

\begin{equation*}
\tilde{\beta}=\beta \beta ^{\dagger }x^{\dagger }\left( x\beta \beta
^{\dagger }x^{\dagger }+\sigma ^{2}W\right) ^{-1}Y
\end{equation*}

by Thm A.18(iv)%
\begin{equation*}
\left( x\beta \beta ^{\dagger }x^{\dagger }+\sigma ^{2}W\right) ^{-1}=\frac{1%
}{\sigma ^{2}}W^{-1}-\frac{\frac{1}{\sigma ^{4}}W^{-1}x\beta \beta ^{\dagger
}x^{\dagger }W^{-1}}{1+\frac{1}{\sigma ^{2}}\beta ^{\dagger }x^{\dagger
}W^{-1}x\beta }
\end{equation*}%
\begin{eqnarray*}
\tilde{\beta}_{2} &=&\beta \beta ^{\dagger }x^{\dagger }\left( \frac{1}{%
\sigma ^{2}}W^{-1}-\frac{\frac{1}{\sigma ^{4}}W^{-1}x\beta \beta ^{\dagger
}x^{\dagger }W^{-1}}{1+\frac{1}{\sigma ^{2}}\beta ^{\dagger }\underset{\text{%
\c{S}}}{\underbrace{x^{\dagger }W^{-1}x}}\beta }\right) \\
&=&\beta \left[ \frac{1}{\sigma ^{2}}-\frac{\frac{1}{\sigma ^{4}}\beta
^{\dagger }\text{\c{S}}\beta }{1+\frac{1}{\sigma ^{2}}\beta ^{\dagger }\text{%
\c{S}}\beta }\right] \beta ^{\dagger }x^{\dagger }W^{-1}%
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}} }%
%BeginExpansion
\underaccent{\wtilde}{Y}
%EndExpansion
\\
&=&\beta \frac{\beta ^{\dagger }x^{\dagger }W^{-1}%
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
}{\sigma ^{2}+\beta ^{\dagger }\text{\c{S}}\beta }
\end{eqnarray*}

\begin{equation*}
\left[ \frac{1}{\sigma ^{2}}-\frac{\frac{1}{\sigma ^{4}}\beta ^{\dagger }%
\text{\c{S}}\beta }{1+\frac{1}{\sigma ^{2}}\beta ^{\dagger }\text{\c{S}}%
\beta }=\frac{1+\frac{1}{\sigma ^{2}}\beta ^{\dagger }\text{\c{S}}\beta -%
\frac{1}{\sigma ^{2}}\beta ^{\dagger }\text{\c{S}}\beta }{\left( 1+\frac{1}{%
\sigma ^{2}}\beta ^{\dagger }\text{\c{S}}\beta \right) \sigma ^{2}}=\frac{1}{%
\sigma ^{2}+\beta ^{\dagger }\text{\c{S}}\beta }\right]
\end{equation*}

\begin{equation*}
E\left( \tilde{\beta}_{2}\right) =\beta \frac{\beta ^{\dagger }x^{\dagger
}W^{-1}x\beta }{\sigma ^{2}+\beta ^{\dagger }\text{\c{S}}\beta }=\beta \frac{%
\beta ^{\dagger }\text{\c{S}}\beta }{\sigma ^{2}+\beta ^{\dagger }\text{\c{S}%
}\beta }<\beta \qquad \text{\ off and underestimated}
\end{equation*}%
\begin{equation*}
\Rightarrow \tilde{\beta}_{2}\text{ underestimated }%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
\end{equation*}%
\begin{equation*}
bias\left( \tilde{\beta}_{2},\beta \right) =E\left( \tilde{\beta}_{2}\right)
-\beta =\beta \frac{\beta ^{\dagger }\text{\c{S}}\beta }{\sigma ^{2}+\beta
^{\dagger }\text{\c{S}}\beta }-\beta =\beta \left( 1-\frac{\beta ^{\dagger }%
\text{\c{S}}\beta }{\sigma ^{2}+\beta ^{\dagger }\text{\c{S}}\beta }\right)
\end{equation*}%
\begin{equation*}
=\beta \underset{\leq 0}{\underbrace{\left( -\frac{\sigma ^{2}}{\sigma
^{2}+\beta ^{\dagger }\text{\c{S}}\beta }\right) }}
\end{equation*}%
\begin{equation*}
Var\left( \tilde{\beta}_{2}\right) =\frac{\beta \beta ^{\dagger }\sigma
^{2}\left( \beta ^{\dagger }\text{\c{S}}\beta \right) }{\left( \sigma
^{2}+\beta ^{\dagger }\text{\c{S}}\beta \right) ^{2}}
\end{equation*}%
\begin{equation*}
MDE=M\left( \hat{\beta}_{2},\beta \right) =Var\left( \tilde{\beta}%
_{2}\right) +bias\cdot bias^{\dagger }
\end{equation*}%
\begin{equation*}
=\frac{\beta \beta ^{\dagger }\sigma ^{2}\left( \beta ^{\dagger }\text{\c{S}}%
\beta \right) }{\left( \sigma ^{2}+\beta ^{\dagger }\text{\c{S}}\beta
\right) ^{2}}+\frac{\sigma ^{4}}{\left( \sigma ^{2}+\beta ^{\dagger }\text{%
\c{S}}\beta \right) ^{2}}\beta \beta ^{\dagger }=\frac{\beta \beta ^{\dagger
}\sigma ^{2}}{\sigma ^{2}+\beta ^{\dagger }\text{\c{S}}\beta }
\end{equation*}

Consider $k=1$, $W=I\sigma ^{2},$ then%
\begin{equation*}
\tilde{\beta}_{2}=\frac{\beta ^{2}%
%TCIMACRO{\TeXButton{underaccent_x}{\underaccent{\wtilde}{x}}}%
%BeginExpansion
\underaccent{\wtilde}{x}%
%EndExpansion
^{\dagger }Y}{\sigma ^{2}+\beta ^{\dagger }%
%TCIMACRO{\TeXButton{underaccent_x}{\underaccent{\wtilde}{x}}}%
%BeginExpansion
\underaccent{\wtilde}{x}%
%EndExpansion
^{\dagger }%
%TCIMACRO{\TeXButton{underaccent_x}{\underaccent{\wtilde}{x}}}%
%BeginExpansion
\underaccent{\wtilde}{x}%
%EndExpansion
}=\frac{%
%TCIMACRO{\TeXButton{underaccent_x}{\underaccent{\wtilde}{x}}}%
%BeginExpansion
\underaccent{\wtilde}{x}%
%EndExpansion
^{\dagger }Y}{\left( \frac{\sigma }{\beta }\right) ^{2}+%
%TCIMACRO{\TeXButton{underaccent_x}{\underaccent{\wtilde}{x}}}%
%BeginExpansion
\underaccent{\wtilde}{x}%
%EndExpansion
^{\dagger }%
%TCIMACRO{\TeXButton{underaccent_x}{\underaccent{\wtilde}{x}}}%
%BeginExpansion
\underaccent{\wtilde}{x}%
%EndExpansion
}
\end{equation*}%
\begin{equation*}
=\frac{%
%TCIMACRO{\TeXButton{underaccent_x}{\underaccent{\wtilde}{x}}}%
%BeginExpansion
\underaccent{\wtilde}{x}%
%EndExpansion
^{\dagger }%
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
}{%
%TCIMACRO{\TeXButton{underaccent_x}{\underaccent{\wtilde}{x}}}%
%BeginExpansion
\underaccent{\wtilde}{x}%
%EndExpansion
^{\dagger }%
%TCIMACRO{\TeXButton{underaccent_x}{\underaccent{\wtilde}{x}}}%
%BeginExpansion
\underaccent{\wtilde}{x}%
%EndExpansion
}\left( \frac{1}{1+\left( \frac{\sigma }{\beta }\right) ^{2}\frac{1}{%
%TCIMACRO{\TeXButton{underaccent_x}{\underaccent{\wtilde}{x}}}%
%BeginExpansion
\underaccent{\wtilde}{x}%
%EndExpansion
^{\dagger }%
%TCIMACRO{\TeXButton{underaccent_x}{\underaccent{\wtilde}{x}}}%
%BeginExpansion
\underaccent{\wtilde}{x}%
%EndExpansion
}}\right) =\hat{\beta}_{OL\text{\c{S}}}\left( 1+\left( \frac{\sigma }{\beta }%
\right) ^{2}\left( 
%TCIMACRO{\TeXButton{underaccent_x}{\underaccent{\wtilde}{x}}}%
%BeginExpansion
\underaccent{\wtilde}{x}%
%EndExpansion
^{\dagger }%
%TCIMACRO{\TeXButton{underaccent_x}{\underaccent{\wtilde}{x}}}%
%BeginExpansion
\underaccent{\wtilde}{x}%
%EndExpansion
\right) ^{-1}\right) ^{-1}
\end{equation*}

\bigskip

\newpage

\part{The Generalized Linear Regression Model}

\begin{equation*}
Y=x\beta +%
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
\quad E\left( 
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
\right) =0\quad Cov\left( 
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
\right) =\sigma ^{2}W,\quad W=p\cdot d\cdot m
\end{equation*}%
rank(x)=k, we want to estimate $%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
$

W know

Consider linear in the response vector $%
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
,$ $\hat{\beta}=CY+%
%TCIMACRO{\TeXButton{underaccent_d}{\underaccent{\wtilde}{d}}}%
%BeginExpansion
\underaccent{\wtilde}{d}%
%EndExpansion
$%
\begin{equation*}
R_{1}\left( \tilde{\beta},\beta ,A\right) =E\left( \left( \tilde{\beta}%
-\beta \right) ^{\dagger }A\left( \tilde{\beta}-\beta \right) \right) \qquad
A=pdm
\end{equation*}%
\begin{equation*}
R_{2}\left( \tilde{\beta},\beta ,%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{\dagger }\right) =E\left( \left( \tilde{\beta}-\beta \right) ^{\dagger }%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
^{\dagger }\left( \tilde{\beta}-\beta \right) \right)
\end{equation*}%
\begin{equation*}
R_{3}\left( \tilde{\beta},\beta \right) =E\left( \left( Y-x\tilde{\beta}%
\right) ^{\dagger }W^{-1}\left( Y-x\tilde{\beta}\right) \right)
\end{equation*}

\paragraph{R$_{1}$-optional estimators}

\begin{enumerate}
\item heterogeneious case $\tilde{\beta}=CY+d$%
\begin{equation*}
\tilde{\beta}-\beta =CY+d-\beta =C\left( x\beta +\varepsilon \right)
+d-\beta =\left( Cx-I\right) \beta +d+C\varepsilon
\end{equation*}%
\begin{equation*}
R_{1}\left( 
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
,\beta ,A\right) =E\left[ \left( Cx-I\right) \beta +d+C\varepsilon \right]
^{\dagger }A\left[ \left( Cx-I\right) \beta +d+C\varepsilon \right]
\end{equation*}%
\begin{equation*}
=\left[ \left( Cx-I\right) \beta +d\right] ^{\dagger }A\left[ \left(
Cx-I\right) \beta +d\right] +E\left[ \left( C\varepsilon \right) ^{\dagger
}A\left( C\varepsilon \right) \right]
\end{equation*}%
Consider $%
%TCIMACRO{\TeXButton{underaccent_d}{\underaccent{\wtilde}{d}}}%
%BeginExpansion
\underaccent{\wtilde}{d}%
%EndExpansion
=-\left( Cx-I\right) \beta $%
\begin{eqnarray}
\min \quad R_{1}\left( 
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
,\beta ,A\right) &=&\underset{C}{\min }\quad E\left[ \left( C\varepsilon
\right) ^{\dagger }A\left( C\varepsilon \right) \right]  \notag \\
&=&\underset{C}{\min }\quad E\left[ \varepsilon ^{\dagger }C^{\dagger
}AC\varepsilon \right]  \notag \\
&&\underset{C}{=\min }\quad tr\left( ACE\left( \varepsilon ^{\dagger
}\varepsilon \right) C^{\dagger }\right)  \notag \\
&&\underset{C}{=\min }\quad tr\left\{ \sigma ^{2}ACWC^{\dagger }\right\} 
\underline{\qquad }\left( \ast \right)
\end{eqnarray}%
$\frac{\partial \left( \ast \right) }{\partial C}=0$ by Thm A.93\symbol{126}%
A.95, $\Rightarrow 2\sigma ^{2}ACW=0\quad \Rightarrow C=0,$ $\because \tilde{%
\beta}=CY+%
%TCIMACRO{\TeXButton{underaccent_d}{\underaccent{\wtilde}{d}}}%
%BeginExpansion
\underaccent{\wtilde}{d}%
%EndExpansion
,$ $C=0,$ $\tilde{\beta}=%
%TCIMACRO{\TeXButton{underaccent_d}{\underaccent{\wtilde}{d}}}%
%BeginExpansion
\underaccent{\wtilde}{d}%
%EndExpansion
\quad $usefullness$_{\#}$

\item homo case $\tilde{\beta}=CY$%
\begin{equation*}
R_{1}\left( \tilde{\beta},\beta ,A\right) =E\left[ \left( Cx-I\right) \beta %
\right] ^{\dagger }A\left[ \left( Cx-I\right) \beta \right] +tr\left\{
\sigma ^{2}ACWC^{\dagger }\right\}
\end{equation*}%
\begin{equation*}
\frac{\partial R_{1}}{\partial C}=2A\left[ C\left( x%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
^{\dagger }x^{\dagger }\right) -\beta \beta ^{\dagger }x^{\dagger }\right] =0
\end{equation*}%
\begin{equation*}
\Rightarrow \tilde{C}_{2}=\beta \beta ^{\dagger }x^{\dagger }\left( x%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
^{\dagger }x^{\dagger }+\sigma ^{2}W\right) ^{-1}
\end{equation*}
\end{enumerate}

\bigskip

December 1

\begin{equation*}
Y=x\beta +\varepsilon \quad Cov\left( 
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
\right) =W
\end{equation*}%
where W is p.d.m.%
\begin{equation*}
R_{1}\left( \tilde{\beta},\beta ,A\right) =E\left\{ \left( \tilde{\beta}%
-\beta \right) ^{\dagger }A\left( \tilde{\beta}-\beta \right) \right\}
\end{equation*}%
\begin{equation*}
\left\{ 
\begin{array}{c}
\text{heterogeneous}\text{: usefullness} \\ 
\text{homogeneous}\text{:}\tilde{\beta}=%
%TCIMACRO{\TeXButton{underaccent_beta}{\underaccent{\wtilde}{\beta}}}%
%BeginExpansion
\underaccent{\wtilde}{\beta}%
%EndExpansion
\frac{\beta ^{\dagger }xW^{-1}Y}{\sigma ^{2}+\beta ^{\dagger }\text{\c{S}}%
\beta },\text{\quad \c{S}}=x^{\dagger }W^{-1}x \\ 
\text{homogeneous}\text{: unbiased}\underline{\qquad }\left( \ast \right)%
\end{array}%
\right.
\end{equation*}%
\begin{equation*}
R_{2}\left( \tilde{\beta},\beta ,a\right) =E\left\{ a^{\dagger }\left( 
\tilde{\beta}-\beta \right) \right\} ^{2}
\end{equation*}%
\begin{equation*}
R_{3}=\left( \tilde{\beta},\beta \right) =E\left\{ \left( Y-x%
%TCIMACRO{%
%\TeXButton{underaccent_beta_hat}{\underaccent{\wtilde}{\hat{\beta}}}}%
%BeginExpansion
\underaccent{\wtilde}{\hat{\beta}}%
%EndExpansion
\right) ^{\dagger }W^{-1}\left( Y-x%
%TCIMACRO{%
%\TeXButton{underaccent_beta_hat}{\underaccent{\wtilde}{\hat{\beta}}}}%
%BeginExpansion
\underaccent{\wtilde}{\hat{\beta}}%
%EndExpansion
\right) \right\}
\end{equation*}%
$\left( \ast \right) $ let CY is a homogeneous estimator of $%
%TCIMACRO{%
%\TeXButton{underaccent_beta_hat}{\underaccent{\wtilde}{\hat{\beta}}}}%
%BeginExpansion
\underaccent{\wtilde}{\hat{\beta}}%
%EndExpansion
$ if c$%
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
$ is unbiased%
\begin{equation*}
E\left( CY\right) =cx\beta =\beta \quad \forall \beta \Rightarrow
Cx=I\Rightarrow C_{i}^{\dagger }x-e_{i}^{\dagger }=%
%TCIMACRO{\TeXButton{underaccent_o}{\underaccent{\wtilde}{o}}}%
%BeginExpansion
\underaccent{\wtilde}{o}%
%EndExpansion
_{i}^{\dagger }\quad i=1,\cdots ,t
\end{equation*}%
$C_{i}^{\dagger }$ and $e_{i}^{\dagger }$ are the ith rwo vector of $%
%TCIMACRO{\TeXButton{underaccent_C}{\underaccent{\wtilde}{C}}}%
%BeginExpansion
\underaccent{\wtilde}{C}%
%EndExpansion
$ and $I$.

\begin{equation*}
\tilde{R}_{1}\left( \tilde{\beta},\beta ,A\right) =\sigma ^{2}tr\left\{
ACWC^{\dagger }\right\}
\end{equation*}%
\begin{equation*}
\Rightarrow \underset{C}{\min }\quad \tilde{R}_{1}=\underset{C}{\min }\quad
\left\{ \sigma ^{2}tr\left\{ ACWC^{\dagger }\right\} \right\}
\end{equation*}%
\begin{equation*}
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
=\sigma ^{2}tr\left\{ ACWC^{\dagger }\right\} -2\frac{\dsum \lambda
_{i}^{\dagger }\left( C_{i}^{\dagger }x-e_{i}^{\dagger }\right) }{\lambda
\left( Cx-I\right) }
\end{equation*}%
$\lambda _{i}$ are k-vector of Lagrogion multipliers $i=1,\cdots ,k$

Let $\Lambda ^{\dagger }=\left( \lambda _{1},\cdots ,\lambda _{k}\right) $%
\begin{equation*}
\frac{\partial 
%TCIMACRO{\U{211a} }%
%BeginExpansion
\mathbb{Q}
%EndExpansion
}{\partial C}=2\sigma ^{2}ACW-2\Lambda x^{\dagger }\Rightarrow \sigma
^{2}ACW=\Lambda x^{\dagger }
\end{equation*}%
\begin{equation*}
\Rightarrow \sigma ^{2}ACx=\Lambda x^{\dagger }W^{-1}x\Rightarrow \Lambda
=\sigma ^{2}ACx\left( x^{\dagger }W^{-1}x\right) ^{-1}
\end{equation*}

Since Cx=I $\Rightarrow \Lambda =\sigma ^{2}A\left( x^{\dagger
}W^{-1}x\right) ^{-1}$%
\begin{equation*}
\Rightarrow \sigma ^{2}AC=\underset{\Lambda }{\underbrace{\sigma ^{2}A\left(
x^{\dagger }W^{-1}x\right) ^{-1}}}x^{\dagger }W^{-1}
\end{equation*}%
\begin{equation*}
\therefore \tilde{C}_{3}=\left( x^{\dagger }W^{-1}x\right) ^{-1}x^{\dagger
}W^{-1}
\end{equation*}%
\begin{equation*}
\therefore \tilde{\beta}_{3}=\left( x^{\dagger }W^{-1}x\right)
^{-1}x^{\dagger }W^{-1}%
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
\quad \blacktriangle
\end{equation*}%
\begin{eqnarray*}
\tilde{R}_{1}\left( \tilde{\beta}_{3},\beta ,A\right) &=&\sigma
^{2}tr\left\{ A\tilde{C}_{3}W\tilde{C}_{3}^{\dagger }\right\} \\
&=&\sigma ^{2}tr\left\{ A\left( x^{\dagger }W^{-1}x\right) ^{-1}x^{\dagger
}W^{-1}x\left( x^{\dagger }W^{-1}x\right) ^{-1}\right\} \\
&=&\sigma ^{2}tr\left\{ A\left( x^{\dagger }W^{-1}x\right) ^{-1}\right\}
\end{eqnarray*}%
\begin{eqnarray*}
Cov\left( \tilde{\beta}_{3}\right) &=&\left( x^{\dagger }W^{-1}x\right)
^{-1}x^{\dagger }W^{-1}WW^{-1}x\left( x^{\dagger }W^{-1}x\right) ^{-1} \\
&=&\sigma ^{2}\left( x^{\dagger }W^{-1}x\right) ^{-1}
\end{eqnarray*}

\paragraph{R$_{2}$-optional estimator}

\begin{equation*}
R_{2}\left( \tilde{\beta},\beta ,%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
\right) =E\left[ a^{\dagger }\left( \tilde{\beta}-\beta \right) \right]
^{2}=E\left[ \left( \tilde{\beta}-\beta \right) ^{\dagger }aa^{\dagger
}\left( \tilde{\beta}-\beta \right) \right]
\end{equation*}

\begin{theorem}
The criteria R$_{1}$ and R$_{2}$ are equivalent.
\end{theorem}

\begin{proof}
$A=\tsum \lambda _{i}P_{i}P_{i}^{\dagger }$, $\left( \lambda
_{i},P_{i}\right) $ are eig-value and eig-vector paires of A
\end{proof}

First we want to show R$_{2}$-optional estimator $\hat{\beta}$ is R$_{1}$%
-optional. If $\hat{\beta}$ is R$_{2}$-optional then for any estimator $\hat{%
\beta}$ and for the choice of $%
%TCIMACRO{\TeXButton{underaccent_a}{\underaccent{\wtilde}{a}}}%
%BeginExpansion
\underaccent{\wtilde}{a}%
%EndExpansion
=\sqrt{\lambda _{i}}P_{i}\quad i=1,\cdots ,k$%
\begin{equation*}
\lambda _{i}E\left\{ \left( \hat{\beta}-\beta \right) ^{\dagger
}P_{i}P_{i}^{\dagger }\left( \hat{\beta}-\beta \right) \right\} \leq \lambda
_{i}E\left\{ \left( \tilde{\beta}-\beta \right) ^{\dagger
}P_{i}P_{i}^{\dagger }\left( \tilde{\beta}-\beta \right) \right\}
\end{equation*}%
$\hat{\beta}$ is R$_{2}$-optional%
\begin{equation*}
\Rightarrow E\left\{ \left( \hat{\beta}-\beta \right) ^{\dagger }\dsum
\lambda _{i}P_{i}P_{i}^{\dagger }\left( \hat{\beta}-\beta \right) \right\}
\leq E\left\{ \left( \tilde{\beta}-\beta \right) ^{\dagger }\dsum \lambda
_{i}P_{i}P_{i}^{\dagger }\left( \tilde{\beta}-\beta \right) \right\}
\end{equation*}%
\begin{equation*}
\Rightarrow E\left\{ \left( \hat{\beta}-\beta \right) ^{\dagger }A\left( 
\hat{\beta}-\beta \right) \right\} \leq E\left\{ \left( \tilde{\beta}-\beta
\right) ^{\dagger }A\left( \tilde{\beta}-\beta \right) \right\}
\end{equation*}

\bigskip

\paragraph{R$_{3}$-optional estimator}

\begin{equation*}
R_{3}\left( \tilde{\beta},\beta \right) =E\left[ \left( Y-x\tilde{\beta}%
\right) ^{\dagger }W^{-1}\left( Y-x\tilde{\beta}\right) \right]
\end{equation*}

Since $\tilde{\beta}=CY+d$%
\begin{equation*}
\Rightarrow R_{3}\left( \tilde{\beta},\beta \right) =E\left[ \left( Y-x%
\tilde{\beta}\right) ^{\dagger }W^{-1}\left( Y-x\tilde{\beta}\right) \right]
\end{equation*}%
\begin{equation*}
=E\left[ \left( Y-xCY-xd\right) ^{\dagger }W^{-1}\left( Y-xCY-xd\right) %
\right]
\end{equation*}%
\begin{equation*}
=E\left[ \left( \left( I-xC\right) Y-xd\right) ^{\dagger }W^{-1}\left(
\left( I-xC\right) Y-xd\right) \right]
\end{equation*}%
\begin{equation*}
=\left( \left( I-xC\right) x\beta -xd\right) ^{\dagger }W^{-1}\left( \left(
I-xC\right) x\beta -xd\right) +\sigma ^{2}tr\left\{ W^{-1}\left( I-xC\right)
W\left( I-xC\right) ^{\dagger }\right\}
\end{equation*}%
\begin{equation*}
=\left( \left( I-xC\right) \beta -d\right) ^{\dagger }x^{\dagger
}W^{-1}x\left( \left( I-xC\right) \beta -d\right) +\sigma ^{2}tr\left\{
W^{-1}\left( I-xC\right) W\left( I-xC\right) ^{\dagger }\right\}
\end{equation*}

Consider $\hat{d}=\left( I-Cx\right) \beta $

Now V$^{2}=tr\left\{ W^{-1}\left( I-xC\right) W\left( I-xC\right) ^{\dagger
}\right\} =tr\left\{ I+C^{\dagger }x^{\dagger }W^{-1}xCW-2C^{\dagger
}x^{\dagger }\right\} $

$\left[ \frac{\partial }{\partial x}tr\left\{ x^{\prime }AxB\right\}
=AxB+A^{\prime }xB^{\prime }\right] $

\begin{equation*}
\frac{\partial V^{2}}{\partial C}=0\Rightarrow 2x^{\dagger
}W^{-1}xCW-2x^{\dagger }=0\Rightarrow \hat{C}=\left( x^{\dagger
}W^{-1}x\right) ^{-1}x^{\dagger }W^{-1}
\end{equation*}%
\begin{equation*}
\Rightarrow \hat{\beta}=\hat{C}x+\hat{d}
\end{equation*}%
where $\hat{d}=\left( I-Cx\right) \beta =\left( I-\left( x^{\dagger
}W^{-1}x\right) ^{-1}x^{\dagger }W^{-1}x\right) \beta =0$

\begin{equation*}
\therefore \hat{\beta}=\left( x^{\dagger }W^{-1}x\right) ^{-1}x^{\dagger
}W^{-1}%
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
\quad \#
\end{equation*}%
\begin{equation*}
Cov\left( \hat{\beta}\right) =\left( x^{\dagger }W^{-1}x\right)
^{-1}x^{\dagger }W^{-1}\sigma ^{2}WW^{-1}x\left( x^{\dagger }W^{-1}x\right)
^{-1}=\left( x^{\dagger }W^{-1}x\right) ^{-1}\sigma ^{2}
\end{equation*}%
\begin{eqnarray*}
R_{3}\left( \hat{\beta},\beta \right) &=&E\left[ \left( Y-x\hat{\beta}%
\right) ^{\dagger }W^{-1}\left( Y-x\hat{\beta}\right) \right] \\
&=&\sigma ^{2}tr\left\{ W^{-1}\left( I-x\hat{C}\right) W\left( I-x\hat{C}%
\right) ^{\dagger }\right\} \\
&=&\sigma ^{2}tr\left\{ W^{-1}\left( I-x\text{\c{S}}^{-1}x^{\dagger
}W^{-1}\right) W\left( I-x\text{\c{S}}^{-1}x^{\dagger }W^{-1}\right)
^{\dagger }\right\} \\
&=&\sigma ^{2}tr\left\{ I-W^{-1}x\text{\c{S}}^{-1}x^{\dagger }W^{-1}W+W^{-1}x%
\text{\c{S}}^{-1}x^{\dagger }W^{-1}W\left( x\text{\c{S}}^{-1}x^{\dagger
}W^{-1}\right) ^{\dagger }-\right. \\
&&\left. W^{-1}W\left( x\text{\c{S}}^{-1}x^{\dagger }W^{-1}\right) ^{\dagger
}\right\} \\
&=&\sigma ^{2}tr\left\{ I-W^{-1}x\text{\c{S}}^{-1}x^{\dagger }+W^{-1}x\text{%
\c{S}}^{-1}\underset{\text{\c{S}}}{\underbrace{x^{\dagger }W^{-1}x}}\text{%
\c{S}}^{-1}x^{\dagger }-W^{-1}x\text{\c{S}}^{-1}x^{\dagger }\right\} \\
&=&\sigma ^{2}tr\left\{ I+W^{-1}x\text{\c{S}}^{-1}x^{\dagger }-2W^{-1}x\text{%
\c{S}}^{-1}x^{\dagger }\right\} \\
&=&\sigma ^{2}tr\left\{ I_{n}-W^{-1}x\text{\c{S}}^{-1}x^{\dagger }\right\} \\
&=&\sigma ^{2}\left( n-k\right)
\end{eqnarray*}%
\begin{equation*}
\left[ tr\left\{ W^{-1}x\left( x^{\dagger }W^{-1}x\right) x^{\dagger
}\right\} =tr\left\{ x^{\dagger }W^{-1}x\left( x^{\dagger }W^{-1}x\right)
\right\} =tr\left\{ I_{k}\right\} =k\right]
\end{equation*}

\bigskip

\bigskip

\paragraph{Aitken Estimator (in fact is the weight LSE)}

\quad

\bigskip

W=W$^{\frac{1}{2}}$W$^{\frac{1}{2}}$, W$^{-1}=$W$^{-\frac{1}{2}}$W$^{-\frac{1%
}{2}}$

$Y=x\beta +\varepsilon \quad E\left( \varepsilon \right) =0\quad Var\left(
\varepsilon \right) =\sigma ^{2}W$

\begin{equation*}
W^{-\frac{1}{2}}Y=W^{-\frac{1}{2}}x\beta +W^{-\frac{1}{2}}\varepsilon
\Rightarrow \tilde{Y}=\tilde{x}\beta +\tilde{\varepsilon}\quad E\left( 
\tilde{\varepsilon}\right) =0\quad Cov\left( \tilde{\varepsilon}\right)
=\sigma ^{2}I
\end{equation*}%
\begin{equation*}
\hat{\beta}=\left( \tilde{x}^{\dagger }\tilde{x}\right) ^{-1}\tilde{x}%
^{\dagger }\tilde{Y}=\left( \tilde{x}^{\dagger }W^{-\frac{1}{2}}W^{-\frac{1}{%
2}}\tilde{x}\right) ^{-1}\tilde{x}^{\dagger }W^{-\frac{1}{2}}W^{-\frac{1}{2}}%
\tilde{Y}=\left( x^{\dagger }W^{-1}x\right) ^{-1}x^{\dagger }W^{-1}Y
\end{equation*}%
\begin{equation*}
E\left( \hat{\beta}\right) =\left( x^{\dagger }W^{-1}x\right)
^{-1}x^{\dagger }W^{-1}E\left( Y\right) =\left( x^{\dagger }W^{-1}x\right)
^{-1}x^{\dagger }W^{-1}x\beta =\beta
\end{equation*}

Consider $\hat{\beta}$ is linear unbiased of $\beta $ (i.e. $\left(
x^{\dagger }\beta ^{-1}x\right) ^{-1}x^{\dagger }\beta ^{-1}Y$)

want to Cov$\left( \tilde{\beta}\right) \geq Cov\left( \hat{\beta}\right) $,
where $\tilde{\beta}=\tilde{C}Y$%
\begin{equation*}
E\left( \tilde{\beta}\right) =E\left( \tilde{C}Y\right) =E\left( \left( \hat{%
C}+D\right) Y\right) =E\left( \hat{C}Y\right) +E\left( DY\right) =\beta
\quad \forall \beta
\end{equation*}%
\begin{equation*}
\left[ \hat{C}=\text{\c{S}}^{-1}x^{\dagger }W^{-1}\right]
\end{equation*}%
\begin{equation*}
\Rightarrow \beta +DE\left( Y\right) =\beta +Dx\beta =\beta \quad
\Rightarrow Dx=0\quad \left( D\perp x\right)
\end{equation*}%
\begin{equation*}
Cov\left( \tilde{\beta}\right) =Cov\left( \left( \hat{C}+D\right) Y\right)
=\left( \hat{C}+D\right) \sigma ^{2}W\left( \hat{C}+D\right) ^{\dagger }
\end{equation*}%
\begin{equation*}
=\sigma ^{2}\left( \hat{C}W\hat{C}^{\dagger }+DWD^{\dagger }+\hat{C}%
WD^{\dagger }+DW\hat{C}^{\dagger }\right)
\end{equation*}%
\begin{equation*}
=\sigma ^{2}\left( \hat{C}W\hat{C}^{\dagger }+DWD^{\dagger }\right) \geq
Cov\left( \hat{\beta}\right) =\sigma ^{2}\text{\c{S}}^{-1}
\end{equation*}

\bigskip

\begin{theorem}[Gauss-Markov-Aitken]
If $Y=x\beta +\varepsilon \quad 
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
\symbol{126}N\left( 0,\sigma ^{2}W\right) $, the Generalized least-square
estimator(GLSE) $\hat{\beta}=\left( x^{\dagger }W^{-1}x\right)
^{-1}x^{\dagger }W^{-1}Y$ is BLUE for $\beta ,$ $Var\left( \hat{\beta}%
\right) =\left( x^{\dagger }W^{-1}x\right) ^{-1}\sigma ^{2}$
\end{theorem}

\bigskip

\paragraph{Misspecification of the Dispersion matrix}

\quad

\bigskip

If W is matrix as A, the we have%
\begin{equation*}
\hat{\beta}^{\ast }=\left( x^{\dagger }A^{-1}x\right) ^{-1}x^{\dagger
}A^{-1}Y
\end{equation*}%
(missread W as A).

\bigskip

Note: $\hat{\beta}^{\ast }$ is unbiased, since $E\left( \hat{\beta}^{\ast
}\right) =\left( x^{\dagger }A^{-1}x\right) ^{-1}x^{\dagger }A^{-1}x\beta
=\beta $. Meaning missreading W does not affect bias.

$Cov\left( \hat{\beta}^{\ast }\right) =\left( x^{\dagger }A^{-1}x\right)
^{-1}x^{\dagger }A^{-1}Cov\left( Y\right) A^{-1}x\left( x^{\dagger
}A^{-1}x\right) ^{-1}$

\bigskip

Since $Cov\left( \hat{\beta}^{\ast }\right) -Cov\left( \hat{\beta}\right)
=\left( x^{\dagger }A^{-1}x\right) ^{-1}x^{\dagger }A^{-1}Cov\left( Y\right)
A^{-1}x\left( x^{\dagger }A^{-1}x\right) ^{-1}-\left( x^{\dagger
}A^{-1}x\right) ^{-1}\sigma ^{2}$%
\begin{equation*}
\underset{\text{by A.41(ri)}}{=}\left\{ \sigma ^{2}\left( x^{\dagger
}A^{-1}x\right) ^{-1}x^{\dagger }A^{-1}-\left( x^{\dagger }W^{-1}x\right)
^{-1}x^{\dagger }W^{-1}\right\} \times
\end{equation*}%
\begin{equation*}
W\left\{ \left( x^{\dagger }A^{-1}x\right) ^{-1}x^{\dagger }A^{-1}-\left(
x^{\dagger }W^{-1}x\right) ^{-1}x^{\dagger }W^{-1}\right\} ^{\dagger }\geq 0
\end{equation*}

\bigskip

If the OLS(i.e. $\hat{\beta}_{0}=\left( x^{\dagger }x^{-1}\right) x^{\dagger
}Y$) is mistakenly instead of the true GLSE $\hat{\beta}_{1}$

\begin{itemize}
\item If take A=I $\hat{\beta}^{\ast }=\hat{\beta}_{OLS}$%
\begin{equation*}
\Rightarrow Cov\left( \hat{\beta}_{OLS}\right) -Cov\left( \hat{\beta}\right)
=\sigma ^{2}\left\{ \left( x^{\dagger }x\right) ^{-1}x^{\dagger }-\left(
x^{\dagger }W^{-1}x\right) ^{-1}x^{\dagger }W^{-1}\right\}
\end{equation*}%
\begin{equation*}
W\left\{ \left( x^{\dagger }x\right) ^{-1}x^{\dagger }-\left( x^{\dagger
}W^{-1}x\right) ^{-1}x^{\dagger }W^{-1}\right\} ^{\dagger }
\end{equation*}%
Let $\left( x^{\dagger }x\right) ^{-1}=U$%
\begin{equation*}
\Rightarrow Cov\left( \hat{\beta}_{OLS}\right) -Cov\left( \hat{\beta}\right)
=\sigma ^{2}\left\{ Ux^{\dagger }-\left( x^{\dagger }W^{-1}x\right)
^{-1}x^{\dagger }W^{-1}\right\} W\left\{ xU-W^{-1}x\left( x^{\dagger
}W^{-1}x\right) ^{-1}\right\}
\end{equation*}%
\begin{equation*}
\Rightarrow Cov\left( \hat{\beta}_{OLS}\right) -Cov\left( \hat{\beta}\right)
=0
\end{equation*}%
wrongly estimated but accuracy the same%
\begin{equation*}
\Leftrightarrow Ux^{\dagger }=\left( x^{\dagger }W^{-1}x\right)
^{-1}x^{\dagger }W^{-1}\ldots \left( \ast \right)
\end{equation*}%
\begin{equation*}
\Leftrightarrow Ux^{\dagger }W=\left( x^{\dagger }W^{-1}x\right)
^{-1}x^{\dagger }\ldots \left( \ast \ast \right)
\end{equation*}
\end{itemize}

\bigskip

Let Z be a matrix of maximum rank s.t. $Z^{\dagger }x=0$

from (*) $\ Ux^{\dagger }WZ=\left( x^{\dagger }W^{-1}x\right)
^{-1}x^{\dagger }Z=0\Leftrightarrow \left( x^{\dagger }WZ\right) =0$

from (*) $\ Ux^{\dagger }Z=\left( x^{\dagger }W^{-1}x\right) ^{-1}x^{\dagger
}W^{-1}Z=0\Leftrightarrow \left( x^{\dagger }W^{-1}Z\right) =0$

\begin{itemize}
\item 
\begin{enumerate}
\item Note that Z$^{\dagger }x=0\Rightarrow $ x and Z span the whole n-space%
\begin{equation*}
\Rightarrow W_{nxn}^{\frac{1}{2}}=xA_{1}+ZB_{1}
\end{equation*}%
\begin{eqnarray*}
W &=&W^{\frac{1}{2}}W^{\frac{1}{2}}=\left( xA_{1}+ZB_{1}\right) \left(
xA_{1}+ZB_{1}\right) ^{\dagger } \\
&=&xA_{1}A_{1}^{\dagger }x^{\dagger }+xA_{1}B_{1}^{\dagger }Z^{\dagger
}+ZB_{1}A_{1}^{\dagger }x^{\dagger }+ZB_{1}B_{1}^{\dagger }Z^{\dagger
}\qquad \left( \triangle \right)
\end{eqnarray*}%
now $x^{\dagger }WZ=0\Rightarrow x^{\dagger }\left[ xA_{1}A_{1}^{\dagger
}x^{\dagger }+xA_{1}B_{1}^{\dagger }Z^{\dagger }+ZB_{1}A_{1}^{\dagger
}x^{\dagger }+ZB_{1}B_{1}^{\dagger }Z^{\dagger }\right] Z=0$%
\begin{equation*}
\because x^{\dagger }Z=0\Rightarrow \underset{\text{non-singular}}{%
\underbrace{x^{\dagger }x}}A_{1}B_{1}^{\dagger }\underset{\text{non-singular}%
}{\underbrace{Z^{\dagger }Z}}=0\Rightarrow A_{1}B_{1}^{\dagger }=0
\end{equation*}%
from ($\triangle $) and $A_{1}B_{1}^{\dagger }\Rightarrow
W=xA_{1}A_{1}^{\dagger }x^{\dagger }+ZB_{1}B_{1}^{\dagger }Z^{\dagger
}=xA_{1}x^{\dagger }+ZB_{1}Z^{\dagger }$, (A,B are nonsingular)
\end{enumerate}
\end{itemize}

\bigskip

\begin{example}
$x=\left[ \boldsymbol{1},x_{1}\right] $ the the choice $W=\left( 1-\sigma
\right) I+\sigma \boldsymbol{11}^{\dagger }\quad \left( 0<\sigma <1\right) $%
\begin{equation*}
x^{\dagger }WZ=x^{\dagger }\left[ \left( 1-\sigma \right) I+\sigma 
\boldsymbol{11}^{\dagger }\right] Z=\left( 1-\sigma \right) \underset{=0}{%
\underbrace{x^{\dagger }Z}}+\sigma \underset{=0}{\underbrace{x^{\dagger }%
\boldsymbol{11}^{\dagger }Z}}=0
\end{equation*}%
\begin{equation*}
\Rightarrow \text{GLSE }\left( W=\left( 1-\sigma \right) I+\sigma 
\boldsymbol{11}^{\dagger }\right) \text{ and OLSE }(W=A=I)\text{ are equal}
\end{equation*}
\end{example}

\bigskip

$Y=x\beta +%
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
\quad Cov\left( 
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
\right) =\sigma ^{2}W\quad \frac{\left( Y-x\hat{\beta}\right) ^{\dagger
}W^{-1}\left( Y-x\hat{\beta}\right) }{n-k}\leadsto \sigma ^{2}$

Note: missread W makes $Var\left( \hat{\beta}_{i}\right) $ larger, then $%
\frac{\tilde{\beta}}{\sqrt{Var\left( \tilde{\beta}\right) }}$ becomes
smaller, ......??

Note:%
\begin{equation*}
\left( 
\begin{array}{ccc}
1 &  & \sigma \\ 
& \ddots &  \\ 
\sigma &  & 1%
\end{array}%
\right) x=\lambda x\quad x=\left[ 
\begin{array}{c}
1 \\ 
\vdots \\ 
1%
\end{array}%
\right]
\end{equation*}%
eigenvalue and =n$\Rightarrow \tsum \lambda _{i}=n$. $1+\left( n+1\right)
\sigma >0\Rightarrow \sigma >-\frac{1}{n-1}$ (n-1 multiple roots)

\bigskip

\paragraph{Estimating $\protect\sigma ^{2}$ if misspecifity W}

\quad

\bigskip

Assume that A is choosen instead of W%
\begin{equation*}
%TCIMACRO{%
%\TeXButton{underaccent_epsilon_hat}{\underaccent{\wtilde}{\hat{\epsilon}}}}%
%BeginExpansion
\underaccent{\wtilde}{\hat{\epsilon}}%
%EndExpansion
=%
%TCIMACRO{\TeXButton{underaccent_e}{\underaccent{\wtilde}{e}}}%
%BeginExpansion
\underaccent{\wtilde}{e}%
%EndExpansion
=Y-x\tilde{\beta}=\left[ I-x\left( x^{\dagger }A^{-1}x\right)
^{-1}x^{\dagger }A^{-1}\right] Y
\end{equation*}%
\begin{eqnarray*}
&=&\left[ I-x\left( x^{\dagger }A^{-1}x\right) ^{-1}x^{\dagger }A^{-1}\right]
\left( x\beta +\varepsilon \right) \\
&=&x\beta -x\left( x^{\dagger }A^{-1}x\right) ^{-1}x^{\dagger }A^{-1}x\beta
+\varepsilon -x\left( x^{\dagger }A^{-1}x\right) ^{-1}x^{\dagger
}A^{-1}\varepsilon \\
&=&\left[ I-x\left( x^{\dagger }A^{-1}x\right) ^{-1}x^{\dagger }A^{-1}\right]
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
\end{eqnarray*}%
\begin{equation*}
\because E\left[ \left( Y-x\hat{\beta}\right) ^{\dagger }W^{-1}\left( Y-x%
\hat{\beta}\right) \right] =\left( n-k\right) \sigma ^{2}\Rightarrow \frac{%
\left( Y-x\hat{\beta}\right) ^{\dagger }W^{-1}\left( Y-x\hat{\beta}\right) }{%
n-k}\leadsto \sigma ^{2}
\end{equation*}%
\begin{equation*}
\frac{e^{\dagger }A^{-1}e}{n-k}=\tilde{\sigma}^{2}
\end{equation*}%
\begin{equation*}
E\left( \tilde{\sigma}^{2}\right) =\sigma ^{2}+\frac{1}{n-k}\left\{
tr\left\{ \sigma ^{2}x\left( x^{\dagger }A^{-1}x\right) ^{-1}x^{\dagger
}A^{-1}\left( I-2W\right) \right\} +tr\left\{ xCov\left( \tilde{\beta}%
\right) x^{\dagger }\right\} \right\}
\end{equation*}

If A=I%
\begin{equation*}
E\left( \tilde{\sigma}^{2}\right) =\sigma ^{2}+\frac{\sigma ^{2}}{n-k}%
\left\{ k-tr\left\{ \left( x^{\dagger }x\right) ^{-1}x^{\dagger }Wx\right\}
\right\} <0\quad \text{meaning parameter underestimate}
\end{equation*}%
Even if paramater are obvious, the result is not obvious

\begin{equation*}
E\left( \tilde{\sigma}^{2}\right) =E\left( \frac{e^{\dagger }A^{-1}e}{n-k}%
\right) =\frac{1}{n-k}E\left( 
%TCIMACRO{\TeXButton{underaccent_e}{\underaccent{\wtilde}{e}}}%
%BeginExpansion
\underaccent{\wtilde}{e}%
%EndExpansion
^{\dagger }A^{-1}%
%TCIMACRO{\TeXButton{underaccent_e}{\underaccent{\wtilde}{e}}}%
%BeginExpansion
\underaccent{\wtilde}{e}%
%EndExpansion
\right)
\end{equation*}%
\begin{equation*}
%TCIMACRO{\TeXButton{underaccent_e}{\underaccent{\wtilde}{e}}}%
%BeginExpansion
\underaccent{\wtilde}{e}%
%EndExpansion
=\left[ I-x\left( x^{\dagger }A^{-1}x\right) ^{-1}x^{\dagger }A^{-1}\right] 
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
\end{equation*}

\bigskip

\paragraph{Heteroccdasticity and Autoregression}

\quad

\bigskip

December 8 (monday)

\begin{itemize}
\item $E\left( 
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
\right) =%
%TCIMACRO{\TeXButton{underaccent_o}{\underaccent{\wtilde}{o}}}%
%BeginExpansion
\underaccent{\wtilde}{o}%
%EndExpansion
\quad Cov\left( 
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
^{\dagger }\right) =\sigma ^{2}W=\sigma ^{2}\left[ 
\begin{array}{ccc}
k_{1} &  & 0 \\ 
& \ddots &  \\ 
0 &  & k_{n}%
\end{array}%
\right] $%
\begin{equation*}
GLSE\quad \hat{\beta}=\left( x^{\dagger }W^{-1}x\right) ^{-1}x^{\dagger
}W^{-1}Y=\left( \tsum 
%TCIMACRO{\TeXButton{underaccent_x}{\underaccent{\wtilde}{x}}}%
%BeginExpansion
\underaccent{\wtilde}{x}%
%EndExpansion
_{i}%
%TCIMACRO{\TeXButton{underaccent_x}{\underaccent{\wtilde}{x}}}%
%BeginExpansion
\underaccent{\wtilde}{x}%
%EndExpansion
_{i}^{\dagger }\right) ^{-1}\left( \tsum 
%TCIMACRO{\TeXButton{underaccent_x}{\underaccent{\wtilde}{x}}}%
%BeginExpansion
\underaccent{\wtilde}{x}%
%EndExpansion
_{i}%
%TCIMACRO{\TeXButton{underaccent_x}{\underaccent{\wtilde}{x}}}%
%BeginExpansion
\underaccent{\wtilde}{x}%
%EndExpansion
_{i}^{\dagger }\right)
\end{equation*}%
x$^{\dagger }=\left( 
%TCIMACRO{\TeXButton{underaccent_x}{\underaccent{\wtilde}{x}}}%
%BeginExpansion
\underaccent{\wtilde}{x}%
%EndExpansion
_{1},\cdots ,%
%TCIMACRO{\TeXButton{underaccent_x}{\underaccent{\wtilde}{x}}}%
%BeginExpansion
\underaccent{\wtilde}{x}%
%EndExpansion
_{n}\right) $
\end{itemize}

\bigskip

example: $y_{i}=\alpha +\beta x_{i}+\varepsilon _{i}\quad Var\left(
\varepsilon _{i}\right) =\sigma ^{2}x_{i}^{2}\quad W=diag\left\{
x_{1}^{2},\cdots ,x_{n}^{2}\right\} $

\begin{itemize}
\item We don't have the original sample $%
%TCIMACRO{\TeXButton{underaccent_y}{\underaccent{\wtilde}{y}}}%
%BeginExpansion
\underaccent{\wtilde}{y}%
%EndExpansion
$ and x, but we have the sample mean $\bar{Y}_{i}=\frac{1}{n_{i}}%
\tsum\limits_{j=1}^{n}y_{j}\quad \bar{x}_{ik}=\frac{1}{n_{i}}%
\tsum\limits_{j=1}^{n_{i}}x_{jk}$%
\begin{equation*}
\bar{Y}_{i}=\beta _{0}+\beta _{1}\bar{x}+\varepsilon _{i}\quad Var\left( 
\bar{Y}_{i}\right) =\frac{\sigma ^{2}}{n_{i}}
\end{equation*}
\end{itemize}

\bigskip

More general situation%
\begin{equation*}
\begin{array}{ccc}
\text{Y}_{i}\text{ continuous:} & \text{normal regression} &  \\ 
Y_{i}\text{ discrete:} & \text{poission regression} & \ast \\ 
& \text{logistic regression} & \ast%
\end{array}%
\end{equation*}%
* $link\left( 
%TCIMACRO{\TeXButton{underaccent_mu}{\underaccent{\wtilde}{\mu}}}%
%BeginExpansion
\underaccent{\wtilde}{\mu}%
%EndExpansion
\right) =x\beta $ is a ?? function

\bigskip

\begin{itemize}
\item The disturbance of followers the so-called process of intral class
correllation $\varepsilon _{j}=V_{j}+u_{tj}$, t=1\symbol{126}m, j=1\symbol{%
126}n
\end{itemize}

\bigskip

Note: The disturbance V$_{j}$ are identical for the m realization modeling $%
\varepsilon _{i}\quad E\left( V_{j}\right) =\sigma _{v}^{2}$, j=1\symbol{126}%
n, $Cov\left( V_{j},V_{j^{\prime }}\right) =0$, $j\neq j^{\prime }$ of each
of the n individ%
\begin{equation*}
E\left( u_{tj}\right) =0\quad Var\left( u_{tj}\right) =\sigma _{u}^{2}\quad
Cov\left( u_{tj},u_{tj^{\prime }}\right) =0\quad \left( t,j\right) \neq
\left( t,j^{\prime }\right)
\end{equation*}%
\begin{equation*}
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
_{mn\times 1}=\left[ 
\begin{array}{c}
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
_{1} \\ 
\vdots \\ 
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
_{n}%
\end{array}%
\right]
\end{equation*}%
\begin{equation*}
E\left( 
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
^{\dagger }\right) =diag\left( \Phi ,\cdots ,\Phi \right) =\left[ 
\begin{array}{ccc}
\Phi &  &  \\ 
& \ddots &  \\ 
&  & \Phi%
\end{array}%
\right]
\end{equation*}%
\begin{equation*}
\Phi _{mxm}=E\left( 
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
_{j}%
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
_{j}^{\dagger }\right) =\left\{ E\left( 
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
_{tj}%
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
_{t^{\prime }j}^{\dagger }\right) \right\}
\end{equation*}%
\begin{equation*}
=\left\{ E\left( V_{j}+u_{tj}\right) \left( V_{j}+u_{t^{\prime }j}\right)
^{\dagger }\right\} =\left\{ E\left( V_{j}^{2}\right) \right\}
\end{equation*}%
\begin{equation*}
=\left\{ 
\begin{array}{c}
\sigma _{v}^{2},\quad t\neq t^{\prime } \\ 
E\left( V_{j}^{2}\right) +E\left( u_{tj}^{2}\right) =\sigma _{v}^{2}+\sigma
_{u}^{2},\quad t\neq t^{\prime }%
\end{array}%
\right.
\end{equation*}%
\begin{equation*}
=\left[ 
\begin{array}{ccc}
\sigma _{v}^{2}+\sigma _{u}^{2} &  & \sigma _{v}^{2} \\ 
& \ddots &  \\ 
\sigma _{v}^{2} &  & \sigma _{v}^{2}+\sigma _{u}^{2}%
\end{array}%
\right] =\sigma ^{2}\left[ 
\begin{array}{ccc}
1 &  & \rho \\ 
& \ddots &  \\ 
\rho &  & 1%
\end{array}%
\right]
\end{equation*}%
(equal correlation)%
\begin{equation*}
\sigma ^{2}=\sigma _{v}^{2}+\sigma _{u}^{2}\quad \rho =\frac{\sigma _{v}^{2}%
}{\sigma _{v}^{2}+\sigma _{u}^{2}}
\end{equation*}

\bigskip

\paragraph{Autoregressive Disturbance}

\quad

\bigskip

Assume $\left\{ u_{t}\right\} \left( t=\cdots ,-2,-1,0,1,2,\cdots \right) $
be an random process $E\left( u_{t}\right) =0\quad E\left( u_{t}^{2}\right)
=\sigma _{u}^{2}\quad Cov\left( u_{t},u_{t^{\prime }}\right) =0\quad \forall
t\neq t^{\prime }$%
\begin{equation*}
V_{t}-\mu =\rho \left( V_{t-1}-\mu \right) \quad \left\vert \rho \right\vert
<1\quad \left( \mu =0,\quad V_{t}=V_{t-1}+u_{t}\right)
\end{equation*}%
repeated subsitute%
\begin{eqnarray*}
V_{t}-\mu &=&\rho \left( V_{t-1}-\mu \right) +u_{t} \\
&=&\rho \left( \rho \left( V_{t-2}-\mu \right) +u_{t-1}\right) +u_{t} \\
&=&\cdots =\tsum\limits_{s=0}^{\infty }\rho ^{s}u_{t-s}
\end{eqnarray*}%
\begin{equation*}
E\left( V_{t}\right) =\mu +E\left( \tsum\limits_{s=0}^{\infty }\rho
^{s}u_{t-s}\right) =\mu +\tsum\limits_{s=0}^{\infty }\rho ^{s}E\left(
u_{t-s}\right) =\mu
\end{equation*}%
\begin{equation*}
E\left( V_{t}-\mu \right) ^{2}=E\left( \tsum\limits_{s=0}^{\infty }\rho
^{s}u_{t-s}\right) ^{2}=\tsum\limits_{s=0}^{\infty
}\tsum\limits_{r=0}^{\infty }\rho ^{s+r}E\left( u_{t-s}u_{t-r}\right)
\end{equation*}%
\begin{eqnarray*}
&=&\tsum\limits_{s=0}^{\infty }\rho ^{2s}E\left( u_{t-s}^{2}\right) \\
&=&\sigma _{u}^{2}\tsum\limits_{s=0}^{\infty }\rho ^{2s} \\
&=&\sigma _{u}^{2}\frac{1}{1-\rho ^{2}}=\sigma ^{2}
\end{eqnarray*}%
\begin{equation*}
E\left[ \left( V_{t}-\mu \right) \left( V_{t-k}-\mu \right) \right] =E\left[
\left( \tsum\limits_{s=0}^{\infty }\rho ^{s}E\left( u_{t-s}\right) \right)
\left( \tsum\limits_{r=0}^{\infty }\rho ^{r}E\left( u_{t-k-r}\right) \right) %
\right]
\end{equation*}%
\begin{equation*}
\begin{array}{c}
\text{if }k+r=S\text{ then }E\left[ u_{t-s}u_{t-k-r}\right] =E\left(
u_{t-s}^{2}\right) \\ 
\text{if }k+r\neq S\text{ then }E\left[ u_{t-s}u_{t-k-r}\right] =0%
\end{array}%
\end{equation*}%
\begin{eqnarray*}
&\therefore &E\left[ \left( V_{t}-\mu \right) \left( V_{t-k}-\mu \right) %
\right] =\left( \tsum\limits_{r=0}^{\infty }\rho ^{2r+k}E\left(
u_{t-k-r}^{2}\right) \right) \\
&=&\sigma _{u}^{2}\tsum\limits_{r=0}^{\infty }\rho ^{2r+k} \\
&=&\sigma _{u}^{2}\frac{\rho ^{k}}{1-\rho ^{2}}=\sigma ^{2}\rho ^{k}
\end{eqnarray*}%
\begin{equation*}
E\left[ \left( V_{t}-\mu \right) ^{2}\right] =\sigma ^{2}=Var\left(
V_{t-k}\right)
\end{equation*}%
\begin{equation*}
Cov\left( 
%TCIMACRO{\TeXButton{underaccent_V}{\underaccent{\wtilde}{V}}}%
%BeginExpansion
\underaccent{\wtilde}{V}%
%EndExpansion
\right) =\sigma ^{2}\left[ 
\begin{array}{ccccc}
1 & \sigma & \sigma ^{2} & \cdots & \sigma ^{n-1} \\ 
& 1 & \sigma &  &  \\ 
&  & \ddots & \sigma & \vdots \\ 
&  &  & 1 & \sigma \\ 
&  &  &  & 1%
\end{array}%
\right] =\sigma ^{2}W
\end{equation*}%
\begin{equation*}
W^{-1}=\frac{1}{1-\rho ^{2}}\left[ 
\begin{array}{ccccc}
1 & -\rho &  &  &  \\ 
& 1+\rho ^{2} & -\rho &  &  \\ 
&  & \ddots & -\rho &  \\ 
&  &  & 1+\rho ^{2} & -\rho \\ 
&  &  &  & 1%
\end{array}%
\right]
\end{equation*}

If $V_{t}-\mu =\rho \left( V_{t-1}-\mu \right) +\mu _{t}$ how to examine the
existence of $\rho $, how to estimate?

\bigskip

\paragraph{Testing Autoregression}

\begin{equation*}
H_{0}=\rho =0
\end{equation*}

\end{document}
