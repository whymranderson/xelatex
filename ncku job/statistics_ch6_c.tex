
\documentclass{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{accents}
\usepackage[ignoreall,a4paper]{geometry}
\usepackage{fancyhdr}

\setcounter{MaxMatrixCols}{10}
%TCIDATA{OutputFilter=LATEX.DLL}
%TCIDATA{Version=5.00.0.2606}
%TCIDATA{<META NAME="SaveForMode" CONTENT="1">}
%TCIDATA{BibliographyScheme=Manual}
%TCIDATA{Created=Wednesday, November 25, 2015 15:33:37}
%TCIDATA{LastRevised=Wednesday, December 23, 2015 11:53:57}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{<META NAME="DocumentShell" CONTENT="Standard LaTeX\Blank - Standard LaTeX Article">}
%TCIDATA{CSTFile=40 LaTeX article.cst}
%TCIDATA{ComputeDefs=
%$W=\left( 1-\sigma \right) I$
%}


\newtheorem{theorem}{Theorem}
\newtheorem{acknowledgement}[theorem]{Acknowledgement}
\newtheorem{algorithm}[theorem]{Algorithm}
\newtheorem{axiom}[theorem]{Axiom}
\newtheorem{case}[theorem]{Case}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conclusion}[theorem]{Conclusion}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{criterion}[theorem]{Criterion}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{solution}[theorem]{Solution}
\newtheorem{summary}[theorem]{Summary}
\newenvironment{proof}[1][Proof]{\noindent\textbf{#1.} }{\ \rule{0.5em}{0.5em}}
\input{../tcilatex}
\DeclareMathAccent{\wtilde}{\mathord}{largesymbols}{"65}
\pagestyle{fancy}
\fancyfoot[C]{\thepage}

\input{tcilatex}

\begin{document}


\setcounter{part}{5} \setcounter{page}{28}

\begin{problem}
When $x_{\ast }\beta $-superiority implies $Y_{\ast }$-superiority vise versa
\end{problem}

This is, when%
\begin{equation*}
M\left( P_{1},Y_{\ast }\right) -M\left( P_{2},Y_{\ast }\right) =M\left(
P_{1},x_{\ast }\beta \right) -M\left( P_{2},x_{\ast }\beta \right)
\end{equation*}

\begin{equation*}
\Rightarrow Var\left( P_{1}\right) -Var\left( P_{2}\right) -\left[ Cov\left(
P_{1},Y_{\ast }\right) +Cov\left( Y_{\ast },P_{1}\right) -Cov\left(
P_{2},Y_{\ast }\right) -Cov\left( Y_{\ast },P_{2}\right) \right]
\end{equation*}%
\begin{equation*}
+d_{1\ast }d_{2\ast }^{\dagger }-d_{1\ast }d_{2\ast }^{\dagger }=Var\left(
P_{1}\right) -Var\left( P_{2}\right) +\left[ d_{1\ast }d_{1\ast }^{\dagger
}-d_{2\ast }d_{2\ast }^{\dagger }\right]
\end{equation*}

\begin{equation*}
\Rightarrow Cov\left( P_{1},Y_{\ast }\right) +Cov\left( Y_{\ast
},P_{1}\right) =Cov\left( P_{2},Y_{\ast }\right) +Cov\left( Y_{\ast
},P_{2}\right)
\end{equation*}

\begin{equation*}
\left[ P_{1}=C_{1}x+d_{1}\quad P_{2}=C_{2}x+d_{2}\right]
\end{equation*}%
\begin{equation*}
\Rightarrow C_{1}W_{0}+W_{0}^{\dagger }C_{1}^{\dagger
}=C_{2}W_{0}+W_{0}^{\dagger }C_{2}^{\dagger }
\end{equation*}%
\begin{equation*}
\Rightarrow W_{0}=0\text{, condition holds, even when now and futre are not
related.}
\end{equation*}

\bigskip

\begin{theorem}
Suppose $E\left( 
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
_{\ast }%
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
_{\ast }^{\dagger }\right) =W_{0}=0$ and let $%
%TCIMACRO{\TeXButton{underaccent_P}{\underaccent{\wtilde}{P}}}%
%BeginExpansion
\underaccent{\wtilde}{P}%
%EndExpansion
_{1}$ and $%
%TCIMACRO{\TeXButton{underaccent_P}{\underaccent{\wtilde}{P}}}%
%BeginExpansion
\underaccent{\wtilde}{P}%
%EndExpansion
_{2}$ be two predictors. Then the following conditions are equivalent for
competing predctions:

\begin{enumerate}
\item $M\left( P_{1},Y_{\ast }\right) -M\left( P_{2},Y_{\ast }\right) \geq 0$

\item $M\left( P_{1},x_{\ast }\beta \right) -M\left( P_{2},x_{\ast }\beta
\right) \geq 0$

\item $R_{A}\left( P_{1},Y_{\ast }\right) -R_{A}\left( P_{2},Y_{\ast
}\right) \geq 0\quad ,\quad \forall A\geq 0$

\item $R_{A}\left( P_{1},x_{\ast }\beta \right) -R_{A}\left( P_{2},x_{\ast
}\beta \right) \geq 0\quad ,\quad \forall A\geq 0$
\end{enumerate}
\end{theorem}

\begin{proof}
($P_{1}=C_{1}x+d_{1}\quad P_{2}=C_{2}x+d_{2}$)%
\begin{equation*}
R_{A}\left( P_{1},x_{\ast }\beta \right) =tr\left\{ A\left[ \left(
C_{1}x-x_{\ast }\right) \beta +d_{1}\right] \left[ \left( C_{1}x-x_{\ast
}\right) \beta +d_{1}\right] ^{\dagger }\right\} +
\end{equation*}%
\begin{equation*}
\sigma ^{2}tr\left\{ A\left( C_{1}WC_{1}^{\dagger }+W_{\ast
}-C_{1}W_{0}-W_{0}^{\dagger }C_{1}^{\dagger }\right) \right\}
\end{equation*}%
\begin{equation*}
\left[ R_{A}\left( P_{1},x_{\ast }\beta \right) =E\left[ \left(
P_{1}-Y_{\ast }\right) ^{\dagger }A\left( P_{1}-Y_{\ast }\right) \right] %
\right]
\end{equation*}%
\begin{equation*}
=tr\left\{ A\left[ Var\left( P_{1}-Y_{\ast }\right) +d_{1\ast }d_{1\ast
}^{\dagger }\right] \right\}
\end{equation*}%
\begin{equation*}
=tr\left\{ AM\left( P_{1}-Y_{\ast }\right) \right\} \quad \left( R_{A}\left(
P_{1},Y_{\ast }\right) \text{ is }M\left( P_{1},Y_{\ast }\right) \text{
function}\right)
\end{equation*}%
\begin{equation*}
\left[ W_{0}=0\quad d_{\ast }=E\left( P_{1}\right) -x_{\ast }\beta =\left(
C_{1}x-x_{\ast }\right) \beta +d_{1}\right]
\end{equation*}%
\begin{equation*}
R_{A}\left( P_{1},Y_{\ast }\right) -R_{A}\left( P_{2},Y_{\ast }\right)
=tr\left\{ A\left[ M\left( P_{1},Y_{\ast }\right) -M\left( P_{2},Y_{\ast
}\right) \right] \right\} \geq 0
\end{equation*}%
\begin{equation*}
\text{iff }M\left( P_{1},Y_{\ast }\right) \geq M\left( P_{2},Y_{\ast
}\right) \quad \forall A\geq 0
\end{equation*}
\end{proof}

\bigskip

\begin{eqnarray*}
%TCIMACRO{\TeXButton{underaccent_P}{\underaccent{\wtilde}{P}}}%
%BeginExpansion
\underaccent{\wtilde}{P}%
%EndExpansion
_{0} &=&x_{\ast }\hat{\beta}\quad \text{classical} \\
%TCIMACRO{\TeXButton{underaccent_P}{\underaccent{\wtilde}{P}}}%
%BeginExpansion
\underaccent{\wtilde}{P}%
%EndExpansion
_{3} &=&x_{\ast }\hat{\beta}+W_{0}^{\dagger }W^{-1}\left( Y-x\hat{\beta}%
\right) \quad \text{optimal}
\end{eqnarray*}

\begin{eqnarray*}
%TCIMACRO{\TeXButton{underaccent_P}{\underaccent{\wtilde}{P}}}%
%BeginExpansion
\underaccent{\wtilde}{P}%
%EndExpansion
_{3} &=&x_{\ast }\hat{\beta}+W_{0}^{\dagger }W^{-1}\left( Y-x\hat{\beta}%
\right) -x_{\ast }\beta -\varepsilon _{\ast } \\
&=&\left( x_{\ast }+W_{0}^{\dagger }W^{-1}x\right) \hat{\beta}%
+W_{0}^{\dagger }W^{-1}Y-x_{\ast }\beta -\varepsilon _{\ast } \\
&=&\left( x_{\ast }+W_{0}^{\dagger }W^{-1}x\right) \hat{\beta}%
+W_{0}^{\dagger }W^{-1}\left( x\beta +\varepsilon \right) -x_{\ast }\beta
-\varepsilon _{\ast }
\end{eqnarray*}%
\begin{eqnarray*}
&=&\left( x_{\ast }+W_{0}^{\dagger }W^{-1}x\right) \hat{\beta}%
+W_{0}^{\dagger }W^{-1}x\beta +W_{0}^{\dagger }W^{-1}\varepsilon -x_{\ast
}\beta -\varepsilon _{\ast } \\
&=&\left( x_{\ast }+W_{0}^{\dagger }W^{-1}x\right) \hat{\beta}+\left(
W_{0}^{\dagger }W^{-1}x-x_{\ast }\right) \beta +W_{0}^{\dagger
}W^{-1}\varepsilon -\varepsilon _{\ast } \\
&=&\left( x_{\ast }+W_{0}^{\dagger }W^{-1}x\right) \left( \hat{\beta}-\beta
\right) +\left( W_{0}^{\dagger }W^{-1}\varepsilon -\varepsilon _{\ast
}\right) \\
&=&Z\left( \hat{\beta}-\beta \right) +\left( W_{0}^{\dagger
}W^{-1}\varepsilon -\varepsilon _{\ast }\right)
\end{eqnarray*}

\bigskip

\begin{equation*}
E\left[ \left( \hat{\beta}-\beta \right) \left( W_{0}^{\dagger
}W^{-1}\varepsilon -\varepsilon _{\ast }\right) ^{\dagger }\right] =E\left[ 
\hat{\beta}\left( W_{0}^{\dagger }W^{-1}\varepsilon -\varepsilon _{\ast
}\right) ^{\dagger }\right]
\end{equation*}%
\begin{equation*}
\left[ \hat{\beta}=\left( x^{\dagger }W^{-1}x\right) ^{-1}x^{\dagger
}W^{-1}Y=DY\right]
\end{equation*}%
\begin{equation*}
=E\left[ DY\left( W_{0}^{\dagger }W^{-1}%
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
-\varepsilon _{\ast }\right) ^{\dagger }\right]
\end{equation*}%
\begin{equation*}
=E\left[ D\left( x\beta +\varepsilon \right) \left( W_{0}^{\dagger }W^{-1}%
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
-%
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
_{\ast }\right) ^{\dagger }\right]
\end{equation*}%
\begin{equation*}
=E\left[ D\varepsilon \left( \varepsilon ^{\dagger }W^{-1}W_{0}^{\dagger
}-\varepsilon _{\ast }^{\dagger }\right) \right]
\end{equation*}%
\begin{equation*}
=E\left[ D\varepsilon \varepsilon ^{\dagger }W^{-1}W_{0}^{\dagger
}-D\varepsilon \varepsilon _{\ast }^{\dagger }\right]
\end{equation*}%
\begin{equation*}
=DE\left( \varepsilon \varepsilon ^{\dagger }\right) W^{-1}W_{0}^{\dagger
}-DE\left( \varepsilon \varepsilon _{\ast }^{\dagger }\right)
\end{equation*}%
\begin{equation*}
=DWW^{-1}W_{0}^{\dagger }-DW_{0}
\end{equation*}%
\begin{equation*}
=0\quad \text{meaning }\left( \hat{\beta}-\beta \right) \text{ and }\left(
W_{0}^{\dagger }W^{-1}\varepsilon -\varepsilon _{\ast }\right) \text{ not
related}
\end{equation*}

So that MDE of $P\left( \hat{\beta}\right) $ is $M\left( P\left( \hat{\beta}%
\right) ,Y_{\ast }\right) $

\begin{equation*}
M\left( P\left( \hat{\beta}\right) ,Y_{\ast }\right) =E\left[ \left( P\left( 
\hat{\beta}\right) -Y_{\ast }\right) \left( P\left( \hat{\beta}\right)
-Y_{\ast }\right) ^{\dagger }\right]
\end{equation*}%
\begin{equation*}
=E\left[ \left( Z\left( \hat{\beta}-\beta \right) +\left( W_{0}^{\dagger
}W^{-1}\varepsilon -\varepsilon _{\ast }\right) \right) \left( Z\left( \hat{%
\beta}-\beta \right) +\left( W_{0}^{\dagger }W^{-1}\varepsilon -\varepsilon
_{\ast }\right) \right) ^{\dagger }\right]
\end{equation*}%
\begin{equation*}
=ZE\left[ \left( \hat{\beta}-\beta \right) \left( \hat{\beta}-\beta \right)
^{\dagger }\right] Z^{\dagger }+E\left[ \left( W_{0}^{\dagger
}W^{-1}\varepsilon -\varepsilon _{\ast }\right) \left( W_{0}^{\dagger
}W^{-1}\varepsilon -\varepsilon _{\ast }\right) ^{\dagger }\right]
\end{equation*}%
\begin{equation*}
=ZM\left( \hat{\beta},\beta \right) Z^{\dagger }+\left( W_{0}^{\dagger
}W^{-1}WW^{-1}W_{0}-W_{0}^{\dagger }W^{-1}W_{0}-W_{0}W^{-1}W_{0}+W_{\ast
}\right) \sigma ^{2}
\end{equation*}%
\begin{equation*}
=ZM\left( \hat{\beta},\beta \right) Z^{\dagger }+\left( W_{\ast
}-W_{0}W^{-1}W_{0}\right) \sigma ^{2}
\end{equation*}

\bigskip

Classical Predictor

\begin{equation*}
\hat{P}_{0}=x_{\ast }\hat{\beta}\quad \hat{\beta}=D%
%TCIMACRO{\TeXButton{underaccent_y}{\underaccent{\wtilde}{y}}}%
%BeginExpansion
\underaccent{\wtilde}{y}%
%EndExpansion
+%
%TCIMACRO{\TeXButton{underaccent_d}{\underaccent{\wtilde}{d}}}%
%BeginExpansion
\underaccent{\wtilde}{d}%
%EndExpansion
\end{equation*}%
\begin{equation*}
%TCIMACRO{\TeXButton{underaccent_b}{\underaccent{\wtilde}{b}}}%
%BeginExpansion
\underaccent{\wtilde}{b}%
%EndExpansion
_{\ast }=E\left( \hat{P}_{0}\right) -x_{\ast }\beta =x_{\ast }\left( Dx\beta
+d\right) -x_{\ast }\beta
\end{equation*}%
\begin{equation*}
=x_{\ast }\left[ \left( Dx-I\right) \beta +%
%TCIMACRO{\TeXButton{underaccent_d}{\underaccent{\wtilde}{d}}}%
%BeginExpansion
\underaccent{\wtilde}{d}%
%EndExpansion
\right]
\end{equation*}%
then

\begin{equation*}
M\left( \hat{P}_{0},Y_{\ast }\right) =Var\left( \hat{P}_{0}-Y_{\ast }\right)
+%
%TCIMACRO{\TeXButton{underaccent_b}{\underaccent{\wtilde}{b}}}%
%BeginExpansion
\underaccent{\wtilde}{b}%
%EndExpansion
_{\ast 0}%
%TCIMACRO{\TeXButton{underaccent_b}{\underaccent{\wtilde}{b}}}%
%BeginExpansion
\underaccent{\wtilde}{b}%
%EndExpansion
_{\ast 0}^{\dagger }
\end{equation*}%
\begin{equation*}
=\sigma ^{2}x_{\ast }DWD^{\dagger }x_{\ast }^{\dagger }+\sigma ^{2}W_{\ast
}-\sigma ^{2}W_{\ast }DW_{0}-\sigma ^{2}W_{0}D^{\dagger }W_{\ast }+%
%TCIMACRO{\TeXButton{underaccent_b}{\underaccent{\wtilde}{b}}}%
%BeginExpansion
\underaccent{\wtilde}{b}%
%EndExpansion
_{\ast 0}%
%TCIMACRO{\TeXButton{underaccent_b}{\underaccent{\wtilde}{b}}}%
%BeginExpansion
\underaccent{\wtilde}{b}%
%EndExpansion
_{\ast 0}^{\dagger }
\end{equation*}

\bigskip

\begin{equation*}
%TCIMACRO{\TeXButton{underaccent_b}{\underaccent{\wtilde}{b}}}%
%BeginExpansion
\underaccent{\wtilde}{b}%
%EndExpansion
_{\ast 1}=E\left( \hat{P}_{1}\right) -x_{\ast }\beta =ZE\left[ \left( \hat{%
\beta}-\beta \right) \right]
\end{equation*}%
where $\hat{P}_{1}=x_{\ast }\hat{\beta}+W_{0}^{\dagger }W^{-1}\left( Y-x\hat{%
\beta}\right) =Z\left( \hat{\beta}-\beta \right) +\left( W_{0}^{\dagger
}W^{-1}%
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
-%
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
_{\ast }\right) $, $z=\left( x_{\ast }-W_{0}^{\dagger }W^{-1}x\right) $%
\begin{equation*}
=Z\left( Dx-I\right) \beta +d
\end{equation*}%
\begin{equation*}
=\left( x_{\ast }-W_{0}^{\dagger }W^{-1}x\right) \left[ \left( Dx-I\right)
\beta +d\right]
\end{equation*}

\begin{equation*}
=x_{\ast }\left[ \left( Dx-I\right) \beta +d\right] -W_{0}^{\dagger }W^{-1}x%
\left[ \left( Dx-I\right) \beta +d\right]
\end{equation*}%
\begin{equation*}
=%
%TCIMACRO{\TeXButton{underaccent_b}{\underaccent{\wtilde}{b}}}%
%BeginExpansion
\underaccent{\wtilde}{b}%
%EndExpansion
_{\ast 0}-W_{0}^{\dagger }W^{-1}x\left[ \left( Dx-I\right) \beta +d\right]
\end{equation*}

\bigskip

\begin{equation*}
M\left( \hat{P}_{0},Y_{\ast }\right) -M\left( \hat{P}\left( \hat{\beta}%
\right) ,Y_{\ast }\right) =\cdots
\end{equation*}

\begin{equation*}
\vdots
\end{equation*}

\begin{equation*}
=\sigma ^{2}G+\sigma ^{2}x_{\ast }EW^{-\frac{1}{2}}W_{0}+\sigma
^{2}W_{0}^{\dagger }W^{-\frac{1}{2}}Ex_{\ast }^{\dagger }+%
%TCIMACRO{\TeXButton{underaccent_b}{\underaccent{\wtilde}{b}}}%
%BeginExpansion
\underaccent{\wtilde}{b}%
%EndExpansion
_{\ast 0}%
%TCIMACRO{\TeXButton{underaccent_b}{\underaccent{\wtilde}{b}}}%
%BeginExpansion
\underaccent{\wtilde}{b}%
%EndExpansion
_{\ast 0}^{\dagger }-%
%TCIMACRO{\TeXButton{underaccent_b}{\underaccent{\wtilde}{b}}}%
%BeginExpansion
\underaccent{\wtilde}{b}%
%EndExpansion
_{\ast 1}%
%TCIMACRO{\TeXButton{underaccent_b}{\underaccent{\wtilde}{b}}}%
%BeginExpansion
\underaccent{\wtilde}{b}%
%EndExpansion
_{\ast 1}^{\dagger }
\end{equation*}%
where

\begin{equation*}
E=DWD^{\dagger }x^{\dagger }W^{-\frac{1}{2}}-DW^{-\frac{1}{2}}
\end{equation*}

\begin{equation*}
G=W_{0}^{\dagger }W^{-\frac{1}{2}}\left( I-D\right) W^{-\frac{1}{2}}W_{0}
\end{equation*}

\begin{equation*}
p=W^{-\frac{1}{2}}xDWD^{\dagger }x^{\dagger }W^{-\frac{1}{2}}
\end{equation*}

\bigskip

If E=0, then%
\begin{eqnarray*}
&&M\left( 
%TCIMACRO{\TeXButton{underaccent_P_hat}{\underaccent{\wtilde}{\hat{P}}}}%
%BeginExpansion
\underaccent{\wtilde}{\hat{P}}%
%EndExpansion
_{0},Y_{\ast }\right) -M\left( \hat{P}\left( \hat{\beta}\right) ,Y_{\ast
}\right) \\
&=&\sigma ^{2}G+%
%TCIMACRO{\TeXButton{underaccent_b}{\underaccent{\wtilde}{b}}}%
%BeginExpansion
\underaccent{\wtilde}{b}%
%EndExpansion
_{\ast 0}%
%TCIMACRO{\TeXButton{underaccent_b}{\underaccent{\wtilde}{b}}}%
%BeginExpansion
\underaccent{\wtilde}{b}%
%EndExpansion
_{\ast 0}^{\dagger }-%
%TCIMACRO{\TeXButton{underaccent_b}{\underaccent{\wtilde}{b}}}%
%BeginExpansion
\underaccent{\wtilde}{b}%
%EndExpansion
_{\ast 1}%
%TCIMACRO{\TeXButton{underaccent_b}{\underaccent{\wtilde}{b}}}%
%BeginExpansion
\underaccent{\wtilde}{b}%
%EndExpansion
_{\ast 1}^{\dagger }\geq 0
\end{eqnarray*}%
then $P\left( \hat{\beta}\right) $ better than $%
%TCIMACRO{\TeXButton{underaccent_P_hat}{\underaccent{\wtilde}{\hat{P}}}}%
%BeginExpansion
\underaccent{\wtilde}{\hat{P}}%
%EndExpansion
_{0}$.

\bigskip

Consider $\hat{\beta}=\left( x^{\dagger }W^{-1}x\right) ^{-1}x^{\dagger
}W^{-1}Y=DY+%
%TCIMACRO{\TeXButton{underaccent_d}{\underaccent{\wtilde}{d}}}%
%BeginExpansion
\underaccent{\wtilde}{d}%
%EndExpansion
\quad (d=0)$%
\begin{equation*}
\therefore E=DWD^{\dagger }x^{\dagger }W^{-\frac{1}{2}}-DW^{-\frac{1}{2}}
\end{equation*}%
\begin{equation*}
=\left( x^{\dagger }W^{-1}x\right) ^{-1}x^{\dagger }W^{-1}W\left( \left(
x^{\dagger }W^{-1}x\right) ^{-1}x^{\dagger }W^{-1}\right) ^{\dagger
}x^{\dagger }W^{-\frac{1}{2}}-\left( \left( x^{\dagger }W^{-1}x\right)
^{-1}x^{\dagger }W^{-1}\right) W^{-\frac{1}{2}}
\end{equation*}%
\begin{equation*}
=\left( x^{\dagger }W^{-1}x\right) ^{-1}x^{\dagger }W^{-1}x\left( x^{\dagger
}W^{-1}x\right) ^{-1}x^{\dagger }W^{-\frac{1}{2}}-\left( x^{\dagger
}W^{-1}x\right) ^{-1}x^{\dagger }W^{-1}W^{-\frac{1}{2}}
\end{equation*}%
\begin{equation*}
=0
\end{equation*}%
\begin{equation*}
\left. 
\begin{array}{c}
\hat{p}_{0} \\ 
\hat{p}_{1} \\ 
\hat{p}_{2} \\ 
\hat{p}_{3}%
\end{array}%
\right\} x_{\ast }\hat{\beta}+W_{0}^{\dagger }W^{-1}\left( Y-x\hat{\beta}%
\right) =Z\left( \hat{\beta}-\beta \right) +W_{0}^{\dagger }W^{-1}
\end{equation*}

\bigskip

\paragraph{Comparison of Classical and Optimal predictial with $x_{\ast }%
\protect\beta $-superiority}

\begin{equation*}
\hat{p}_{0}=x_{\ast }\hat{\beta}\quad \hat{p}_{3}=P\left( \hat{\beta}\right)
=x_{\ast }\hat{\beta}+W_{0}^{\dagger }W^{-1}\left( Y-x\hat{\beta}\right)
\quad \hat{\beta}=D%
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
+%
%TCIMACRO{\TeXButton{underaccent_d}{\underaccent{\wtilde}{d}}}%
%BeginExpansion
\underaccent{\wtilde}{d}%
%EndExpansion
\end{equation*}

\bigskip

Note: Different from $Y_{\ast }$-superiority of $P\left( \hat{\beta}\right) $%
. It might be expected that $\hat{P}_{0}$ is a more efficient predictor
according to the $x_{\ast }\beta $-criterion when compared with $P\left( 
\hat{\beta}\right) $.

$\hat{\beta}_{3}$ is better than $\hat{p}_{0}$ in $Y_{\ast }$-superiority if 
$E=0\quad \hat{\beta}=\left( x^{\dagger }W^{-1}x\right) ^{-1}x^{\dagger
}W^{-1}%
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
$

\bigskip

\paragraph{$x_{\ast }\protect\beta $-superiority}

\begin{equation*}
M\left( \hat{P}_{0},x_{\ast }\hat{\beta}\right) =Var\left( \hat{P}%
_{0}\right) +b_{\ast 0}b_{\ast 0}^{\dagger }=x_{\ast }DWDx_{\ast }^{\dagger
}\sigma ^{2}+b_{\ast 0}b_{\ast 0}^{\dagger }
\end{equation*}%
\begin{equation*}
M\left( \hat{P}\left( \hat{\beta}\right) ,x_{\ast }\hat{\beta}\right)
=Var\left( \hat{P}_{3}\right) +b_{\ast 1}b_{\ast 1}^{\dagger }
\end{equation*}%
\begin{equation*}
Var\left( \hat{P}_{3}\right) =Var\left( x_{\ast }\hat{\beta}\right)
+W_{0}^{\dagger }W^{-1}\left( Y-x\hat{\beta}\right)
\end{equation*}%
\begin{equation*}
=Var\left( x_{\ast }\hat{\beta}\right) +W_{0}^{\dagger }W^{-1}Var\left(
Y\right) W^{-1}W_{0}+W_{0}^{\dagger }W^{-1}Var\left( x_{\ast }\hat{\beta}%
\right) W^{-1}W_{0}^{\dagger }
\end{equation*}%
\begin{equation*}
+Cov\left( x_{\ast }\hat{\beta},W_{0}^{\dagger }W^{-1}Y\right) +Cov\left(
x_{\ast }\hat{\beta},W_{0}^{\dagger }W^{-1}x\hat{\beta}\right) -Cov\left(
x_{\ast }\hat{\beta},W_{0}^{\dagger }W^{-1}x\hat{\beta}\right)
\end{equation*}%
\begin{equation*}
-Cov\left( W_{0}^{\dagger }W^{-1}x\hat{\beta},W_{0}^{\dagger }W^{-1}x_{\ast }%
\hat{\beta}\right) -Cov\left( W_{0}^{\dagger }W^{-1}%
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
,W_{0}^{\dagger }W^{-1}x\hat{\beta}\right)
\end{equation*}%
\begin{equation*}
-Cov\left( W_{0}^{\dagger }W^{-1}x\hat{\beta},W_{0}^{\dagger }W^{-1}%
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
\right)
\end{equation*}

\bigskip

\bigskip

\begin{equation*}
M\left( \hat{P}_{3},x_{\ast }\hat{\beta}\right) -M\left( \hat{P}_{0},x_{\ast
}\hat{\beta}\right) =-\sigma ^{2}G-b_{\ast 0}b_{\ast 0}^{\dagger }+b_{\ast
1}b_{\ast 1}^{\dagger }-\sigma ^{2}x_{\ast }EW^{-\frac{1}{2}}W_{0}
\end{equation*}%
\begin{equation*}
-\sigma ^{2}W_{0}^{\dagger }W^{-\frac{1}{2}}E^{\dagger }x_{\ast }^{\dagger
}+\sigma ^{2}W_{0}^{\dagger }W^{-1}\left[ I-xD\right] W_{0}+\sigma ^{2}W_{0}%
\left[ I-D^{\dagger }x^{\dagger }\right] W^{-1}W_{0}
\end{equation*}%
\begin{equation*}
\text{If }E=0\Rightarrow M\left( \hat{P}_{3},x_{\ast }\hat{\beta}\right)
-M\left( \hat{P}_{0},x_{\ast }\hat{\beta}\right) =\sigma ^{2}G+b_{\ast
1}b_{\ast 1}^{\dagger }-b_{\ast 0}b_{\ast 0}^{\dagger }
\end{equation*}

\bigskip

\begin{theorem}
Let $\hat{\beta}=DY+%
%TCIMACRO{\TeXButton{underaccent_d}{\underaccent{\wtilde}{d}}}%
%BeginExpansion
\underaccent{\wtilde}{d}%
%EndExpansion
$ be a linear estimator s.t. the matrix D satisfies the condition E=0. Then
the classical predictor $\hat{P}_{0}=x_{\ast }\hat{\beta}$ is $x_{\ast }\hat{%
\beta}$-superiority to the predictor $\hat{P}\left( \hat{\beta}\right)
=x_{\ast }\hat{\beta}+W_{0}^{\dagger }W^{-1}\left( Y-x\hat{\beta}\right) $
iff

\begin{enumerate}
\item b$_{\ast 0}\in R\left( \sigma ^{2}G+b_{\ast 1}b_{\ast 1}^{\dagger
}\right) $

\item b$_{\ast 0}^{\dagger }\left( \sigma ^{2}G+b_{\ast 1}b_{\ast
1}^{\dagger }\right) -b_{\ast 0}\leq 1$
\end{enumerate}
\end{theorem}

\bigskip

\begin{example}
Let $\hat{\beta}=\left( x^{\dagger }W^{-1}x\right) ^{-1}x^{\dagger }W^{-1}Y$%
\begin{equation*}
M\left( x_{\ast }\hat{\beta},x_{\ast }\beta \right) =Var\left( x_{\ast }\hat{%
\beta}\right) =\sigma ^{2}x_{\ast }\left( x^{\dagger }W^{-1}x\right)
^{-1}x_{\ast }^{\dagger }
\end{equation*}%
\begin{equation*}
\hat{\beta}_{3}=x_{\ast }\hat{\beta}+W_{0}^{\dagger }W^{-1}\left( 
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
-x_{\ast }\hat{\beta}\right) =Z\left( \hat{\beta}-\beta \right)
+W_{0}^{\dagger }W^{-1}x_{\ast }^{\dagger }
\end{equation*}%
\begin{equation*}
M\left( \hat{\beta}_{3},x_{\ast }\beta \right) =E\left( Z\left( \hat{\beta}%
-\beta \right) \left( \hat{\beta}-\beta \right) ^{\dagger }Z^{\dagger
}\right) +E\left[ W_{0}^{\dagger }W^{-1}%
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
^{\dagger }W^{-1}W_{0}^{\dagger }\right]
\end{equation*}%
\begin{equation*}
+E\left( Z\left( \hat{\beta}-\beta \right) \left( W_{0}W^{-1}\varepsilon
\right) ^{\dagger }\right) +E\left( \left( W_{0}W^{-1}\varepsilon \right)
\left( Z\left( \hat{\beta}-\beta \right) \right) ^{\dagger }\right)
\end{equation*}%
\begin{equation*}
=\sigma ^{2}Z\left( x^{\dagger }W^{-1}x\right) ^{-1}Z^{\dagger }+\sigma
^{2}W_{0}^{\dagger }W^{-1}W_{0}^{\dagger }+\sigma ^{2}Z\left( x^{\dagger
}W^{-1}x\right) ^{-1}x^{\dagger }W^{-1}W_{0}
\end{equation*}%
\begin{equation*}
+\sigma ^{2}W_{0}^{\dagger }W^{-1}x\left( x^{\dagger }W^{-1}x\right)
^{-1}Z^{\dagger }
\end{equation*}%
\begin{equation*}
=\underset{M\left( x_{\ast }\hat{\beta},x_{\ast }\beta \right) }{\underbrace{%
\sigma ^{2}x_{\ast }\left( x^{\dagger }W^{-1}x\right) ^{-1}x_{\ast
}^{\dagger }}}+\sigma ^{2}W_{0}^{\dagger }W^{-1}W^{-1}W_{0}^{\dagger
}-\sigma ^{2}W_{0}^{\dagger }W^{-1}x\left( x^{\dagger }W^{-1}x\right)
^{-1}x^{\dagger }W^{-1}W_{0}
\end{equation*}%
\begin{equation*}
=\sigma ^{2}x_{\ast }\left( x^{\dagger }W^{-1}x\right) ^{-1}x_{\ast
}^{\dagger }+\sigma ^{2}W_{0}^{\dagger }\left( W^{-\frac{1}{2}%
}-W^{-1}x\left( x^{\dagger }W^{-1}x\right) ^{-1}x^{\dagger }W^{-1}\right)
\cdot
\end{equation*}%
\begin{equation*}
\left( W^{-\frac{1}{2}}-W^{-1}x\left( x^{\dagger }W^{-1}x\right) ^{-1}W^{-%
\frac{1}{2}}\right) ^{\dagger }W_{0}
\end{equation*}%
$\therefore $ when $\hat{\beta}=\left( x^{\dagger }W^{-1}x\right)
^{-1}x^{\dagger }W^{-1}Y$, $M\left( P\left( \hat{\beta}\right) ,x_{\ast
}\beta \right) $ is better than $M\left( x_{\ast }\hat{\beta},x_{\ast }\beta
\right) $. It is different than the result of superiority-Y$_{\ast }$.
\end{example}

\bigskip

\bigskip

\begin{equation*}
x_{\ast }\hat{\beta}\quad \quad x_{\ast }\hat{\beta}+W_{0}^{\dagger
}W^{-1}\left( Y-x\hat{\beta}\right) \quad 
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
\sim \mathcal{N}\left( x\beta ,\sigma ^{2}W\right)
\end{equation*}%
\begin{equation*}
\frac{\left( Y-x\hat{\beta}\right) ^{\dagger }W^{-1}\left( Y-x\hat{\beta}%
\right) }{n-k}=S^{2}
\end{equation*}

\begin{equation*}
\hat{P}_{3}\sim \mathcal{N}\left( x_{\ast }\beta ,\tsum\nolimits_{\ast
}\sigma ^{2}\right) \quad \hat{P}_{3}-Y_{\ast }\sim \mathcal{N}\left( 
%TCIMACRO{\TeXButton{underaccent_O}{\underaccent{\wtilde}{O}}}%
%BeginExpansion
\underaccent{\wtilde}{O}%
%EndExpansion
,\tsum\nolimits_{0}\sigma ^{2}\right)
\end{equation*}

\begin{equation*}
\frac{\left( \hat{P}_{3}-Y_{\ast }\right) ^{\dagger }\left( \sigma
^{2}\tsum\nolimits_{0}\right) ^{-1}\left( \hat{P}_{3}-Y_{\ast }\right) }{%
n_{\ast }\frac{S^{2}}{\sigma ^{2}}}\sim ?F_{n_{\ast },n-k}
\end{equation*}%
want to know

\begin{enumerate}
\item nominator is ???

\item denominator is ???\qquad \qquad \qquad \qquad \qquad $\Longrightarrow $%
construct liability eliptic

\item nominator and denominator independent?
\end{enumerate}

\bigskip

\paragraph{Prediction regression for the random vector}

\begin{equation*}
\text{Assume }\left( 
\begin{array}{c}
\varepsilon _{\ast } \\ 
\varepsilon%
\end{array}%
\right) \sim \mathcal{N}\left( \left( 
\begin{array}{c}
0 \\ 
0%
\end{array}%
\right) \left( 
\begin{array}{cc}
W_{\ast } & W_{0} \\ 
W_{0}^{\dagger } & W%
\end{array}%
\right) \right)
\end{equation*}%
\begin{equation*}
W_{\ast }-W_{0}^{\dagger }W^{-1}W_{0}>0
\end{equation*}%
choose the R$_{A}$-Optimal homo. unbiased predictor%
\begin{equation*}
\hat{P}_{3}=x_{\ast }\hat{\beta}+W_{0}^{\dagger }W^{-1}\left( Y-x\hat{\beta}%
\right) \quad \hat{\beta}=\left( x^{\dagger }W^{-1}x\right) ^{-1}x^{\dagger
}W^{-1}Y
\end{equation*}%
\begin{equation*}
\hat{P}_{3}-Y_{\ast }\sim \mathcal{N}_{\mathcal{N}_{\ast }}\left( 
%TCIMACRO{\TeXButton{underaccent_O}{\underaccent{\wtilde}{O}}}%
%BeginExpansion
\underaccent{\wtilde}{O}%
%EndExpansion
,\tsum\nolimits_{0}\sigma ^{2}\right)
\end{equation*}%
where%
\begin{equation*}
\tsum\nolimits_{0}=\underset{Z}{\underbrace{\left( x_{\ast }-W_{0}^{\dagger
}W^{-1}x\right) }}\left( x^{\dagger }W^{-1}x\right) ^{-1}\underset{Z}{%
\underbrace{\left( x_{\ast }-W_{0}^{\dagger }W^{-1}x\right) ^{\dagger }}}%
+W_{0}-W_{0}^{\dagger }W^{-1}W_{0}
\end{equation*}%
\begin{equation*}
\frac{\left( \hat{P}_{3}-Y_{\ast }\right) ^{\dagger
}\tsum\nolimits_{0}^{-1}\left( \hat{P}_{3}-Y_{\ast }\right) }{\sigma ^{2}}%
\sim \mathcal{X}_{n_{\ast }}^{2}
\end{equation*}%
\begin{equation*}
\left[ x\sim \mathcal{N}\left( \mu ,\tsum \right) \quad \left( x-\mu \right)
^{\dagger }\tsum\nolimits^{-1}\left( x-\mu \right) \sim \mathcal{X}_{p}^{2}%
\right]
\end{equation*}

\bigskip

\begin{theorem}
let 
\begin{equation*}
\frac{\left( Y-x\hat{\beta}\right) ^{\dagger }W^{-1}\left( Y-x\hat{\beta}%
\right) }{n-k}=S^{2}
\end{equation*}%
be the estimator of $\sigma ^{2}$. Then 
\begin{equation*}
\frac{\left( \hat{P}_{3}-Y_{\ast }\right) ^{\dagger
}\tsum\nolimits_{0}^{-1}\left( \hat{P}_{3}-Y_{\ast }\right) /\sigma ^{2}}{%
n_{\ast }\frac{S^{2}}{\sigma ^{2}}}\sim F_{n_{\ast },n-k}
\end{equation*}
\end{theorem}

\begin{proof}
(consider the standardized vector of errors)%
\begin{equation*}
\Phi =\left( 
\begin{array}{c}
W^{-\frac{1}{2}}%
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}} }%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}
%EndExpansion
\\ 
W_{\ast }^{-\frac{1}{2}}%
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
_{\ast }%
\end{array}%
\right) \sim \mathcal{N}_{n+n_{\ast }}\left( 0,\sigma ^{2}V\right)
\end{equation*}%
\begin{equation*}
\mathcal{V=}\left( 
\begin{array}{cc}
I_{n} & W^{-\frac{1}{2}}W_{0}W_{\ast }^{-\frac{1}{2}} \\ 
W^{-\frac{1}{2}}W_{0}W_{\ast }^{-\frac{1}{2}} & I_{n_{\ast }}%
\end{array}%
\right)
\end{equation*}%
\begin{equation*}
\hat{P}_{3}-Y_{\ast }=Z\left( \hat{\beta}-\beta \right) +W_{0}^{\dagger
}W^{-1}%
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
-x_{\ast }\beta -\varepsilon _{\ast }
\end{equation*}%
\begin{equation*}
=Z\left( \hat{\beta}-\beta \right) -x_{\ast }\beta +W_{0}^{\dagger }W^{-1}%
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
-\varepsilon _{\ast }
\end{equation*}%
\begin{equation*}
=Z\left( \left( x^{\dagger }W^{-1}x\right) ^{-1}x^{\dagger }W^{-1}\left(
x\beta +\varepsilon \right) -\beta \right) +W_{0}^{\dagger
}W^{-1}\varepsilon -\varepsilon _{\ast }
\end{equation*}%
\begin{equation*}
=\left( x^{\dagger }W^{-1}x\right) ^{-1}x^{\dagger }W^{-1}\varepsilon
+W_{0}^{\dagger }W^{-1}%
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
-\varepsilon _{\ast }
\end{equation*}%
\begin{equation*}
=\left[ Z\left( x^{\dagger }W^{-1}x\right) ^{-1}x^{\dagger }W^{-\frac{1}{2}%
}+W_{0}^{\dagger }W^{-\frac{1}{2}},\ -W_{\ast }^{\frac{1}{2}}\right] \left[ 
\begin{array}{c}
W^{-\frac{1}{2}}%
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}} }%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}
%EndExpansion
\\ 
W_{\ast }^{-\frac{1}{2}}%
%TCIMACRO{\TeXButton{underaccent_epsilon}{\underaccent{\wtilde}{\epsilon}}}%
%BeginExpansion
\underaccent{\wtilde}{\epsilon}%
%EndExpansion
_{\ast }%
\end{array}%
\right]
\end{equation*}%
\begin{equation*}
=\left[ 
\begin{array}{cc}
A_{r} & A_{2}%
\end{array}%
\right] \Phi
\end{equation*}%
\begin{equation*}
\hat{P}_{3}-Y_{\ast }\sim \mathcal{N}\left( 0,\sigma
^{2}\tsum\nolimits_{0}\right)
\end{equation*}%
\begin{equation*}
\tsum\nolimits_{0}=\left( A_{1},A_{2}\right) V\left[ 
\begin{array}{c}
A_{1}^{\dagger } \\ 
A_{2}^{\dagger }%
\end{array}%
\right] \ \text{and}\ V^{-\frac{1}{2}}\Phi \sim \mathcal{N}\left( 0,I\sigma
^{2}\right)
\end{equation*}%
\begin{equation*}
\left( \hat{P}_{3}-Y_{\ast }\right) ^{\dagger }\tsum\nolimits_{0}^{-1}\left( 
\hat{P}_{3}-Y_{\ast }\right) =\left[ \left[ 
\begin{array}{cc}
A_{1} & A_{2}%
\end{array}%
\right] \Phi \right] ^{\dagger }\tsum\nolimits_{0}^{-1}\left[ \left[ 
\begin{array}{cc}
A_{1} & A_{2}%
\end{array}%
\right] \Phi \right]
\end{equation*}%
\begin{equation*}
=\left( V^{-\frac{1}{2}}\Phi \right) ^{\dagger }V^{\frac{1}{2}}\left[ 
\begin{array}{c}
A_{1}^{\dagger } \\ 
A_{2}^{\dagger }%
\end{array}%
\right] \tsum\nolimits_{0}^{-1}\left[ 
\begin{array}{cc}
A_{1} & A_{2}%
\end{array}%
\right] V^{\frac{1}{2}}V^{-\frac{1}{2}}\Phi
\end{equation*}%
Note:%
\begin{equation*}
\left( V^{\frac{1}{2}}\left[ 
\begin{array}{c}
A_{1}^{\dagger } \\ 
A_{2}^{\dagger }%
\end{array}%
\right] \tsum\nolimits_{0}^{-1}\left[ 
\begin{array}{cc}
A_{1} & A_{2}%
\end{array}%
\right] V^{\frac{1}{2}}\right) \cdot \left( V^{\frac{1}{2}}\left[ 
\begin{array}{c}
A_{1}^{\dagger } \\ 
A_{2}^{\dagger }%
\end{array}%
\right] \tsum\nolimits_{0}^{-1}\left[ 
\begin{array}{cc}
A_{1} & A_{2}%
\end{array}%
\right] V^{\frac{1}{2}}\right)
\end{equation*}%
\begin{equation*}
=V^{\frac{1}{2}}\left[ 
\begin{array}{c}
A_{1}^{\dagger } \\ 
A_{2}^{\dagger }%
\end{array}%
\right] \tsum\nolimits_{0}^{-1}\left[ 
\begin{array}{cc}
A_{1} & A_{2}%
\end{array}%
\right]
\end{equation*}%
is an idemptent matrix.\newline
\begin{equation*}
\therefore \left( \hat{P}_{3}-Y_{\ast }\right) ^{\dagger
}\tsum\nolimits_{0}^{-1}\left( \hat{P}_{3}-Y_{\ast }\right) \sim \sigma
^{2}\chi _{n_{\ast }}^{2}
\end{equation*}%
also%
\begin{eqnarray*}
W^{-\frac{1}{2}}\left( Y-x\hat{\beta}\right) &=&W^{-\frac{1}{2}}\left(
x\beta +\varepsilon -x\left( x^{\dagger }W^{-1}x\right) ^{-1}x^{\dagger
}W^{-1}\left( x\beta +\varepsilon \right) \right) \\
&=&W^{-\frac{1}{2}}\left( \varepsilon -x\left( x^{\dagger }W^{-1}x\right)
^{-1}x^{\dagger }W^{-1}\varepsilon \right) \\
&=&\left( I-W^{-\frac{1}{2}}x\left( x^{\dagger }W^{-1}x\right) ^{-1}W^{-%
\frac{1}{2}}\right) W^{-\frac{1}{2}}\varepsilon \\
&=&\left( I-M\right) W^{-\frac{1}{2}}\varepsilon
\end{eqnarray*}%
\begin{equation*}
M^{2}=\left( W^{-\frac{1}{2}}x\left( x^{\dagger }W^{-1}x\right)
^{-1}x^{\dagger }W^{-\frac{1}{2}}\right) \left( W^{-\frac{1}{2}}x\left(
x^{\dagger }W^{-1}x\right) ^{-1}x^{\dagger }W^{-\frac{1}{2}}\right) =M
\end{equation*}%
\begin{eqnarray*}
tr\left( M\right) &=&tr\left( W^{-\frac{1}{2}}x\left( x^{\dagger
}W^{-1}x\right) ^{-1}x^{\dagger }W^{-\frac{1}{2}}\right) =tr\left(
x^{\dagger }W^{-1}x\left( x^{\dagger }W^{-1}x\right) ^{-1}\right) \\
&=&tr\left( I_{k}\right) =k
\end{eqnarray*}%
\begin{equation*}
\frac{\left( 
%TCIMACRO{\TeXButton{underaccent_Y}{\underaccent{\wtilde}{Y}}}%
%BeginExpansion
\underaccent{\wtilde}{Y}%
%EndExpansion
-x\hat{\beta}\right) ^{\dagger }W^{-1}\left( Y-x\hat{\beta}\right) }{\sigma
^{2}}=\frac{n-k}{\sigma ^{2}}S^{2}\sim \chi _{n-k}^{2}
\end{equation*}%
Note%
\begin{eqnarray*}
\left( Y-x\hat{\beta}\right) ^{\dagger }W^{-1}\left( Y-x\hat{\beta}\right)
&=&\left[ W^{-\frac{1}{2}}\left( Y-x\hat{\beta}\right) \right] ^{\dagger }%
\left[ W^{-\frac{1}{2}}\left( Y-x\hat{\beta}\right) \right] \\
&=&\left[ \left( I-M\right) W^{-\frac{1}{2}}\varepsilon \right] ^{\dagger }%
\left[ \left( I-M\right) W^{-\frac{1}{2}}\varepsilon \right] \\
&=&\left[ W^{-\frac{1}{2}}\varepsilon \right] ^{\dagger }\left( I-M\right) %
\left[ W^{-\frac{1}{2}}\varepsilon \right]
\end{eqnarray*}%
independence\newline
nominator $\left( V^{-\frac{1}{2}}\Phi \right) ^{\dagger }V^{\frac{1}{2}}%
\left[ 
\begin{array}{c}
A_{1}^{\dagger } \\ 
A_{2}^{\dagger }%
\end{array}%
\right] \tsum\nolimits_{0}^{-1}\left[ 
\begin{array}{cc}
A_{1} & A_{2}%
\end{array}%
\right] V^{\frac{1}{2}}\left( V^{-\frac{1}{2}}\Phi \right) =\left( \hat{P}%
_{3}-Y_{\ast }\right) ^{\dagger }\tsum\nolimits_{0}^{-1}\left( \hat{P}%
_{3}-Y_{\ast }\right) $\newline
denominator 
\begin{equation*}
\varepsilon ^{\dagger }W^{-\frac{1}{2}}\left( I-M\right) W^{-\frac{1}{2}%
}\varepsilon =\Phi ^{\dagger }\left[ 
\begin{array}{cc}
I-M & 0 \\ 
0 & 0%
\end{array}%
\right] \Phi ,\text{ where }\Phi =\left[ 
\begin{array}{c}
W^{-\frac{1}{2}}\varepsilon \\ 
W_{\ast }^{-\frac{1}{2}}\varepsilon _{\ast }%
\end{array}%
\right]
\end{equation*}%
\begin{eqnarray*}
&=&\Phi ^{\dagger }M_{1}\Phi \\
&=&\left( V^{-\frac{1}{2}}\Phi \right) ^{\dagger }V^{\frac{1}{2}}M_{1}V^{%
\frac{1}{2}}\left( V^{-\frac{1}{2}}\Phi \right)
\end{eqnarray*}%
\newline
If we can show that $V^{\frac{1}{2}}M_{1}V^{\frac{1}{2}}V^{\frac{1}{2}}\left[
\begin{array}{c}
A_{1}^{\dagger } \\ 
A_{2}^{\dagger }%
\end{array}%
\right] \tsum\nolimits_{0}^{-1}\left[ 
\begin{array}{cc}
A_{1} & A_{2}%
\end{array}%
\right] V^{\frac{1}{2}}=0$, then $\left( \hat{P}_{3}-Y_{\ast }\right)
^{\dagger }\tsum\nolimits_{0}^{-1}\left( \hat{P}_{3}-Y_{\ast }\right) $ and S%
$^{2}$ are independent.\newline
Look at%
\begin{eqnarray*}
M_{1}V\left[ 
\begin{array}{c}
A_{1}^{\dagger } \\ 
A_{2}^{\dagger }%
\end{array}%
\right] &=&\left[ 
\begin{array}{cc}
I-M & 0 \\ 
0 & 0%
\end{array}%
\right] \left[ 
\begin{array}{cc}
I_{n} & W^{-\frac{1}{2}}W_{0}W_{\ast }^{-\frac{1}{2}} \\ 
W^{-\frac{1}{2}}W_{0}W_{\ast }^{-\frac{1}{2}} & I_{n_{\ast }}%
\end{array}%
\right] \left[ 
\begin{array}{c}
A_{1}^{\dagger } \\ 
A_{2}^{\dagger }%
\end{array}%
\right] \\
&=&\left[ 
\begin{array}{cc}
I-M & \left( I-M\right) W^{-\frac{1}{2}}W_{0}W_{\ast }^{-\frac{1}{2}} \\ 
0 & 0%
\end{array}%
\right] \left[ 
\begin{array}{c}
A_{1}^{\dagger } \\ 
A_{2}^{\dagger }%
\end{array}%
\right] \\
&&\vdots \\
&=&0
\end{eqnarray*}%
\begin{eqnarray*}
&\therefore &\frac{\left( \hat{P}_{3}-Y_{\ast }\right) ^{\dagger
}\tsum\nolimits_{0}^{-1}\left( \hat{P}_{3}-Y_{\ast }\right) }{n_{\ast }S^{2}}%
\longrightarrow F_{n_{\ast },n-k} \\
S^{2} &=&\frac{\left( Y-x\hat{\beta}\right) ^{\dagger }W^{-1}\left( Y-x\hat{%
\beta}\right) }{n-k}
\end{eqnarray*}
\end{proof}

\bigskip

\bigskip

December 29 (Monday)

\bigskip

\begin{equation*}
\frac{\left( \hat{P}_{3}-Y_{\ast }\right) ^{\dagger
}\tsum\nolimits_{0}^{-1}\left( \hat{P}_{3}-Y_{\ast }\right) }{n_{\ast }S^{2}}%
\longrightarrow F_{n_{\ast },n-k}
\end{equation*}

\begin{eqnarray*}
S^{2} &=&\left( Y-x\hat{\beta}\right) ^{\dagger }W^{-1}\left( Y-x\hat{\beta}%
\right) /\left( n-k\right) \\
\tsum\nolimits_{0} &=&Z\left( x^{\dagger }W^{-1}x\right) ^{-1}Z^{\dagger
}-W_{0}^{\dagger }W^{-1}W_{0} \\
Z &=&x_{\ast }-W_{0}^{\dagger }W^{-1}x \\
\hat{P}_{3} &=&x_{\ast }\hat{\beta}+W_{0}^{\dagger }W^{-1}\left( Y-x\hat{%
\beta}\right)
\end{eqnarray*}

\bigskip

\paragraph{Prediction regions of Y$_{\ast }$}

\begin{definition}
A compact set $B\left( P\left( \hat{\beta}\right) \right) $ is called a
region with expection coverage q (0$\leq $q$\leq $1) for the unknow random
vector Y$_{\ast }$ centraed around $P\left( \hat{\beta}\right) $ if%
\begin{equation*}
E_{Y_{\ast }}\left[ P\left\{ Y_{\ast }\in B\left( P\left( \hat{\beta}\right)
\right) \right\} \right] =q
\end{equation*}%
(meaning averaged covering volume)
\end{definition}

\begin{theorem}
The ellipsoid 
\begin{equation*}
B\left( \hat{P}_{3}\right) =\left\{ Y_{\ast }:n_{\ast }^{-1}S^{-2}\left(
Y_{\ast }-\hat{P}_{\ast }\right) ^{\dagger }\tsum\nolimits_{0}^{-1}\left(
Y_{\ast }-\hat{P}_{\ast }\right) \leq F_{n_{\ast },n-k,1-\alpha }\right\}
\end{equation*}%
is a region with expected coverage $\left( 1-\alpha \right) $ for the vector
Y$_{\ast }$.
\end{theorem}

\bigskip

Comparing the efficience of prediction ellipsoid, let $V_{n}$ denote the
volume of the n-dimentional unit sphere. Let $a^{\dagger }Aa\leq 1$, $A$:
positive define matrix, and $V_{A}=V_{n}\left\vert A\right\vert ^{-\frac{1}{2%
}}$ be the volume of $a^{\dagger }Aa\leq 1$, $V_{A}^{2}=V_{n}^{2}\left\vert
A\right\vert ^{-1}$.

\bigskip

Note: If $n=2\quad A=\left[ 
\begin{array}{cc}
1 & 0 \\ 
0 & 1%
\end{array}%
\right] \quad x^{\dagger }Ax=x_{1}^{2}+x_{2}^{2}\leq 1\quad V_{2}=\pi $

Now want to the volume of $B\left( \hat{P}_{3}\right) $%
\begin{equation*}
\left( Y_{\ast }-\hat{P}_{3}\right) ^{\dagger }\left( n_{\ast
}S^{2}F\tsum\nolimits_{0}^{-1}\right) ^{-1}\left( Y_{\ast }-\hat{P}%
_{3}\right) \leq 1
\end{equation*}%
(the form for making $a^{\dagger }Aa\leq 1$)%
\begin{equation*}
\therefore n_{\ast }S^{2}F\tsum\nolimits_{0}=A^{-1}
\end{equation*}%
\begin{equation*}
\left\vert A^{-1}\right\vert =\left\vert n_{\ast
}S^{2}F\tsum\nolimits_{0}\right\vert =\left( n_{\ast }S^{2}F\right)
^{n_{\ast }}\left\vert \tsum\nolimits_{0}\right\vert
\end{equation*}%
the volume of $B\left( \hat{P}_{3}\right) $: $Vol\left( B\left( \hat{P}%
_{3}\right) \right) =V_{n_{\ast }}^{2}\left( n_{\ast }S^{2}F\right)
^{n_{\ast }}\left\vert \tsum\nolimits_{0}\right\vert $

So%
\begin{equation*}
E\left[ V_{0}|\left( B\left( \hat{P}_{3}^{\ast }\right) \right) ^{2}\right]
=V_{n_{\ast }}^{2}\left( n_{\ast }F\right) ^{n_{\ast }}\left\vert
\tsum\nolimits_{0}^{\ast }\right\vert E\left( S^{2n_{\ast }}\right)
\end{equation*}%
(expected volume integration is related to $\tsum\nolimits_{0}$)

\bigskip

\begin{theorem}
Suppose that there are exist unbiased estimator $\hat{\beta}_{1}$, $\hat{%
\beta}_{2}$ for $\beta $, having dispersion matrix $V\left( \hat{\beta}%
_{1}\right) $ and $V\left( \hat{\beta}_{2}\right) $, resp., and the
corresponding predictions $P\left( \hat{\beta}_{i}\right) =x_{\ast }\hat{%
\beta}_{i}+W_{0}^{\dagger }W^{-1}\left( Y-x\hat{\beta}_{i}\right) \quad
i=1,2,\cdots $.\newline
Assume that $P\left( \hat{\beta}_{1}\right) $ and $P\left( \hat{\beta}%
_{2}\right) $ satisfy the necessary conditions for F distribution, i.e. 
\begin{equation*}
n_{\ast }^{-1}S^{-2}\left( \hat{P}_{3}\left( \hat{\beta}_{i}\right) -Y_{\ast
}\right) ^{\dagger }\tsum\nolimits_{0i}^{-1}\left( \hat{P}_{3}\left( \hat{%
\beta}_{i}\right) -Y_{\ast }\right) \sim F_{n_{\ast },n-k}
\end{equation*}%
Then%
\begin{equation*}
V\left( \hat{\beta}_{1}\right) -V\left( \hat{\beta}_{2}\right) \geq 0
\end{equation*}%
\begin{equation*}
\Rightarrow E\left[ V_{0}|\left( \hat{P}_{3}\left( \hat{\beta}_{1}\right)
\right) ^{2}\right] -E\left[ V_{0}|\left( \hat{P}_{3}\left( \hat{\beta}%
_{2}\right) \right) ^{2}\right] \geq 0
\end{equation*}
\end{theorem}

\end{document}
