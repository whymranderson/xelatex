
\documentclass{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{accents}
\usepackage[ignoreall,a4paper]{geometry}
\usepackage{fancyhdr}

\setcounter{MaxMatrixCols}{10}
%TCIDATA{OutputFilter=LATEX.DLL}
%TCIDATA{Version=5.00.0.2606}
%TCIDATA{<META NAME="SaveForMode" CONTENT="1">}
%TCIDATA{BibliographyScheme=Manual}
%TCIDATA{Created=Wednesday, November 25, 2015 15:33:37}
%TCIDATA{LastRevised=Sunday, June 19, 2016 10:58:13}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{<META NAME="DocumentShell" CONTENT="Standard LaTeX\Blank - Standard LaTeX Article">}
%TCIDATA{CSTFile=40 LaTeX article.cst}
%TCIDATA{ComputeDefs=
%$W=\left( 1-\sigma \right) I$
%}


\newtheorem{theorem}{Theorem}
\newtheorem{acknowledgement}[theorem]{Acknowledgement}
\newtheorem{algorithm}[theorem]{Algorithm}
\newtheorem{axiom}[theorem]{Axiom}
\newtheorem{case}[theorem]{Case}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conclusion}[theorem]{Conclusion}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{criterion}[theorem]{Criterion}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{solution}[theorem]{Solution}
\newtheorem{summary}[theorem]{Summary}
\newenvironment{proof}[1][Proof]{\noindent\textbf{#1.} }{\ \rule{0.5em}{0.5em}}
\input{../../tcilatex}
\DeclareMathAccent{\wtilde}{\mathord}{largesymbols}{"65}
\pagestyle{fancy}
\fancyfoot[C]{\thepage}



\begin{document}


\section{Non-full-Rank Models}

\begin{enumerate}
\item linear combination of the parameters

\item reparameterization

\item $^{\bigstar }$constraints
\end{enumerate}

\bigskip

\begin{example}
\begin{enumerate}
\item One\_Way model%
\begin{equation*}
y_{ij}=\mu +\alpha _{i}+\varepsilon _{ij}\quad i=1,2\quad j=1,2,3
\end{equation*}%
\begin{equation*}
\left[ 
\begin{array}{c}
y_{11} \\ 
y_{12} \\ 
y_{13} \\ 
y_{21} \\ 
y_{22} \\ 
y_{23}%
\end{array}%
\right] =\left[ 
\begin{array}{ccc}
1 & 1 & 0 \\ 
1 & 1 & 0 \\ 
1 & 1 & 0 \\ 
1 & 0 & 1 \\ 
1 & 0 & 1 \\ 
1 & 0 & 1%
\end{array}%
\right] \left[ 
\begin{array}{c}
\mu \\ 
\alpha _{1} \\ 
\alpha _{2}%
\end{array}%
\right] +\left[ 
\begin{array}{c}
\epsilon _{11} \\ 
\epsilon _{12} \\ 
\epsilon _{13} \\ 
\epsilon _{21} \\ 
\epsilon _{22} \\ 
\epsilon _{23}%
\end{array}%
\right]
\end{equation*}%
\newline
\newline
\begin{equation*}
\mathbf{Y=}\underset{6\times 3}{\mathbf{X}}\mathbf{\beta +\epsilon },\quad
r\left( \mathbf{X}\right) =2<3
\end{equation*}

\item Two\_Way model%
\begin{equation*}
y_{ij}=\mu +\alpha _{i}+\beta _{j}+\varepsilon _{ij}\quad 
\begin{tabular}{l}
$i=1,2$ \\ 
$j=1,2$%
\end{tabular}%
\end{equation*}%
\begin{equation*}
\left[ 
\begin{array}{c}
y_{11} \\ 
y_{12} \\ 
y_{21} \\ 
y_{22}%
\end{array}%
\right] =\left[ 
\begin{array}{ccccc}
1 & 1 & 0 & 1 & 0 \\ 
1 & 1 & 0 & 0 & 1 \\ 
1 & 0 & 1 & 1 & 0 \\ 
1 & 0 & 1 & 0 & 1%
\end{array}%
\right] \left[ 
\begin{array}{c}
\mu \\ 
\alpha _{1} \\ 
\alpha _{2} \\ 
\beta _{1} \\ 
\beta _{2}%
\end{array}%
\right] +\left[ 
\begin{array}{c}
\varepsilon _{11} \\ 
\varepsilon _{12} \\ 
\varepsilon _{21} \\ 
\varepsilon _{22}%
\end{array}%
\right]
\end{equation*}%
\newline
\newline
\begin{equation*}
\mathbf{Y=}\underset{4\times 5}{\mathbf{X}}\mathbf{\beta +\epsilon },\quad
r\left( \mathbf{X}\right) =3<5
\end{equation*}
\end{enumerate}
\end{example}

\bigskip

Consider the model%
\begin{equation*}
\mathbf{Y=X\beta +\epsilon }
\end{equation*}%
where $E\left( \mathbf{\epsilon }\right) =\mathbf{0}$, and $Var\left( 
\mathbf{\epsilon }\right) =\sigma ^{2}I_{n}$ and $\mathbf{X}$ is a $n\times
p $ matrix with $r\left( \mathbf{X}\right) <p\leq n$.

Then the least square estimator of $\mathbf{\beta }$ is%
\begin{equation*}
\mathbf{\hat{\beta}}=\left( \mathbf{X}^{\dagger }\mathbf{X}\right) ^{-}%
\mathbf{X}^{\dagger }\mathbf{Y\quad }\text{(it's not square)}
\end{equation*}%
\begin{eqnarray*}
E\left( \mathbf{\hat{\beta}}\right) &=&E\left[ \left( \mathbf{X}^{\dagger }%
\mathbf{X}\right) ^{-}\mathbf{X}^{\dagger }\mathbf{Y}\right] =\left( \mathbf{%
X}^{\dagger }\mathbf{X}\right) ^{-}\mathbf{X}^{\dagger }E\left( \mathbf{Y}%
\right) \\
&=&\left( \mathbf{X}^{\dagger }\mathbf{X}\right) ^{-}\mathbf{X}^{\dagger }%
\mathbf{X\beta \neq \beta }
\end{eqnarray*}%
\begin{eqnarray*}
Var\left( \mathbf{\hat{\beta}}\right) &=&Var\left( \left( \mathbf{X}%
^{\dagger }\mathbf{X}\right) ^{-}\mathbf{X}^{\dagger }\mathbf{Y}\right)
=\left( \mathbf{X}^{\dagger }\mathbf{X}\right) ^{-}\mathbf{X}^{\dagger
}Var\left( \mathbf{Y}\right) \left[ \left( \mathbf{X}^{\dagger }\mathbf{X}%
\right) ^{-}\mathbf{X}^{\dagger }\right] \\
&=&\sigma ^{2}\left( \mathbf{X}^{\dagger }\mathbf{X}\right) ^{-}\mathbf{X}%
^{\dagger }\mathbf{X}\left( \mathbf{X}^{\dagger }\mathbf{X}\right) ^{-} \\
&&\text{(it's not invariant to the choice of }\left( \mathbf{X}^{\dagger }%
\mathbf{X}\right) ^{-}\text{)}
\end{eqnarray*}

\bigskip

\begin{theorem}
In the model $\mathbf{Y=X\beta +\epsilon }$, where $E\left( \mathbf{\epsilon 
}\right) =\mathbf{0}$\quad $Var\left( \mathbf{\epsilon }\right) =\sigma
^{2}I $ and $\mathbf{X}$ is $n\times p$ matrix with $r\left( \mathbf{X}%
\right) =r<p\leq n$, the $\mathbf{\lambda }^{\dagger }\mathbf{\beta }$ is
estimable iff one of the following conditions holds:

\begin{enumerate}
\item $\mathbf{\lambda }^{\dagger }\in R\left( \mathbf{X}\right) \quad
\left( \exists \ \mathbf{a}\quad \text{s.t.}\quad \mathbf{a}^{\dagger }%
\mathbf{X=\lambda }^{\dagger }\right) $

\item $\mathbf{\lambda }^{\dagger }\in R\left( \mathbf{X^{\dagger }X}\right)
\quad \left( \exists \ \mathbf{r}\quad \text{s.t.}\quad \mathbf{\gamma
^{\dagger }X}^{\dagger }\mathbf{X=\lambda }^{\dagger }\right) $

\item $\left( \mathbf{X^{\dagger }X}\right) \left( \mathbf{X^{\dagger }X}%
\right) ^{-}\mathbf{\lambda =\lambda }$ or $\mathbf{\lambda }^{\dagger
}\left( \mathbf{X^{\dagger }X}\right) ^{-}\mathbf{X^{\dagger }X=\lambda }%
^{\dagger }$
\end{enumerate}

\begin{proof}
\begin{enumerate}
\item[2.] let $\mathbf{\gamma ^{\dagger }X}^{\dagger }\mathbf{X=\lambda }%
\quad \left( \mathbf{a=X\gamma }\right) $\newline
$E\left( \mathbf{a}^{\dagger }\mathbf{Y}\right) =E\left( \mathbf{\gamma
^{\dagger }X}^{\dagger }\mathbf{Y}\right) =\mathbf{\gamma ^{\dagger }X}%
^{\dagger }\mathbf{X\beta =\lambda }^{\dagger }\mathbf{\beta }$\newline
\fbox{$E\left( \mathbf{a}^{\dagger }\mathbf{Y}\right) =\mathbf{\lambda }%
^{\dagger }\mathbf{\beta \Rightarrow a}^{\dagger }\mathbf{X\beta =\lambda }%
^{\dagger }\mathbf{\beta \Rightarrow a}^{\dagger }\mathbf{X=\lambda }%
^{\dagger }$}

\item[3.] If $\mathbf{X}^{\dagger }\mathbf{X}\left( \mathbf{X}^{\dagger }%
\mathbf{X}\right) ^{-}\mathbf{\lambda =\lambda }$\newline
then $\left( \mathbf{X}^{\dagger }\mathbf{X}\right) ^{-}\mathbf{\lambda }$
is a solution to $\mathbf{X}^{\dagger }\mathbf{X\gamma =\lambda }$
\end{enumerate}
\end{proof}
\end{theorem}

\begin{example}
\begin{equation*}
y_{ij}=\mu +\alpha _{i}+\varepsilon _{ij}\quad 
\begin{tabular}{l}
$i=1,2$ \\ 
$j=1,2,3$%
\end{tabular}%
\end{equation*}%
\begin{equation*}
\mathbf{X}=\left[ 
\begin{array}{ccc}
1 & 1 & 0 \\ 
1 & 1 & 0 \\ 
1 & 1 & 0 \\ 
1 & 0 & 1 \\ 
1 & 0 & 1 \\ 
1 & 0 & 1%
\end{array}%
\right] \quad ,\quad \mathbf{\beta }=\left[ 
\begin{array}{c}
\mu \\ 
\alpha _{1} \\ 
\alpha _{2}%
\end{array}%
\right]
\end{equation*}%
\newline
\newline
let $\mathbf{\lambda }^{\dagger }=\left[ 
\begin{array}{ccc}
0 & 1 & -1%
\end{array}%
\right] $

\begin{enumerate}
\item $\mathbf{\lambda }^{\dagger }\in R\left( \mathbf{X}\right) \quad $%
(i.e. $\mathbf{\lambda }^{\dagger }=\left[ \quad \right] -\left[ \quad %
\right] $)

\item $\mathbf{X}^{\dagger }\mathbf{X=}\left[ 
\begin{array}{ccc}
6 & 3 & 3 \\ 
3 & 3 & 0 \\ 
3 & 0 & 3%
\end{array}%
\right] $\newline
\newline
if take $\left( \mathbf{X}^{\dagger }\mathbf{X}\right) ^{-}=\left[ 
\begin{array}{ccc}
0 & 0 & 0 \\ 
0 & \frac{1}{3} & 0 \\ 
0 & 0 & \frac{1}{3}%
\end{array}%
\right] $\newline
\newline
$\mathbf{\gamma =}\left( \mathbf{X}^{\dagger }\mathbf{X}\right) ^{-}\mathbf{%
\lambda =}\left[ 
\begin{array}{ccc}
0 & 0 & 0 \\ 
0 & \frac{1}{3} & 0 \\ 
0 & 0 & \frac{1}{3}%
\end{array}%
\right] \left[ 
\begin{array}{c}
0 \\ 
1 \\ 
-1%
\end{array}%
\right] =\left[ 
\begin{array}{c}
0 \\ 
\frac{1}{3} \\ 
-\frac{1}{3}%
\end{array}%
\right] $\newline
\newline

\item $\left( \mathbf{X}^{\dagger }\mathbf{X}\right) \left( \mathbf{X}%
^{\dagger }\mathbf{X}\right) ^{-}=\left[ 
\begin{array}{ccc}
0 & 1 & 1 \\ 
0 & 1 & 0 \\ 
0 & 0 & 1%
\end{array}%
\right] $\newline
\newline
$\left( \mathbf{X}^{\dagger }\mathbf{X}\right) \left( \mathbf{X}^{\dagger }%
\mathbf{X}\right) ^{-}\mathbf{\lambda =}\left[ 
\begin{array}{ccc}
0 & 1 & 1 \\ 
0 & 1 & 0 \\ 
1 & 0 & 1%
\end{array}%
\right] \left[ 
\begin{array}{c}
0 \\ 
1 \\ 
-1%
\end{array}%
\right] =\left[ 
\begin{array}{c}
0 \\ 
1 \\ 
-1%
\end{array}%
\right] $
\end{enumerate}
\end{example}

\bigskip

\begin{theorem}
In the non-full-rank model $\mathbf{Y=X\beta +\epsilon }$, the number of
linearly independent estimable functions of $\mathbf{\beta }$ is the rank of 
$\mathbf{X}$.
\end{theorem}

\bigskip

note:

\begin{enumerate}
\item each row of $\mathbf{X\beta }$ is estimable

\item each row of $\mathbf{X}^{\dagger }\mathbf{X\beta }$ is estimable
\end{enumerate}

\bigskip

\begin{theorem}
Let $\mathbf{\lambda }^{\dagger }\mathbf{\beta }$ be an estimable function
of $\mathbf{\beta }$ in the model $\mathbf{Y=X\beta +\epsilon }$, $E\left( 
\mathbf{\epsilon }\right) =\mathbf{0}$, $Var\left( \mathbf{\epsilon }\right)
=\sigma ^{2}I$ and $\mathbf{X}_{n\times p}$ with $r\left( \mathbf{X}\right)
=r<p\leq n$.
\end{theorem}

\bigskip

Let $\mathbf{\hat{\beta}}$ be any solution to the normal equations $\mathbf{X%
}^{\dagger }\mathbf{X\hat{\beta}=X}^{\dagger }\mathbf{Y}$, and let $\mathbf{%
\gamma }$ be any solution to $\mathbf{X}^{\dagger }\mathbf{X\gamma =\lambda }
$, then

\begin{enumerate}
\item $E\left( \mathbf{\lambda }^{\dagger }\mathbf{\hat{\beta}}\right)
=E\left( \mathbf{\gamma }^{\dagger }\mathbf{X}^{\dagger }\mathbf{Y}\right) =%
\mathbf{\lambda }^{\dagger }\mathbf{\beta }$

\item $\mathbf{\lambda }^{\dagger }\mathbf{\hat{\beta}}$ is equal to $%
\mathbf{\gamma }^{\dagger }\mathbf{X}^{\dagger }\mathbf{Y\quad \forall \ 
\hat{\beta}}$ or $\mathbf{\gamma }$

\item $\mathbf{\lambda }^{\dagger }\mathbf{\hat{\beta}}$ and $\mathbf{\gamma 
}^{\dagger }\mathbf{X}^{\dagger }\mathbf{Y}$ are invariant to the choice of $%
\mathbf{\hat{\beta}}$ or $\mathbf{\gamma }$

\item $Var\left( \mathbf{\lambda }^{\dagger }\mathbf{\hat{\beta}}\right)
=\sigma ^{2}\mathbf{\lambda }^{\dagger }\left( \mathbf{X}^{\dagger }\mathbf{X%
}\right) ^{-}\mathbf{\lambda }$\newline
$Var\left( \mathbf{\gamma }^{\dagger }\mathbf{X}^{\dagger }\mathbf{Y}\right)
=\sigma ^{2}\mathbf{\gamma }^{\dagger }\mathbf{X}^{\dagger }\mathbf{X\gamma =%
}\sigma ^{2}\mathbf{\gamma \lambda }$

\item $^{\bigstar \bigstar }Var\left( \mathbf{\lambda }^{\dagger }\mathbf{%
\hat{\beta}}\right) $ is unique (invariant to the choice of $\mathbf{\gamma }
$ or $\left( \mathbf{X}^{\dagger }\mathbf{X}\right) ^{-}$)
\end{enumerate}

\begin{proof}
\begin{enumerate}
\item 
\begin{eqnarray*}
E\left( \mathbf{\lambda }^{\dagger }\mathbf{\hat{\beta}}\right) &=&E\left( 
\mathbf{\lambda }^{\dagger }\left( \mathbf{X}^{\dagger }\mathbf{X}\right)
^{-}\mathbf{X}^{\dagger }\mathbf{Y}\right) \\
&=&\mathbf{\lambda }^{\dagger }\left( \mathbf{X}^{\dagger }\mathbf{X}\right)
^{-}\mathbf{X}^{\dagger }\mathbf{X\beta \quad }\text{(i.e. }\mathbf{\lambda }%
^{\dagger }\left( \mathbf{X}^{\dagger }\mathbf{X}\right) ^{-}\mathbf{X}%
^{\dagger }\mathbf{X=\lambda }^{\dagger }\text{)} \\
&=&\mathbf{\lambda }^{\dagger }\mathbf{\beta }
\end{eqnarray*}%
\begin{eqnarray*}
E\left( \mathbf{\gamma }^{\dagger }\mathbf{X}^{\dagger }\mathbf{Y}\right) &=&%
\mathbf{\gamma }^{\dagger }\mathbf{X}^{\dagger }\mathbf{X\beta =}\left( 
\mathbf{X}^{\dagger }\mathbf{X\gamma }\right) ^{\dagger }\mathbf{\beta } \\
&=&\mathbf{\lambda }^{\dagger }\mathbf{\beta \quad }\text{(}\mathbf{X}%
^{\dagger }\mathbf{X\gamma =\lambda }\text{)}
\end{eqnarray*}

\item[3.] let $\mathbf{\gamma }_{1}$ and $\mathbf{\gamma }_{2}$ such that $%
\mathbf{X}^{\dagger }\mathbf{X\gamma }_{1}=\mathbf{X}^{\dagger }\mathbf{%
X\gamma }_{2}=\mathbf{\lambda }$\newline
$\Rightarrow \mathbf{\gamma }_{1}^{\dagger }\mathbf{X}^{\dagger }\mathbf{X%
\hat{\beta}}=\mathbf{\gamma }_{1}^{\dagger }\mathbf{X^{\dagger }Y}$ and $%
\mathbf{\gamma }_{2}^{\dagger }\mathbf{X}^{\dagger }\mathbf{X\hat{\beta}}=%
\mathbf{\gamma }_{2}^{\dagger }\mathbf{X}^{\dagger }\mathbf{Y}$\newline
$\Rightarrow \mathbf{\gamma }_{1}^{\dagger }\mathbf{X}^{\dagger }\mathbf{Y}=%
\mathbf{\gamma }_{2}^{\dagger }\mathbf{X}^{\dagger }\mathbf{Y}$

\item[5.] $\because \mathbf{X}\left( \mathbf{X}^{\dagger }\mathbf{X}\right)
^{-}\mathbf{X}^{\dagger }$ isinvariant to the choice of $\left( \mathbf{X}%
^{\dagger }\mathbf{X}\right) ^{-}$ (why!)\newline
hints:$\left\{ 
\begin{tabular}{l}
1. $\mathbf{X}^{\dagger }\mathbf{X}\left( \mathbf{X}^{\dagger }\mathbf{X}%
\right) ^{-}\mathbf{X}^{\dagger }\mathbf{X=X}^{\dagger }\mathbf{X}$ \\ 
2. $\mathbf{X}\left( \mathbf{X}^{\dagger }\mathbf{X}\right) ^{-}\mathbf{X}%
^{\dagger }\mathbf{X=X}$ \\ 
3. $\mathbf{X}G_{1}\mathbf{X}^{\dagger }\mathbf{X=X}G_{2}\mathbf{X}^{\dagger
}\mathbf{X}$ \\ 
$\vdots $ \\ 
$G_{1}=G_{2}$%
\end{tabular}%
\right. $\newline
\newline
Let $G_{1}$ and $G_{2}$ be two generalized inverse of $\left( \mathbf{X}%
^{\dagger }\mathbf{X}\right) $ then%
\begin{eqnarray*}
\mathbf{X}G_{1}\mathbf{X}^{\dagger } &\mathbf{=}&\mathbf{X}G_{2}\mathbf{X}%
^{\dagger }\quad \text{(}\mathbf{X}\left( \mathbf{X}^{\dagger }\mathbf{X}%
\right) ^{-}\mathbf{X}^{\dagger }\text{ is invariant)} \\
&\Rightarrow &\mathbf{a}^{\dagger }\mathbf{X}G_{1}\mathbf{X}^{\dagger }%
\mathbf{a=\mathbf{a}^{\dagger }X}G_{2}\mathbf{X}^{\dagger }\mathbf{a,}\quad 
\text{where }\mathbf{a}^{\dagger }\mathbf{X=\lambda } \\
&&\text{(}\mathbf{\lambda }^{\dagger }\mathbf{\beta }\text{ is estimable)} \\
&\Rightarrow &\mathbf{\lambda }G_{1}\mathbf{\lambda }^{\dagger }=\mathbf{%
\lambda }G_{2}\mathbf{\lambda }^{\dagger } \\
&\therefore &G_{1}=G_{2}
\end{eqnarray*}
\end{enumerate}
\end{proof}

\bigskip

\begin{theorem}
If $\mathbf{\lambda }^{\dagger }\mathbf{\beta }$ is an estimable function in
the linear model $\mathbf{Y=X\beta +\epsilon }$, where $r\left( \mathbf{X}%
\right) =r<p\leq n$, then $\mathbf{\lambda }^{\dagger }\mathbf{\beta }$ and $%
\mathbf{\gamma }^{\dagger }\mathbf{X}^{\dagger }\mathbf{Y}$ is BLUE.

\begin{proof}
\begin{eqnarray*}
&&\mathbf{\lambda }^{\dagger }\mathbf{\beta }\text{ is estimable} \\
&\Rightarrow &\exists \ \mathbf{a\quad }\text{s.t.}\mathbf{\quad a}^{\dagger
}\mathbf{X=\lambda }^{\dagger } \\
&\Rightarrow &\exists \ \mathbf{\gamma \quad }\text{s.t.}\mathbf{\quad
\gamma ^{\dagger }X}^{\dagger }\mathbf{X=\lambda }^{\dagger }
\end{eqnarray*}%
\newline
\newline
let $\mathbf{a}^{\dagger }\mathbf{Y}$ be a linear estimator of $\mathbf{%
\lambda }^{\dagger }\mathbf{\beta }$, WLOG, let $\mathbf{a}^{\dagger }=%
\mathbf{\gamma }^{\dagger }\mathbf{X}^{\dagger }\mathbf{+C}^{\dagger }$
where $\mathbf{\gamma }^{\dagger }$ is a solution to $\mathbf{\lambda
^{\dagger }=\gamma ^{\dagger }X}^{\dagger }\mathbf{X}$%
\begin{eqnarray*}
E\left( \mathbf{a}^{\dagger }\mathbf{Y}\right) &=&E\left( \left( \mathbf{%
\gamma }^{\dagger }\mathbf{X}^{\dagger }\mathbf{+C}^{\dagger }\right) 
\mathbf{Y}\right) \\
&=&\left( \mathbf{\gamma }^{\dagger }\mathbf{X}^{\dagger }\mathbf{+C}%
^{\dagger }\right) \mathbf{X\beta } \\
&=&\left( \mathbf{\gamma }^{\dagger }\mathbf{X}^{\dagger }\mathbf{X+C}%
^{\dagger }\mathbf{X}\right) \mathbf{\beta } \\
&=&\mathbf{\lambda }^{\dagger }\mathbf{\beta }
\end{eqnarray*}%
\begin{eqnarray*}
&\Rightarrow &\mathbf{\gamma }^{\dagger }\mathbf{X}^{\dagger }\mathbf{X+C}%
^{\dagger }\mathbf{X=\lambda }^{\dagger } \\
&\Rightarrow &\mathbf{C}^{\dagger }\mathbf{X=0\quad }\text{(}\because 
\mathbf{\lambda ^{\dagger }=\gamma ^{\dagger }X}^{\dagger }\mathbf{X}\text{)}
\end{eqnarray*}%
\begin{eqnarray*}
Var\left( \mathbf{a}^{\dagger }\mathbf{Y}\right) &=&\mathbf{a}^{\dagger
}\sigma ^{2}I\left( \mathbf{a}^{\dagger }\right) ^{\dagger } \\
&=&\sigma ^{2}\mathbf{a}^{\dagger }\mathbf{a}=\sigma ^{2}\left[ \left( 
\mathbf{\gamma }^{\dagger }\mathbf{X}^{\dagger }\mathbf{+C}^{\dagger
}\right) \left( \mathbf{\gamma X+C}\right) \right] \\
&=&\sigma ^{2}\left[ \mathbf{\gamma }^{\dagger }\mathbf{X}^{\dagger }\mathbf{%
X+\mathbf{\gamma }^{\dagger }\mathbf{X}^{\dagger }C+C}^{\dagger }\mathbf{%
X\gamma +C}^{\dagger }\mathbf{C}\right] \\
&=&\sigma ^{2}\left[ \mathbf{\gamma }^{\dagger }\mathbf{X}^{\dagger }\mathbf{%
X+}\underset{\text{min=0}}{\underbrace{\mathbf{C}^{\dagger }\mathbf{C}}}%
\right]
\end{eqnarray*}%
\begin{eqnarray*}
\mathbf{\hat{\beta}} &=&\left( \mathbf{X}^{\dagger }\mathbf{X}\right) ^{-}%
\mathbf{X}^{\dagger }\mathbf{Y} \\
\underset{\quad \hookrightarrow \text{BLUE}}{\mathbf{\lambda }^{\dagger }%
\mathbf{\hat{\beta}}} &\mathbf{\leadsto }&\mathbf{\lambda }^{\dagger }%
\mathbf{\beta }
\end{eqnarray*}
\end{proof}

\begin{proof}

\begin{enumerate}
\item 
\begin{eqnarray*}
E\left( \text{SSE}\right)  &=&E\left( \mathbf{Y}^{\dagger }\left( I-P_{%
\mathbf{X}}\right) \mathbf{Y}\right) ,\quad P_{\mathbf{X}}=\mathbf{X}\left( 
\mathbf{X}^{\dagger }\mathbf{X}\right) ^{-}\mathbf{X}^{\dagger } \\
&=&tr\left( \left( I_{n}-P_{\mathbf{X}}\right) \sigma ^{2}I\right) +\left( 
\mathbf{X\beta }\right) ^{\dagger }\left( I-P_{\mathbf{X}}\right) \left( 
\mathbf{X\beta }\right)  \\
&=&\sigma ^{2}tr\left( I_{n}-P_{\mathbf{X}}\right) +\mathbf{\beta }^{\dagger
}\mathbf{X}^{\dagger }\left( I-P_{\mathbf{X}}\right) \mathbf{X\beta } \\
&=&\sigma ^{2}tr\left( I_{n}-\mathbf{X}\left( \mathbf{X}^{\dagger }\mathbf{X}%
\right) ^{-}\mathbf{X}^{\dagger }\right) +0 \\
&=&\sigma ^{2}\left[ n-tr\left( \mathbf{X}\left( \mathbf{X}^{\dagger }%
\mathbf{X}\right) ^{-}\mathbf{X}^{\dagger }\right) \right]  \\
&=&\sigma ^{2}\left[ n-\underset{r\left( \mathbf{X}\right) =r}{\underbrace{%
r\left( \mathbf{X}^{\dagger }\mathbf{X}\right) }}\right]  \\
&=&\sigma ^{2}\left[ n-r\right] 
\end{eqnarray*}%
\begin{equation*}
E\left( S^{2}\right) =E\left( \frac{\left( \mathbf{Y}-\mathbf{X\hat{\beta}}%
\right) ^{\dagger }\left( \mathbf{Y}-\mathbf{X\hat{\beta}}\right) }{n-r}%
\right) =\sigma ^{2}
\end{equation*}

\item $\because $ SSE $=\mathbf{Y}^{\dagger }\left( I-P_{\mathbf{X}}\right) 
\mathbf{Y}$, $P_{\mathbf{X}}=\mathbf{X}\left( \mathbf{X}^{\dagger }\mathbf{X}%
\right) ^{-}\mathbf{X}^{\dagger }$\newline
$\because \mathbf{X}\left( \mathbf{X}^{\dagger }\mathbf{X}\right) ^{-}%
\mathbf{X}^{\dagger }$ is invariant to choice of $\left( \mathbf{X}^{\dagger
}\mathbf{X}\right) ^{-}$\newline
$\therefore $SSE is invariant to choice of $\left( \mathbf{X}^{\dagger }%
\mathbf{X}\right) ^{-}$
\end{enumerate}
\end{proof}
\end{theorem}

\bigskip

\subsubsection{Reparmeterization}

\begin{eqnarray*}
\mathbf{Y} &=&\mathbf{X\beta +\epsilon \quad }\text{non-full-rank model} \\
&=&\mathbf{ZU\beta +\epsilon } \\
&=&\mathbf{Z\gamma +\epsilon \quad }\text{full-rank model}
\end{eqnarray*}

\begin{enumerate}
\item $\underset{r\times p}{\mathbf{U}}\underset{p\times 1}{\mathbf{\beta }}%
\mathbf{=}\underset{r\times 1}{\mathbf{\gamma }}$\newline
$\mathbf{\gamma }$ linearly indep. estimable functions of $\mathbf{\beta }$

\item $\mathbf{ZU=X}$\newline
$\Rightarrow \mathbf{ZUU}^{\dagger }=\mathbf{XU}^{\dagger }$\newline
$\Rightarrow \mathbf{Z=XU}^{\dagger }\left( \mathbf{UU}^{\dagger }\right)
^{-1}$ where $\mathbf{Z}$ is full-rank with $r\left( \mathbf{Z}\right) =r$

\item $\mathbf{\hat{\gamma}=}\left( \mathbf{Z^{\dagger }Z}\right) ^{-1}%
\mathbf{Z^{\dagger }Y}$%
\begin{eqnarray*}
S^{2} &=&\frac{\left( \mathbf{Y-Z\hat{\gamma}}\right) ^{\dagger }\left( 
\mathbf{Y-Z\hat{\gamma}}\right) }{n-r} \\
&=&\frac{\left( \mathbf{Y}-\mathbf{X\hat{\beta}}\right) ^{\dagger }\left( 
\mathbf{Y}-\mathbf{X\hat{\beta}}\right) }{n-r},\quad \mathbf{Z\gamma =X\beta 
}\Leftrightarrow \mathbf{Z\hat{\gamma}=X\hat{\beta}}
\end{eqnarray*}
\end{enumerate}

\bigskip

\begin{example}
Consider the model%
\begin{equation*}
y_{ij}=\mu +\alpha _{i}+\varepsilon _{ij},\quad i=1,2,\quad j=1,2
\end{equation*}%
\begin{equation*}
\mathbf{Y=X\beta +\epsilon =}\left[ 
\begin{array}{ccc}
1 & 1 & 0 \\ 
1 & 1 & 0 \\ 
1 & 0 & 1 \\ 
1 & 0 & 1%
\end{array}%
\right] \left[ 
\begin{array}{c}
\mu \\ 
\alpha _{1} \\ 
\alpha _{2}%
\end{array}%
\right] +\epsilon ,\quad r\left( \mathbf{X}\right) =2
\end{equation*}%
\newline
let%
\begin{eqnarray*}
\mathbf{\gamma } &\mathbf{=}&\left[ 
\begin{array}{c}
\gamma _{1} \\ 
\gamma _{2}%
\end{array}%
\right] =\left[ 
\begin{array}{c}
\mu +\alpha _{1} \\ 
\mu +\alpha _{2}%
\end{array}%
\right] =\left[ 
\begin{array}{ccc}
1 & 1 & 0 \\ 
1 & 0 & 1%
\end{array}%
\right] \left[ 
\begin{array}{c}
\mu \\ 
\alpha _{1} \\ 
\alpha _{2}%
\end{array}%
\right] \\
&=&\mathbf{U\beta }
\end{eqnarray*}%
\begin{equation*}
\mathbf{Z}=\mathbf{XU}^{\dagger }\left( \mathbf{UU}^{\dagger }\right) ^{-1}=%
\left[ 
\begin{array}{cc}
1 & 0 \\ 
1 & 0 \\ 
0 & 1 \\ 
0 & 1%
\end{array}%
\right] ,\quad r\left( \mathbf{Z}\right) =2
\end{equation*}%
\begin{equation*}
\mathbf{Z}^{\dagger }\mathbf{Y=}\left[ 
\begin{array}{cccc}
1 & 1 & 0 & 0 \\ 
0 & 0 & 1 & 1%
\end{array}%
\right] \left[ 
\begin{array}{c}
Y_{11} \\ 
Y_{12} \\ 
Y_{21} \\ 
Y_{22}%
\end{array}%
\right] =\left[ 
\begin{array}{c}
y_{1} \\ 
y_{2}%
\end{array}%
\right]
\end{equation*}%
\begin{equation*}
\mathbf{Z}^{\dagger }\mathbf{Z=}\left[ 
\begin{array}{cccc}
1 & 1 & 0 & 0 \\ 
0 & 0 & 1 & 1%
\end{array}%
\right] \left[ 
\begin{array}{cc}
1 & 0 \\ 
1 & 0 \\ 
0 & 1 \\ 
0 & 1%
\end{array}%
\right] =\left[ 
\begin{array}{cc}
2 & 0 \\ 
0 & 2%
\end{array}%
\right]
\end{equation*}%
\begin{equation*}
\mathbf{Z}^{\dagger }\mathbf{Z\hat{\gamma}=Z}^{\dagger }\mathbf{Y}
\end{equation*}%
\begin{equation*}
\left[ 
\begin{array}{cc}
2 & 0 \\ 
0 & 2%
\end{array}%
\right] \left[ 
\begin{array}{c}
\hat{r}_{1} \\ 
\hat{r}_{2}%
\end{array}%
\right] =\left[ 
\begin{array}{c}
y_{1} \\ 
y_{2}%
\end{array}%
\right] \quad 
\begin{tabular}{l}
$\hat{r}_{1}=\frac{y_{1}}{2}$ \\ 
$\hat{r}_{2}=\frac{y_{2}}{2}$%
\end{tabular}%
\end{equation*}
\end{example}

\bigskip

\paragraph{Side Conditions}

\begin{theorem}
If $\mathbf{Y}=\mathbf{X\beta +\epsilon }$ where $\mathbf{X}$ is $n\times p$
matrix with $r\left( \mathbf{X}\right) =r<p\leq n$, and if $\Pi _{\left(
p-r\right) \times p}$ matrix with $r\left( \Pi \right) =p-r$ such that $\Pi 
\mathbf{\beta }$ is a set of nonestimable functions, then there is a unique
vector $\hat{\beta}$ that satisfies both

\begin{enumerate}
\item $\mathbf{X}^{\dagger }\mathbf{X}\hat{\beta}=\mathbf{X^{\dagger }Y}$,
and

\item $\Pi \mathbf{\beta =0}$
\end{enumerate}
\end{theorem}

\bigskip

\end{document}
