
\documentclass{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{accents}
\usepackage[ignoreall,a4paper]{geometry}
\usepackage{fancyhdr}

\setcounter{MaxMatrixCols}{10}
%TCIDATA{OutputFilter=LATEX.DLL}
%TCIDATA{Version=5.00.0.2606}
%TCIDATA{<META NAME="SaveForMode" CONTENT="1">}
%TCIDATA{BibliographyScheme=Manual}
%TCIDATA{Created=Wednesday, November 25, 2015 15:33:37}
%TCIDATA{LastRevised=Monday, July 04, 2016 11:26:27}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{<META NAME="DocumentShell" CONTENT="Standard LaTeX\Blank - Standard LaTeX Article">}
%TCIDATA{CSTFile=40 LaTeX article.cst}
%TCIDATA{ComputeDefs=
%$W=\left( 1-\sigma \right) I$
%}


\newtheorem{theorem}{Theorem}
\newtheorem{acknowledgement}[theorem]{Acknowledgement}
\newtheorem{algorithm}[theorem]{Algorithm}
\newtheorem{axiom}[theorem]{Axiom}
\newtheorem{case}[theorem]{Case}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conclusion}[theorem]{Conclusion}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{criterion}[theorem]{Criterion}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{solution}[theorem]{Solution}
\newtheorem{summary}[theorem]{Summary}
\newenvironment{proof}[1][Proof]{\noindent\textbf{#1.} }{\ \rule{0.5em}{0.5em}}
\input{../../tcilatex}
\DeclareMathAccent{\wtilde}{\mathord}{largesymbols}{"65}
\pagestyle{fancy}
\fancyfoot[C]{\thepage}


\begin{document}


\begin{eqnarray*}
\mathbf{Y}^{\dagger }\left( P_{\mathbf{X}}-P_{\mathbf{X}_{1}}\right) \mathbf{%
Y} &=&\mathbf{Y}^{\dagger }P_{\mathbf{X}}\mathbf{Y-Y}^{\dagger }P_{\mathbf{X}%
_{1}}\mathbf{Y} \\
&=&\mathbf{Y}^{\dagger }\mathbf{X}\left( \mathbf{X}^{\dagger }\mathbf{X}%
\right) ^{-1}\mathbf{X}^{\dagger }\mathbf{Y-Y}^{\dagger }\mathbf{X}%
_{1}\left( \mathbf{X}_{1}^{\dagger }\mathbf{X}_{1}\right) ^{-1}\mathbf{X}%
_{1}^{\dagger }\mathbf{Y} \\
&=&\left[ \left( \mathbf{X}^{\dagger }\mathbf{X}\right) ^{-1}\mathbf{X}%
^{\dagger }\mathbf{Y}\right] ^{\dagger }\mathbf{XY-}\left[ \left( \mathbf{X}%
_{1}^{\dagger }\mathbf{X}_{1}\right) ^{-1}\mathbf{X}_{1}^{\dagger }\mathbf{Y}%
\right] ^{\dagger }\mathbf{X}_{1}^{\dagger }\mathbf{Y} \\
&=&\hat{\beta}^{\dagger }\mathbf{X}^{\dagger }\mathbf{Y-}\hat{\beta}\mathbf{%
_{1}^{\dagger }X}_{1}^{\dagger }\mathbf{Y}
\end{eqnarray*}%
\begin{equation*}
\mathbf{Y}^{\dagger }\left( I-P_{\mathbf{X}}\right) \mathbf{Y=Y}^{\dagger }%
\mathbf{Y-Y}^{\dagger }P_{\mathbf{X}}\mathbf{Y=Y}^{\dagger }\mathbf{Y-}\hat{%
\beta}^{\dagger }\mathbf{X}^{\dagger }\mathbf{Y}
\end{equation*}

\bigskip

Summary

\bigskip

Consider the linear model%
\begin{equation*}
\mathbf{Y=X\beta +\epsilon }
\end{equation*}

\bigskip

\subsubsection{The general linear hypothesis}

\bigskip

test for%
\begin{eqnarray*}
H_{0} &:&\mathbf{C}_{q\times p}\mathbf{\beta }_{p\times 1}=\mathbf{0}%
_{q\times 1} \\
H_{1} &:&\mathbf{C}_{q\times p}\mathbf{\beta }_{p\times 1}\neq \mathbf{0}%
_{q\times 1}
\end{eqnarray*}

\bigskip

\begin{example}
\begin{enumerate}
\item $\mathbf{Y=X\beta +\epsilon ,\quad \beta =}\left[ \beta _{0},\beta
_{1},\cdots ,\beta _{k}\right] ^{\dagger }=\left[ 
\begin{array}{cc}
\beta _{0} & \beta _{1}^{\dagger }%
\end{array}%
\right] ^{\dagger }$%
\begin{equation*}
H_{0}:\mathbf{\beta }_{1}=\mathbf{0}
\end{equation*}%
\begin{equation*}
\Leftrightarrow H_{0}:\fbox{$\mathbf{C\beta }$}=\left[ 
\begin{array}{cc}
\mathbf{0}_{k\times 1} & I_{k}%
\end{array}%
\right] \left[ 
\begin{array}{c}
\beta _{0} \\ 
\beta _{1}%
\end{array}%
\right] =\mathbf{0}_{k\times 1}
\end{equation*}

\item $\mathbf{Y=X\beta +\epsilon =}\left[ 
\begin{array}{cc}
\mathbf{X}_{1} & \mathbf{X}_{2}%
\end{array}%
\right] \left[ 
\begin{array}{c}
\beta _{1} \\ 
\beta _{2}%
\end{array}%
\right] +\mathbf{\epsilon }$%
\begin{equation*}
H_{0}:\underset{n\times 1}{\underbrace{\mathbf{\beta }_{2}=\mathbf{0}}}
\end{equation*}%
\begin{equation*}
\Leftrightarrow H_{0}:\mathbf{C\beta }=\left[ 
\begin{array}{cc}
\mathbf{0}_{n\times \left( p-h\right) } & I_{h}%
\end{array}%
\right] \left[ 
\begin{array}{c}
\beta _{1} \\ 
\beta _{2}%
\end{array}%
\right] =\mathbf{0}_{n\times 1}
\end{equation*}

\item $\mathbf{Y=X\beta +\epsilon ,\quad \beta =}\left[ \beta _{0},\beta
_{1},\cdots ,\beta _{4}\right] ^{\dagger }$

\begin{enumerate}
\item $H_{0}:2\beta _{1}-\beta _{2}=\beta _{2}-2\beta _{3}+3\beta _{4}=\beta
_{1}-\beta _{4}=0$%
\begin{equation*}
\Leftrightarrow H_{0}:\mathbf{C\beta }=\overset{\beta _{0}\sim \beta _{4}}{%
\left[ 
\begin{array}{ccccc}
0 & 2 & -1 & 0 & 0 \\ 
0 & 0 & 1 & -2 & 3 \\ 
0 & 1 & 0 & 0 & -1%
\end{array}%
\right] }_{3\times 5}\mathbf{\beta =0}_{3\times 1}
\end{equation*}

\item $H_{0}:\beta _{1}=\beta _{2}=\cdots =\beta _{4}\Leftrightarrow
H_{0}:\beta _{1}-\beta _{2}=\beta _{2}-\beta _{3}=\beta _{3}-\beta _{4}=0$%
\begin{equation*}
\Leftrightarrow H_{0}:\mathbf{C\beta }=\left[ 
\begin{array}{ccccc}
0 & 1 & -1 & 0 & 0 \\ 
0 & 0 & 1 & -1 & 0 \\ 
0 & 0 & 0 & 1 & 1%
\end{array}%
\right] _{3\times 5}\mathbf{\beta =0}_{3\times 1}
\end{equation*}
\end{enumerate}
\end{enumerate}
\end{example}

\bigskip

\begin{theorem}
Consider the model%
\begin{equation*}
\mathbf{Y=X\beta }_{p\times 1}\mathbf{+\epsilon \quad ,\quad \epsilon }\sim
N_{n}\left( 0,\sigma ^{2}I\right)
\end{equation*}%
Let $\mathbf{C}$ be a $q\times p$ matrix with $r\left( \mathbf{C}\right)
=q\leq p$. Then we have

\begin{enumerate}
\item $\mathbf{C}_{q\times p}\mathbf{\hat{\beta}}_{p\times 1}\sim
N_{q}\left( \mathbf{C\beta },\sigma ^{2}\mathbf{C}\left( \mathbf{X}^{\dagger
}\mathbf{X}\right) ^{-1}\mathbf{C}^{\dagger }\right) $

\item $\frac{\text{SSH}}{\sigma ^{2}}=\frac{\left( \mathbf{C\hat{\beta}}%
\right) ^{\dagger }\left[ \mathbf{C}\left( \mathbf{X}^{\dagger }\mathbf{X}%
\right) ^{-1}\mathbf{C}^{\dagger }\right] ^{-1}\left( \mathbf{C\hat{\beta}}%
\right) }{\sigma ^{2}}\sim \chi _{q}^{2}\left[ \frac{\left( \mathbf{C\beta }%
\right) ^{\dagger }\left[ \mathbf{C}\left( \mathbf{X}^{\dagger }\mathbf{X}%
\right) ^{-1}\mathbf{C}^{\dagger }\right] ^{-1}\left( \mathbf{C\beta }%
\right) }{2\sigma ^{2}}\right] $

\item $\frac{\text{SSE}}{\sigma ^{2}}=\frac{\mathbf{Y}^{\dagger }\left( I-P_{%
\mathbf{X}}\right) \mathbf{Y}}{\sigma ^{2}}\sim \chi _{n-r}^{2}$

\item SSH and SSE are indep

\item $F=\frac{\frac{\text{SSH}/\sigma ^{2}}{q}}{\frac{\text{SSE}/\sigma ^{2}%
}{n-r}}\sim F_{q,n-r}\left( \frac{\left( \mathbf{C\beta }\right) ^{\dagger
}\left( \sigma ^{2}H\right) ^{-1}\left( \mathbf{C\beta }\right) }{2}\right)
, $ where $H=\mathbf{C}\left( \mathbf{X}^{\dagger }\mathbf{X}\right) ^{-1}%
\mathbf{C}^{\dagger }$
\end{enumerate}
\end{theorem}

\bigskip

\begin{theorem}
\begin{eqnarray*}
H_{0} &:&\mathbf{C\beta =\tau }\quad H_{1}:\mathbf{C\beta \neq \tau } \\
H_{0} &:&\mathbf{C\beta -\tau =0}
\end{eqnarray*}%
\newline
Consider the model%
\begin{equation*}
\mathbf{Y=X\beta +\epsilon \quad ,\quad \epsilon }\sim N_{n}\left( 0,\sigma
^{2}I\right)
\end{equation*}%
\newline
Let $\mathbf{C}$ be a $q\times p$ matrix with $r\left( \mathbf{C}\right)
=q\leq p$. Then we have

\begin{enumerate}
\item $C\hat{\beta}-\mathbf{\tau }\sim N_{q}\left( \mathbf{C\beta -\tau }%
,\sigma ^{2}\mathbf{C}\left( \mathbf{X}^{\dagger }\mathbf{X}\right) ^{-1}%
\mathbf{C}^{\dagger }\right) $

\item $\frac{\text{SSH}}{\sigma ^{2}}=\frac{\left( \mathbf{C\hat{\beta}-\tau 
}\right) ^{\dagger }\left[ \mathbf{C}\left( \mathbf{X}^{\dagger }\mathbf{X}%
\right) ^{-1}\mathbf{C}^{\dagger }\right] ^{-1}\left( \mathbf{C\hat{\beta}%
-\tau }\right) }{\sigma ^{2}}\sim \chi _{q}^{2}\left[ \frac{\left( \mathbf{%
C\beta -\tau }\right) ^{\dagger }\left[ \mathbf{C}\left( \mathbf{X}^{\dagger
}\mathbf{X}\right) ^{-1}\mathbf{C}^{\dagger }\right] ^{-1}\left( \mathbf{%
C\beta -\tau }\right) }{2\sigma ^{2}}\right] $
\end{enumerate}
\end{theorem}

\bigskip

\subsubsection{Testing on $\protect\beta _{j}$ or $\mathbf{a}^{\dagger }%
\mathbf{\protect\beta }$}

We consider a special case of testing $H_{0}:\mathbf{C\beta =0}$. When $%
r\left( \mathbf{C}\right) =1$. This hypothesis is more appropriately written
as $H_{0}:\mathbf{a}^{\dagger }\mathbf{\beta =0}$ where $\mathbf{a}$ is a $%
p\times 1$ vector. Using $\mathbf{a}^{\dagger }$ in place of the matrix $%
\mathbf{C}$ in $\mathbf{C\beta =0}$, we have $q=1$ and statistic becomes%
\begin{equation*}
F=\frac{\left( \mathbf{a}^{\dagger }\mathbf{\hat{\beta}}\right) ^{\dagger }%
\left[ \mathbf{a}^{\dagger }\left( \mathbf{X}^{\dagger }\mathbf{X}\right)
^{-1}\mathbf{a}\right] ^{-1}\mathbf{a}^{\dagger }\mathbf{\hat{\beta}/1}}{%
\fbox{SSE/n-r}\rightarrow S^{2}}=\frac{\left( \mathbf{a}^{\dagger }\mathbf{%
\hat{\beta}}\right) ^{2}}{S^{2}\left[ \mathbf{a}^{\dagger }\left( \mathbf{X}%
^{\dagger }\mathbf{X}\right) ^{-1}\mathbf{a}\right] }
\end{equation*}

\bigskip

Consider $H_{0}:\mathbf{\beta }_{j}\mathbf{=0}\Leftrightarrow H_{0}:\mathbf{a%
}^{\dagger }\mathbf{\beta =0}$, where $\mathbf{a}^{\dagger }=\left[ 
\begin{array}{ccccccc}
0 & 0 & \cdots & 1 & 0 & \cdots & 0%
\end{array}%
\right] $%
\begin{equation*}
\therefore F=\frac{\hat{\beta}_{j}^{2}}{S^{2}g_{jj}}
\end{equation*}%
where $g_{jj}$ is the $j$th diagonal elements of $\left( \mathbf{X}^{\dagger
}\mathbf{X}\right) ^{-1}$%
\begin{eqnarray*}
F &=&\left( \frac{\hat{\beta}_{j}}{S\sqrt{g_{jj}}}\right) ^{2}\sim
F_{1,n-r}\left( 0\right) \\
&=&\left( t_{j}^{2}\right) \curvearrowright t_{n-r}\left( 0\right)
\end{eqnarray*}

\bigskip

\bigskip

\subsection{The full-reduced model test versus the general linear hypothesis
test}

\begin{theorem}
The F test for the general linear hypothesis $H_{0}:\mathbf{C\beta =0}$ is a
full-reduced model test.

\begin{proof}
the reduced model under $H_{0}$ is%
\begin{equation*}
\mathbf{Y=X\beta +\epsilon \quad }\text{subject to }\mathbf{C\beta =0}
\end{equation*}%
\newline
Using Lagrange multipliers, it can be shown that the estimator for $\mathbf{%
\beta }$ is%
\begin{equation*}
\mathbf{\hat{\beta}}_{c}^{\ast }=\mathbf{\hat{\beta}-}\left( \mathbf{X}%
^{\dagger }\mathbf{X}\right) ^{-1}\mathbf{C}^{\dagger }\left[ \mathbf{C}%
\left( \mathbf{X}^{\dagger }\mathbf{X}\right) ^{-1}\mathbf{C}^{\dagger }%
\right] ^{-1}\mathbf{C\hat{\beta}}
\end{equation*}%
where $\mathbf{\hat{\beta}=}\left( \mathbf{X}^{\dagger }\mathbf{X}\right)
^{-1}\mathbf{X}^{\dagger }\mathbf{Y}$ is estimated from the full model.%
\newline
\newline
The F test statistic is%
\begin{eqnarray*}
F &=&\frac{\mathbf{Y}^{\dagger }\left( P_{\mathbf{X}}-P_{\mathbf{W}}\right) 
\mathbf{Y/}r^{\ast }}{\mathbf{Y}^{\dagger }\left( I-P_{\mathbf{X}}\right) 
\mathbf{Y/}\left( n-r\right) } \\
&=&\frac{\left( \mathbf{\hat{\beta}}^{\dagger }\mathbf{X^{\dagger }Y-\hat{%
\beta}}_{c}^{\ast \dagger }\mathbf{X^{\dagger }Y}\right) /r^{\ast }}{\text{%
SSE}/\left( n-r\right) }
\end{eqnarray*}%
\begin{eqnarray*}
&&\mathbf{\hat{\beta}}^{\dagger }\mathbf{X^{\dagger }Y-\hat{\beta}}%
_{c}^{\ast \dagger }\mathbf{X^{\dagger }Y} \\
&=&\mathbf{\hat{\beta}}^{\dagger }\mathbf{X^{\dagger }Y-}\left[ \mathbf{\hat{%
\beta}-}\left( \mathbf{X}^{\dagger }\mathbf{X}\right) ^{-1}\mathbf{C}%
^{\dagger }\left[ \mathbf{C}\left( \mathbf{X}^{\dagger }\mathbf{X}\right)
^{-1}\mathbf{C}^{\dagger }\right] ^{-1}\mathbf{C\hat{\beta}}\right] \mathbf{%
X^{\dagger }Y} \\
&=&\mathbf{\hat{\beta}}^{\dagger }\mathbf{X^{\dagger }Y-}\left[ \mathbf{\hat{%
\beta}}^{\dagger }\mathbf{-\hat{\beta}}^{\dagger }\mathbf{C}^{\dagger }\left[
\mathbf{C}\left( \mathbf{X}^{\dagger }\mathbf{X}\right) ^{-1}\mathbf{C}%
^{\dagger }\right] ^{-1}\mathbf{C\left( \mathbf{X}^{\dagger }\mathbf{X}%
\right) ^{-1}}\right] \mathbf{X^{\dagger }Y} \\
&=&\mathbf{\hat{\beta}}^{\dagger }\mathbf{X^{\dagger }Y-\hat{\beta}}%
^{\dagger }\mathbf{X^{\dagger }Y+\hat{\beta}}^{\dagger }\mathbf{C}^{\dagger }%
\left[ \mathbf{C}\left( \mathbf{X}^{\dagger }\mathbf{X}\right) ^{-1}\mathbf{C%
}^{\dagger }\right] ^{-1}\underset{\hat{\beta}}{\underbrace{\mathbf{C\left( 
\mathbf{X}^{\dagger }\mathbf{X}\right) ^{-1}X^{\dagger }Y}}} \\
&=&\mathbf{\hat{\beta}}^{\dagger }\mathbf{C}^{\dagger }\left[ \mathbf{C}%
\left( \mathbf{X}^{\dagger }\mathbf{X}\right) ^{-1}\mathbf{C}^{\dagger }%
\right] ^{-1}\mathbf{C\hat{\beta}}
\end{eqnarray*}%
\begin{equation*}
F=\frac{\text{SSH}/q}{\text{SSE}/\left( n-r\right) },\quad r^{\ast
}=r-r_{0}=P_{1}+P_{2}-P_{1}=\underset{\text{why}}{\underbrace{P_{2}=q}}
\end{equation*}
\end{proof}
\end{theorem}

\bigskip

\bigskip

\paragraph{Likelihood Ratio Tests}

\begin{equation*}
\mathbf{Y=X\beta +\epsilon \quad ,\quad \epsilon }\sim N_{n}\left( 0,\sigma
^{2}I_{n}\right)
\end{equation*}%
\begin{equation*}
H_{0}:\mathbf{\beta =0}\quad \text{v.s}\quad H_{1}:\mathbf{\beta \neq 0}
\end{equation*}

\bigskip

the likelihood ratio%
\begin{equation*}
\text{LR}=\frac{\text{max}_{H_{0}}L\left( \mathbf{\beta },\sigma ^{2}\right) 
}{\text{max}_{H_{1}}L\left( \mathbf{\beta },\sigma ^{2}\right) }
\end{equation*}%
where%
\begin{equation*}
L\left( \mathbf{\beta },\sigma ^{2}\right) =\left( 2\pi \sigma ^{2}\right)
^{-\frac{n}{2}}e^{-\frac{\left( \mathbf{Y-X\beta }\right) ^{\dagger }\left( 
\mathbf{Y-X\beta }\right) }{2\sigma ^{2}}}=\frac{\text{max }L\left( \mathbf{0%
},\sigma ^{2}\right) }{\text{max }L\left( \mathbf{\beta },\sigma ^{2}\right) 
}
\end{equation*}

\bigskip

\begin{theorem}
The likelihood ratio test for $H_{0}:\mathbf{\beta =0}$ can be based on%
\begin{equation*}
F=\frac{\mathbf{\hat{\beta}X^{\dagger }Y}/P}{\left( \mathbf{Y^{\dagger }Y}-%
\mathbf{\hat{\beta}}^{\dagger }\mathbf{X^{\dagger }Y}\right) /\left(
n-p\right) }=\frac{\left( \mathbf{\hat{\beta}}^{\dagger }\mathbf{X^{\dagger
}Y}\right) \left( n-p\right) }{\left( \mathbf{Y^{\dagger }Y}-\mathbf{\hat{%
\beta}}^{\dagger }\mathbf{X^{\dagger }Y}\right) P}
\end{equation*}%
We reject $H_{0}$ if $F>F_{\alpha ,p,n-p}$

\begin{proof}
\begin{eqnarray*}
\text{max}_{H_{0}}L\left( \mathbf{\beta },\sigma ^{2}\right)  &=&L\left( 
\mathbf{\hat{\beta}},\hat{\sigma}^{2}\right)  \\
&=&\left( 2\pi \hat{\sigma}^{2}\right) ^{-\frac{n}{2}}e^{-\frac{\left( 
\mathbf{Y-X\hat{\beta}}\right) ^{\dagger }\left( \mathbf{Y-X\hat{\beta}}%
\right) }{2\hat{\sigma}^{2}}}
\end{eqnarray*}%
where%
\begin{equation*}
\mathbf{\hat{\beta}}=\mathbf{\left( \mathbf{X}^{\dagger }\mathbf{X}\right)
^{-1}X^{\dagger }Y}\text{ and }\hat{\sigma}^{2}=\frac{\left( \mathbf{Y-X\hat{%
\beta}}\right) ^{\dagger }\left( \mathbf{Y-X\hat{\beta}}\right) }{n}
\end{equation*}%
As $\mathbf{\beta }=\mathbf{0}$%
\begin{equation*}
L\left( \mathbf{0},\sigma ^{2}\right) =\left( 2\pi \sigma ^{2}\right) ^{-%
\frac{n}{2}}e^{-\frac{\mathbf{Y}^{\dagger }\mathbf{Y}}{2\sigma ^{2}}}
\end{equation*}%
\begin{equation*}
\ln L\left( \mathbf{0},\sigma ^{2}\right) =l\left( \mathbf{0},\sigma
^{2}\right) =-\frac{n}{2}\ln \left( 2\pi \sigma ^{2}\right) -\frac{\mathbf{Y}%
^{\dagger }\mathbf{Y}}{2\sigma ^{2}}
\end{equation*}%
\begin{equation*}
\frac{\partial l}{\partial \sigma ^{2}}=0\Rightarrow -\frac{n}{2}\frac{2\pi 
}{2\pi \hat{\sigma}_{0}^{2}}+\frac{\mathbf{Y}^{\dagger }\mathbf{Y}}{2\left( 
\hat{\sigma}^{2}\right) ^{2}}=0\Rightarrow \hat{\sigma}_{0}^{2}=\frac{%
\mathbf{Y}^{\dagger }\mathbf{Y}}{n}
\end{equation*}%
\begin{equation*}
\therefore \text{max }_{H_{0}}L\left( \mathbf{\beta },\sigma ^{2}\right)
=L\left( \mathbf{0},\hat{\sigma}_{0}^{2}\right) =\left( 2\pi \hat{\sigma}%
_{0}^{2}\right) ^{-\frac{n}{2}}e^{-\frac{\mathbf{Y}^{\dagger }\mathbf{Y}}{n}}
\end{equation*}%
\begin{eqnarray*}
&\therefore &\text{LR}=\frac{\text{max}_{H_{0}}L\left( \mathbf{\beta }%
,\sigma ^{2}\right) }{\text{max}_{H_{1}}L\left( \mathbf{\beta },\sigma
^{2}\right) }=\cdots =\left[ \frac{\left( \mathbf{Y-X\hat{\beta}}\right)
^{\dagger }\left( \mathbf{Y-X\hat{\beta}}\right) }{\mathbf{Y}^{\dagger }%
\mathbf{Y}}\right] ^{\frac{n}{2}} \\
&=&\left[ \frac{1}{1+F\frac{p}{n-p}}\right] ^{\frac{p}{2}}
\end{eqnarray*}%
\newline
Thus, rejection $H_{0}:\mathbf{\beta =0}$ for a small value of LR $%
\Leftrightarrow $ rejection $H_{0}:\mathbf{\beta =0}$ for a large value F.
\end{proof}
\end{theorem}

\end{document}
